
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Simulating a smart thermostat using CATS: a Contextual Bandit algorithm with a continuous action space &#8212; VowpalWabbit latest documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nav.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".cell"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Classification with Vowpal Wabbit" href="python_classification.html" />
    <link rel="prev" title="Offline policy evaluation using the VW command line" href="off_policy_evaluation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <div class="navbar_container main_nav_container">
  <div class="container nav_wrapper">
    <div class="logo">
      <a href="https://vowpalwabbit.org/index.html">
        <?xml version="1.0" encoding="UTF-8"?>
<svg width="172px" height="30px" viewBox="0 0 172 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 57.1 (83088) - https://sketch.com -->
    <title>logo_vw_horiz_gray</title>
    <desc>Created with Sketch.</desc>
    <g id="Styles" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Desktop-Copy" transform="translate(-944.000000, -314.000000)">
            <g id="logo_vw_horiz_gray" transform="translate(941.000000, 314.000000)">
                <rect id="framework" x="0" y="0" width="175" height="30"></rect>
                <path d="M49.488,22 L46.59,22 L42.252,10.12 L44.88,10.12 L47.382,17.68 L48.066,20.02 L48.732,17.698 L51.252,10.12 L53.808,10.12 L49.488,22 Z M58.524,12.82 C59.9760073,12.82 61.106996,13.2339959 61.917,14.062 C62.7270041,14.8900041 63.132,16.0359927 63.132,17.5 C63.132,18.9640073 62.7270041,20.1099959 61.917,20.938 C61.106996,21.7660041 59.9760073,22.18 58.524,22.18 C57.0719927,22.18 55.9410041,21.7660041 55.131,20.938 C54.320996,20.1099959 53.916,18.9640073 53.916,17.5 C53.916,16.0359927 54.320996,14.8900041 55.131,14.062 C55.9410041,13.2339959 57.0719927,12.82 58.524,12.82 Z M58.524,14.656 C57.8279965,14.656 57.2970018,14.8929976 56.931,15.367 C56.5649982,15.8410024 56.382,16.5519953 56.382,17.5 C56.382,18.4480047 56.5649982,19.1589976 56.931,19.633 C57.2970018,20.1070024 57.8279965,20.344 58.524,20.344 C59.2200035,20.344 59.7509982,20.1070024 60.117,19.633 C60.4830018,19.1589976 60.666,18.4480047 60.666,17.5 C60.666,16.5519953 60.4830018,15.8410024 60.117,15.367 C59.7509982,14.8929976 59.2200035,14.656 58.524,14.656 Z M79.368,13 L76.506,22 L73.644,22 L71.682,15.646 L69.792,22 L66.948,22 L64.086,13 L66.696,13 L68.496,20.02 L70.512,13 L72.942,13 L74.958,20.02 L76.758,13 L79.368,13 Z M86.316,12.82 C87.516006,12.82 88.4579966,13.2309959 89.142,14.053 C89.8260034,14.8750041 90.168,16.0179927 90.168,17.482 C90.168,18.9580074 89.8260034,20.1099959 89.142,20.938 C88.4579966,21.7660041 87.516006,22.18 86.316,22.18 C85.6679968,22.18 85.1040024,22.0330015 84.624,21.739 C84.1439976,21.4449985 83.7660014,21.0400026 83.49,20.524 L83.49,25.78 L81.024,25.78 L81.024,13 L83.202,13 L83.292,14.782 C83.5560013,14.181997 83.9489974,13.7050018 84.471,13.351 C84.9930026,12.9969982 85.6079965,12.82 86.316,12.82 Z M85.578,20.29 C86.2500034,20.29 86.7719981,20.0500024 87.144,19.57 C87.5160019,19.0899976 87.702,18.4000045 87.702,17.5 C87.702,16.5999955 87.5160019,15.9100024 87.144,15.43 C86.7719981,14.9499976 86.2500034,14.71 85.578,14.71 C84.977997,14.71 84.4920019,14.9169979 84.12,15.331 C83.7479981,15.7450021 83.5380002,16.3359962 83.49,17.104 L83.49,17.896 C83.5380002,18.6520038 83.7479981,19.2399979 84.12,19.66 C84.4920019,20.0800021 84.977997,20.29 85.578,20.29 Z M100.518,20.506 C100.770001,20.506 100.973999,20.4820002 101.13,20.434 L100.95,21.928 C100.613998,22.0960008 100.224002,22.18 99.78,22.18 C98.6279942,22.18 97.9380011,21.7300045 97.71,20.83 C97.4459987,21.2740022 97.0380028,21.6099989 96.486,21.838 C95.9339972,22.0660011 95.2800038,22.18 94.524,22.18 C93.6479956,22.18 92.9640025,21.982002 92.472,21.586 C91.9799975,21.189998 91.734,20.6200037 91.734,19.876 C91.734,18.4119927 92.9039883,17.4640022 95.244,17.032 L97.404,16.618 L97.404,16.186 C97.404,15.7059976 97.2690014,15.3250014 96.999,15.043 C96.7289987,14.7609986 96.3540024,14.62 95.874,14.62 C95.3219972,14.62 94.8720017,14.7399988 94.524,14.98 C94.1759983,15.2200012 93.9360007,15.6099973 93.804,16.15 L91.842,15.322 C92.034001,14.5419961 92.4659966,13.9300022 93.138,13.486 C93.8100034,13.0419978 94.6859946,12.82 95.766,12.82 C97.0500064,12.82 98.0519964,13.0989972 98.772,13.657 C99.4920036,14.2150028 99.852,15.0399945 99.852,16.132 L99.852,19.822 C99.852,20.0620012 99.9059995,20.2359995 100.014,20.344 C100.122001,20.4520005 100.289999,20.506 100.518,20.506 Z M95.298,20.506 C95.8260026,20.506 96.3089978,20.3770013 96.747,20.119 C97.1850022,19.8609987 97.404,19.5100022 97.404,19.066 L97.404,18.13 L95.478,18.562 C95.069998,18.6580005 94.767001,18.7869992 94.569,18.949 C94.370999,19.1110008 94.272,19.3359986 94.272,19.624 C94.272,19.9120014 94.3619991,20.1309992 94.542,20.281 C94.7220009,20.4310007 94.9739984,20.506 95.298,20.506 Z M105.054,19.138 C105.054,19.5700022 105.116999,19.8699992 105.243,20.038 C105.369001,20.2060008 105.599998,20.29 105.936,20.29 C106.140001,20.29 106.316999,20.2750001 106.467,20.245 C106.617001,20.2149998 106.793999,20.1640004 106.998,20.092 L106.782,21.802 C106.589999,21.9220006 106.338002,22.0149997 106.026,22.081 C105.713998,22.1470003 105.408002,22.18 105.108,22.18 C104.231996,22.18 103.593002,21.9670021 103.191,21.541 C102.788998,21.1149979 102.588,20.4340047 102.588,19.498 L102.588,9.058 L105.054,9.058 L105.054,19.138 Z M118.482,22 L115.62,22 L112.164,10.12 L114.846,10.12 L117.15,20.038 L119.526,10.12 L121.902,10.12 L124.314,20.038 L126.618,10.12 L129.174,10.12 L125.718,22 L122.928,22 L121.272,15.52 L120.714,12.712 L120.678,12.712 L120.12,15.52 L118.482,22 Z M138.336,20.506 C138.588001,20.506 138.791999,20.4820002 138.948,20.434 L138.768,21.928 C138.431998,22.0960008 138.042002,22.18 137.598,22.18 C136.445994,22.18 135.756001,21.7300045 135.528,20.83 C135.263999,21.2740022 134.856003,21.6099989 134.304,21.838 C133.751997,22.0660011 133.098004,22.18 132.342,22.18 C131.465996,22.18 130.782002,21.982002 130.29,21.586 C129.797998,21.189998 129.552,20.6200037 129.552,19.876 C129.552,18.4119927 130.721988,17.4640022 133.062,17.032 L135.222,16.618 L135.222,16.186 C135.222,15.7059976 135.087001,15.3250014 134.817,15.043 C134.546999,14.7609986 134.172002,14.62 133.692,14.62 C133.139997,14.62 132.690002,14.7399988 132.342,14.98 C131.993998,15.2200012 131.754001,15.6099973 131.622,16.15 L129.66,15.322 C129.852001,14.5419961 130.283997,13.9300022 130.956,13.486 C131.628003,13.0419978 132.503995,12.82 133.584,12.82 C134.868006,12.82 135.869996,13.0989972 136.59,13.657 C137.310004,14.2150028 137.67,15.0399945 137.67,16.132 L137.67,19.822 C137.67,20.0620012 137.723999,20.2359995 137.832,20.344 C137.940001,20.4520005 138.107999,20.506 138.336,20.506 Z M133.116,20.506 C133.644003,20.506 134.126998,20.3770013 134.565,20.119 C135.003002,19.8609987 135.222,19.5100022 135.222,19.066 L135.222,18.13 L133.296,18.562 C132.887998,18.6580005 132.585001,18.7869992 132.387,18.949 C132.188999,19.1110008 132.09,19.3359986 132.09,19.624 C132.09,19.9120014 132.179999,20.1309992 132.36,20.281 C132.540001,20.4310007 132.791998,20.506 133.116,20.506 Z M145.734,12.82 C146.934006,12.82 147.875997,13.2339959 148.56,14.062 C149.244003,14.8900041 149.586,16.0419926 149.586,17.518 C149.586,18.9820073 149.244003,20.1249959 148.56,20.947 C147.875997,21.7690041 146.934006,22.18 145.734,22.18 C145.025996,22.18 144.411003,22.0030018 143.889,21.649 C143.366997,21.2949982 142.974001,20.818003 142.71,20.218 L142.62,22 L140.442,22 L140.442,9.058 L142.908,9.058 L142.908,14.476 C143.184001,13.9599974 143.561998,13.5550015 144.042,13.261 C144.522002,12.9669985 145.085997,12.82 145.734,12.82 Z M144.996,20.29 C145.668003,20.29 146.189998,20.0500024 146.562,19.57 C146.934002,19.0899976 147.12,18.4000045 147.12,17.5 C147.12,16.5999955 146.934002,15.9100024 146.562,15.43 C146.189998,14.9499976 145.668003,14.71 144.996,14.71 C144.395997,14.71 143.910002,14.9199979 143.538,15.34 C143.165998,15.7600021 142.956,16.3479962 142.908,17.104 L142.908,17.896 C142.956,18.6640038 143.165998,19.2549979 143.538,19.669 C143.910002,20.0830021 144.395997,20.29 144.996,20.29 Z M157.056,12.82 C158.256006,12.82 159.197997,13.2339959 159.882,14.062 C160.566003,14.8900041 160.908,16.0419926 160.908,17.518 C160.908,18.9820073 160.566003,20.1249959 159.882,20.947 C159.197997,21.7690041 158.256006,22.18 157.056,22.18 C156.347996,22.18 155.733003,22.0030018 155.211,21.649 C154.688997,21.2949982 154.296001,20.818003 154.032,20.218 L153.942,22 L151.764,22 L151.764,9.058 L154.23,9.058 L154.23,14.476 C154.506001,13.9599974 154.883998,13.5550015 155.364,13.261 C155.844002,12.9669985 156.407997,12.82 157.056,12.82 Z M156.318,20.29 C156.990003,20.29 157.511998,20.0500024 157.884,19.57 C158.256002,19.0899976 158.442,18.4000045 158.442,17.5 C158.442,16.5999955 158.256002,15.9100024 157.884,15.43 C157.511998,14.9499976 156.990003,14.71 156.318,14.71 C155.717997,14.71 155.232002,14.9199979 154.86,15.34 C154.487998,15.7600021 154.278,16.3479962 154.23,17.104 L154.23,17.896 C154.278,18.6640038 154.487998,19.2549979 154.86,19.669 C155.232002,20.0830021 155.717997,20.29 156.318,20.29 Z M164.328,11.704 C163.307995,11.704 162.798,11.2660044 162.798,10.39 C162.798,9.50199556 163.307995,9.058 164.328,9.058 C165.348005,9.058 165.858,9.50199556 165.858,10.39 C165.858,11.2660044 165.348005,11.704 164.328,11.704 Z M165.552,22 L163.086,22 L163.086,13 L165.552,13 L165.552,22 Z M174.336,21.442 C174.047999,21.6700011 173.685002,21.8499993 173.247,21.982 C172.808998,22.1140007 172.350002,22.18 171.87,22.18 C169.86599,22.18 168.864,21.2740091 168.864,19.462 L168.864,14.836 L167.226,14.836 L167.226,13 L168.864,13 L168.864,10.93 L171.33,10.246 L171.33,13 L174.246,13 L174.246,14.836 L171.33,14.836 L171.33,19.066 C171.33,19.8940041 171.743996,20.308 172.572,20.308 C173.100003,20.308 173.561998,20.1400017 173.958,19.804 L174.336,21.442 Z" id="VowpalWabbit" fill="#333333" fill-rule="nonzero"></path>
                <g id="logo_vw_color" transform="translate(3.000000, 0.000000)" fill="#2A3B93">
                    <path d="M27.9875518,16.6117194 C27.9875518,9.21947752 21.9666728,9.36035971 21.9666728,9.36035971 C21.3736977,6.15536974 20.3362508,3.5963294 19.3414955,1.96947553 C18.1790857,0.436543115 17.3241355,0 17.3241355,0 C16.2887633,0.700737156 15.7766231,3.93943024 15.7766231,3.93943024 C14.1726939,1.18184505 12.329851,1.05294263 12.329851,1.05294263 C9.93824094,8.37466357 17.0427696,11.1203489 17.0427696,11.1203489 C9.97542657,11.1203489 6.33307087,15.0400524 4.59284756,17.9877167 C4.0042614,19.0524794 3.60319929,20.0302689 3.35048069,20.7371557 L2.99801525,21.8605394 C1.89952322,21.2108361 0.011355398,21.1878349 0.011355398,21.1878349 C-0.278708419,29.2136474 5.0845596,28.0167877 5.0845596,28.0167877 C5.0845596,29.1432063 6.56177043,30 6.56177043,30 L18.0978518,30 C18.0978518,30 17.9248509,28.5478912 16.7183131,27.7616983 C16.5196972,27.4693917 16.4533057,27.212705 16.6897456,26.9422016 C17.354698,26.1816454 17.8296525,27.1798804 17.8296525,27.1798804 L18.3302221,27.8553801 C19.7539686,29.627988 20.7440159,29.9516816 21.1646284,30 L21.391732,30 C20.5763614,27.5009384 20.6054875,25.3190215 20.6054875,25.3190215 C20.4822802,22.1365535 22.8107704,19.2166024 22.8107704,19.2166024 C28.5084697,19.2166024 27.9875518,16.6117194 27.9875518,16.6117194" id="logo_rabbit"></path>
                </g>
            </g>
        </g>
    </g>
</svg>
      </a>
    </div>

    <div class="nav">
      <a href="https://vowpalwabbit.org/start.html">
        Get started
      </a>
      <a href="https://vowpalwabbit.org/features.html">
        Features
      </a>
      <a href="https://vowpalwabbit.org/tutorials.html">
        Tutorials
      </a>
      <a href="https://vowpalwabbit.org/blog.html">
        Blog
      </a>
      <a href="https://vowpalwabbit.org/research.html">
        Research
      </a>
      <div class="external_links">
        <a class="active" href="index.html">
          Doc
        </a>

        <a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki" target="_blank">
          Wiki
        </a>

        <a href="https://github.com/VowpalWabbit/vowpal_wabbit" target="_blank" class="github_link">
          <?xml version="1.0" encoding="UTF-8"?>
<svg width="30px" height="30px" viewBox="0 0 30 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 53 (72520) - https://sketchapp.com -->
    <title>GitHub</title>
    <desc>Created with Sketch.</desc>
    <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="HD_Desktop_header_Home" transform="translate(-1538.000000, -58.000000)" fill="#FFFFFF">
            <g id="Header">
                <path d="M1568,73.7951128 C1567.94603,74.2583723 1567.89891,74.7224863 1567.83682,75.1847206 C1567.56271,77.2238487 1566.86543,79.1138828 1565.7732,80.8526868 C1564.55268,82.7956941 1562.9969,84.4188114 1561.05088,85.6538569 C1560.03339,86.2996179 1558.94817,86.8066231 1557.80753,87.1895684 C1557.17559,87.4016322 1556.73848,87.0743943 1556.73531,86.4093237 C1556.72907,85.1020808 1556.73745,83.7947524 1556.73164,82.487424 C1556.72804,81.6908602 1556.64825,80.9063436 1556.21259,80.2087201 C1556.0855,80.0052003 1555.92463,79.8226135 1555.77393,79.6234512 C1556.35935,79.5140871 1556.9463,79.4362506 1557.51632,79.2916849 C1559.04696,78.9034423 1560.41543,78.2275208 1561.34791,76.8924242 C1562.03287,75.9115647 1562.34632,74.7851144 1562.48436,73.6108172 C1562.59169,72.6982249 1562.62222,71.7826422 1562.42971,70.8740656 C1562.23608,69.9599354 1561.84044,69.1418405 1561.22834,68.4359293 C1561.07756,68.2620575 1561.04763,68.1215929 1561.12221,67.896713 C1561.52468,66.6818314 1561.3562,65.491984 1560.9042,64.3262309 C1560.87829,64.2595017 1560.76574,64.1973008 1560.68569,64.1853391 C1560.15364,64.1058793 1559.65196,64.2559986 1559.18533,64.4761793 C1558.42904,64.8332361 1557.69764,65.242668 1556.9487,65.6159585 C1556.82229,65.6790137 1556.64782,65.7219904 1556.51706,65.6889249 C1554.16941,65.0964789 1551.82595,65.097077 1549.47805,65.6883268 C1549.34078,65.7228448 1549.14638,65.677134 1549.02331,65.5987849 C1548.07109,64.9919849 1547.06446,64.5120644 1545.97001,64.2236166 C1545.9511,64.218661 1545.93272,64.2115694 1545.91364,64.2077246 C1545.22551,64.0670892 1545.09971,64.1456947 1544.9036,64.8108506 C1544.58682,65.884755 1544.5296,66.9550708 1544.90668,68.0296587 C1544.93627,68.1139033 1544.90129,68.2616303 1544.8404,68.3306664 C1543.60397,69.7341156 1543.31096,71.3989279 1543.46559,73.1936101 C1543.55933,74.2817831 1543.81162,75.3262104 1544.29869,76.3083514 C1544.97176,77.6654063 1546.11181,78.4952066 1547.4926,78.982475 C1548.35956,79.2884382 1549.27852,79.4473579 1550.18824,79.6758264 C1550.19526,79.6319098 1550.20056,79.6666842 1550.18568,79.6820635 C1549.71726,80.1697591 1549.45556,80.755028 1549.34531,81.4170227 C1549.33137,81.5007546 1549.27365,81.6203716 1549.20685,81.6454912 C1548.16482,82.0372369 1547.11706,82.2433199 1546.08683,81.6149888 C1545.61867,81.3295314 1545.27683,80.9169382 1545.00101,80.4479541 C1544.56852,79.712395 1543.95864,79.179074 1543.13923,78.9361661 C1542.84434,78.8487602 1542.50823,78.8709748 1542.19359,78.8892591 C1541.97909,78.9018189 1541.90862,79.062362 1542.05256,79.2422147 C1542.18529,79.4077988 1542.32025,79.5950849 1542.4978,79.6971865 C1543.28625,80.1507913 1543.72798,80.8753286 1544.08881,81.6641173 C1544.30382,82.1341266 1544.48812,82.6140471 1544.88675,82.9753759 C1545.52169,83.5510755 1546.29115,83.7682658 1547.11612,83.8044072 C1547.81434,83.834995 1548.51496,83.8107298 1549.24722,83.8107298 C1549.24611,83.8009041 1549.26073,83.8742123 1549.26167,83.9476058 C1549.27211,84.7377616 1549.2828,85.5279173 1549.28844,86.3180731 C1549.294,87.0913115 1548.82935,87.4109452 1548.0952,87.1563319 C1544.28705,85.8355039 1541.4928,83.3342269 1539.62819,79.7992882 C1538.22405,77.1372118 1537.78027,74.2780237 1538.09739,71.2935795 C1538.4294,68.1688416 1539.66702,65.4337134 1541.73193,63.0872551 C1543.89022,60.6347648 1546.57714,59.0045559 1549.78825,58.3523869 C1554.45335,57.4048494 1558.71409,58.3562318 1562.44442,61.3515269 C1565.27245,63.6222848 1567.02271,66.5767393 1567.72914,70.1361141 C1567.83314,70.6605492 1567.87265,71.197715 1567.94398,71.7286436 C1567.95792,71.832625 1567.9811,71.9354102 1568,72.0387934 L1568,73.7951128 Z" id="GitHub"></path>
            </g>
        </g>
    </g>
</svg>
          <div>
            GitHub
          </div>
        </a>
      </div>
    </div>
  </div>
</div>
    <div class="navbar_container mobile_nav_container">
  <div class="container nav_wrapper">
    <div class="hamburger_icon">
      <?xml version="1.0" encoding="UTF-8"?>
<svg width="18px" height="16px" viewBox="0 0 18 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: sketchtool 57.1 (101010) - https://sketch.com -->
    <title>8049A6A1-2687-43E9-9B5D-E205E8F9E871</title>
    <desc>Created with sketchtool.</desc>
    <g id="Pages" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd" stroke-linecap="round">
        <g id="Mobile_home" transform="translate(-12.000000, -56.000000)" stroke="#FFFFFF" stroke-width="2">
            <g id="header">
                <g id="ui_header_mobile_dk" transform="translate(12.000000, 44.000000)">
                    <g id="icon_menu" transform="translate(1.000000, 12.500000)">
                        <g id="Line">
                            <path d="M16,0.5 L0,0.5"></path>
                            <path d="M16,7.5 L0,7.5"></path>
                            <path d="M16,14.5 L0,14.5"></path>
                        </g>
                    </g>
                </g>
            </g>
        </g>
    </g>
</svg>
    </div>
    <div class="logo">
      <a href="https://vowpalwabbit.org/index.html">
        <?xml version="1.0" encoding="UTF-8"?>
<svg width="172px" height="30px" viewBox="0 0 172 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 57.1 (83088) - https://sketch.com -->
    <title>logo_vw_horiz_gray</title>
    <desc>Created with Sketch.</desc>
    <g id="Styles" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Desktop-Copy" transform="translate(-944.000000, -314.000000)">
            <g id="logo_vw_horiz_gray" transform="translate(941.000000, 314.000000)">
                <rect id="framework" x="0" y="0" width="175" height="30"></rect>
                <path d="M49.488,22 L46.59,22 L42.252,10.12 L44.88,10.12 L47.382,17.68 L48.066,20.02 L48.732,17.698 L51.252,10.12 L53.808,10.12 L49.488,22 Z M58.524,12.82 C59.9760073,12.82 61.106996,13.2339959 61.917,14.062 C62.7270041,14.8900041 63.132,16.0359927 63.132,17.5 C63.132,18.9640073 62.7270041,20.1099959 61.917,20.938 C61.106996,21.7660041 59.9760073,22.18 58.524,22.18 C57.0719927,22.18 55.9410041,21.7660041 55.131,20.938 C54.320996,20.1099959 53.916,18.9640073 53.916,17.5 C53.916,16.0359927 54.320996,14.8900041 55.131,14.062 C55.9410041,13.2339959 57.0719927,12.82 58.524,12.82 Z M58.524,14.656 C57.8279965,14.656 57.2970018,14.8929976 56.931,15.367 C56.5649982,15.8410024 56.382,16.5519953 56.382,17.5 C56.382,18.4480047 56.5649982,19.1589976 56.931,19.633 C57.2970018,20.1070024 57.8279965,20.344 58.524,20.344 C59.2200035,20.344 59.7509982,20.1070024 60.117,19.633 C60.4830018,19.1589976 60.666,18.4480047 60.666,17.5 C60.666,16.5519953 60.4830018,15.8410024 60.117,15.367 C59.7509982,14.8929976 59.2200035,14.656 58.524,14.656 Z M79.368,13 L76.506,22 L73.644,22 L71.682,15.646 L69.792,22 L66.948,22 L64.086,13 L66.696,13 L68.496,20.02 L70.512,13 L72.942,13 L74.958,20.02 L76.758,13 L79.368,13 Z M86.316,12.82 C87.516006,12.82 88.4579966,13.2309959 89.142,14.053 C89.8260034,14.8750041 90.168,16.0179927 90.168,17.482 C90.168,18.9580074 89.8260034,20.1099959 89.142,20.938 C88.4579966,21.7660041 87.516006,22.18 86.316,22.18 C85.6679968,22.18 85.1040024,22.0330015 84.624,21.739 C84.1439976,21.4449985 83.7660014,21.0400026 83.49,20.524 L83.49,25.78 L81.024,25.78 L81.024,13 L83.202,13 L83.292,14.782 C83.5560013,14.181997 83.9489974,13.7050018 84.471,13.351 C84.9930026,12.9969982 85.6079965,12.82 86.316,12.82 Z M85.578,20.29 C86.2500034,20.29 86.7719981,20.0500024 87.144,19.57 C87.5160019,19.0899976 87.702,18.4000045 87.702,17.5 C87.702,16.5999955 87.5160019,15.9100024 87.144,15.43 C86.7719981,14.9499976 86.2500034,14.71 85.578,14.71 C84.977997,14.71 84.4920019,14.9169979 84.12,15.331 C83.7479981,15.7450021 83.5380002,16.3359962 83.49,17.104 L83.49,17.896 C83.5380002,18.6520038 83.7479981,19.2399979 84.12,19.66 C84.4920019,20.0800021 84.977997,20.29 85.578,20.29 Z M100.518,20.506 C100.770001,20.506 100.973999,20.4820002 101.13,20.434 L100.95,21.928 C100.613998,22.0960008 100.224002,22.18 99.78,22.18 C98.6279942,22.18 97.9380011,21.7300045 97.71,20.83 C97.4459987,21.2740022 97.0380028,21.6099989 96.486,21.838 C95.9339972,22.0660011 95.2800038,22.18 94.524,22.18 C93.6479956,22.18 92.9640025,21.982002 92.472,21.586 C91.9799975,21.189998 91.734,20.6200037 91.734,19.876 C91.734,18.4119927 92.9039883,17.4640022 95.244,17.032 L97.404,16.618 L97.404,16.186 C97.404,15.7059976 97.2690014,15.3250014 96.999,15.043 C96.7289987,14.7609986 96.3540024,14.62 95.874,14.62 C95.3219972,14.62 94.8720017,14.7399988 94.524,14.98 C94.1759983,15.2200012 93.9360007,15.6099973 93.804,16.15 L91.842,15.322 C92.034001,14.5419961 92.4659966,13.9300022 93.138,13.486 C93.8100034,13.0419978 94.6859946,12.82 95.766,12.82 C97.0500064,12.82 98.0519964,13.0989972 98.772,13.657 C99.4920036,14.2150028 99.852,15.0399945 99.852,16.132 L99.852,19.822 C99.852,20.0620012 99.9059995,20.2359995 100.014,20.344 C100.122001,20.4520005 100.289999,20.506 100.518,20.506 Z M95.298,20.506 C95.8260026,20.506 96.3089978,20.3770013 96.747,20.119 C97.1850022,19.8609987 97.404,19.5100022 97.404,19.066 L97.404,18.13 L95.478,18.562 C95.069998,18.6580005 94.767001,18.7869992 94.569,18.949 C94.370999,19.1110008 94.272,19.3359986 94.272,19.624 C94.272,19.9120014 94.3619991,20.1309992 94.542,20.281 C94.7220009,20.4310007 94.9739984,20.506 95.298,20.506 Z M105.054,19.138 C105.054,19.5700022 105.116999,19.8699992 105.243,20.038 C105.369001,20.2060008 105.599998,20.29 105.936,20.29 C106.140001,20.29 106.316999,20.2750001 106.467,20.245 C106.617001,20.2149998 106.793999,20.1640004 106.998,20.092 L106.782,21.802 C106.589999,21.9220006 106.338002,22.0149997 106.026,22.081 C105.713998,22.1470003 105.408002,22.18 105.108,22.18 C104.231996,22.18 103.593002,21.9670021 103.191,21.541 C102.788998,21.1149979 102.588,20.4340047 102.588,19.498 L102.588,9.058 L105.054,9.058 L105.054,19.138 Z M118.482,22 L115.62,22 L112.164,10.12 L114.846,10.12 L117.15,20.038 L119.526,10.12 L121.902,10.12 L124.314,20.038 L126.618,10.12 L129.174,10.12 L125.718,22 L122.928,22 L121.272,15.52 L120.714,12.712 L120.678,12.712 L120.12,15.52 L118.482,22 Z M138.336,20.506 C138.588001,20.506 138.791999,20.4820002 138.948,20.434 L138.768,21.928 C138.431998,22.0960008 138.042002,22.18 137.598,22.18 C136.445994,22.18 135.756001,21.7300045 135.528,20.83 C135.263999,21.2740022 134.856003,21.6099989 134.304,21.838 C133.751997,22.0660011 133.098004,22.18 132.342,22.18 C131.465996,22.18 130.782002,21.982002 130.29,21.586 C129.797998,21.189998 129.552,20.6200037 129.552,19.876 C129.552,18.4119927 130.721988,17.4640022 133.062,17.032 L135.222,16.618 L135.222,16.186 C135.222,15.7059976 135.087001,15.3250014 134.817,15.043 C134.546999,14.7609986 134.172002,14.62 133.692,14.62 C133.139997,14.62 132.690002,14.7399988 132.342,14.98 C131.993998,15.2200012 131.754001,15.6099973 131.622,16.15 L129.66,15.322 C129.852001,14.5419961 130.283997,13.9300022 130.956,13.486 C131.628003,13.0419978 132.503995,12.82 133.584,12.82 C134.868006,12.82 135.869996,13.0989972 136.59,13.657 C137.310004,14.2150028 137.67,15.0399945 137.67,16.132 L137.67,19.822 C137.67,20.0620012 137.723999,20.2359995 137.832,20.344 C137.940001,20.4520005 138.107999,20.506 138.336,20.506 Z M133.116,20.506 C133.644003,20.506 134.126998,20.3770013 134.565,20.119 C135.003002,19.8609987 135.222,19.5100022 135.222,19.066 L135.222,18.13 L133.296,18.562 C132.887998,18.6580005 132.585001,18.7869992 132.387,18.949 C132.188999,19.1110008 132.09,19.3359986 132.09,19.624 C132.09,19.9120014 132.179999,20.1309992 132.36,20.281 C132.540001,20.4310007 132.791998,20.506 133.116,20.506 Z M145.734,12.82 C146.934006,12.82 147.875997,13.2339959 148.56,14.062 C149.244003,14.8900041 149.586,16.0419926 149.586,17.518 C149.586,18.9820073 149.244003,20.1249959 148.56,20.947 C147.875997,21.7690041 146.934006,22.18 145.734,22.18 C145.025996,22.18 144.411003,22.0030018 143.889,21.649 C143.366997,21.2949982 142.974001,20.818003 142.71,20.218 L142.62,22 L140.442,22 L140.442,9.058 L142.908,9.058 L142.908,14.476 C143.184001,13.9599974 143.561998,13.5550015 144.042,13.261 C144.522002,12.9669985 145.085997,12.82 145.734,12.82 Z M144.996,20.29 C145.668003,20.29 146.189998,20.0500024 146.562,19.57 C146.934002,19.0899976 147.12,18.4000045 147.12,17.5 C147.12,16.5999955 146.934002,15.9100024 146.562,15.43 C146.189998,14.9499976 145.668003,14.71 144.996,14.71 C144.395997,14.71 143.910002,14.9199979 143.538,15.34 C143.165998,15.7600021 142.956,16.3479962 142.908,17.104 L142.908,17.896 C142.956,18.6640038 143.165998,19.2549979 143.538,19.669 C143.910002,20.0830021 144.395997,20.29 144.996,20.29 Z M157.056,12.82 C158.256006,12.82 159.197997,13.2339959 159.882,14.062 C160.566003,14.8900041 160.908,16.0419926 160.908,17.518 C160.908,18.9820073 160.566003,20.1249959 159.882,20.947 C159.197997,21.7690041 158.256006,22.18 157.056,22.18 C156.347996,22.18 155.733003,22.0030018 155.211,21.649 C154.688997,21.2949982 154.296001,20.818003 154.032,20.218 L153.942,22 L151.764,22 L151.764,9.058 L154.23,9.058 L154.23,14.476 C154.506001,13.9599974 154.883998,13.5550015 155.364,13.261 C155.844002,12.9669985 156.407997,12.82 157.056,12.82 Z M156.318,20.29 C156.990003,20.29 157.511998,20.0500024 157.884,19.57 C158.256002,19.0899976 158.442,18.4000045 158.442,17.5 C158.442,16.5999955 158.256002,15.9100024 157.884,15.43 C157.511998,14.9499976 156.990003,14.71 156.318,14.71 C155.717997,14.71 155.232002,14.9199979 154.86,15.34 C154.487998,15.7600021 154.278,16.3479962 154.23,17.104 L154.23,17.896 C154.278,18.6640038 154.487998,19.2549979 154.86,19.669 C155.232002,20.0830021 155.717997,20.29 156.318,20.29 Z M164.328,11.704 C163.307995,11.704 162.798,11.2660044 162.798,10.39 C162.798,9.50199556 163.307995,9.058 164.328,9.058 C165.348005,9.058 165.858,9.50199556 165.858,10.39 C165.858,11.2660044 165.348005,11.704 164.328,11.704 Z M165.552,22 L163.086,22 L163.086,13 L165.552,13 L165.552,22 Z M174.336,21.442 C174.047999,21.6700011 173.685002,21.8499993 173.247,21.982 C172.808998,22.1140007 172.350002,22.18 171.87,22.18 C169.86599,22.18 168.864,21.2740091 168.864,19.462 L168.864,14.836 L167.226,14.836 L167.226,13 L168.864,13 L168.864,10.93 L171.33,10.246 L171.33,13 L174.246,13 L174.246,14.836 L171.33,14.836 L171.33,19.066 C171.33,19.8940041 171.743996,20.308 172.572,20.308 C173.100003,20.308 173.561998,20.1400017 173.958,19.804 L174.336,21.442 Z" id="VowpalWabbit" fill="#333333" fill-rule="nonzero"></path>
                <g id="logo_vw_color" transform="translate(3.000000, 0.000000)" fill="#2A3B93">
                    <path d="M27.9875518,16.6117194 C27.9875518,9.21947752 21.9666728,9.36035971 21.9666728,9.36035971 C21.3736977,6.15536974 20.3362508,3.5963294 19.3414955,1.96947553 C18.1790857,0.436543115 17.3241355,0 17.3241355,0 C16.2887633,0.700737156 15.7766231,3.93943024 15.7766231,3.93943024 C14.1726939,1.18184505 12.329851,1.05294263 12.329851,1.05294263 C9.93824094,8.37466357 17.0427696,11.1203489 17.0427696,11.1203489 C9.97542657,11.1203489 6.33307087,15.0400524 4.59284756,17.9877167 C4.0042614,19.0524794 3.60319929,20.0302689 3.35048069,20.7371557 L2.99801525,21.8605394 C1.89952322,21.2108361 0.011355398,21.1878349 0.011355398,21.1878349 C-0.278708419,29.2136474 5.0845596,28.0167877 5.0845596,28.0167877 C5.0845596,29.1432063 6.56177043,30 6.56177043,30 L18.0978518,30 C18.0978518,30 17.9248509,28.5478912 16.7183131,27.7616983 C16.5196972,27.4693917 16.4533057,27.212705 16.6897456,26.9422016 C17.354698,26.1816454 17.8296525,27.1798804 17.8296525,27.1798804 L18.3302221,27.8553801 C19.7539686,29.627988 20.7440159,29.9516816 21.1646284,30 L21.391732,30 C20.5763614,27.5009384 20.6054875,25.3190215 20.6054875,25.3190215 C20.4822802,22.1365535 22.8107704,19.2166024 22.8107704,19.2166024 C28.5084697,19.2166024 27.9875518,16.6117194 27.9875518,16.6117194" id="logo_rabbit"></path>
                </g>
            </g>
        </g>
    </g>
</svg>
      </a>
    </div>
  </div>
</div>

<div class="mobile_nav">
  <button type="button" class="go_back_button">
    <
  </button>

  <a href="https://vowpalwabbit.org/start.html">
    Get started
  </a>
  <a href="https://vowpalwabbit.org/features.html">
    Features
  </a>
  <a href="https://vowpalwabbit.org/tutorials.html">
    Tutorials
  </a>
  <a href="https://vowpalwabbit.org/blog.html">
    Blog
  </a>
  <a href="https://vowpalwabbit.org/research.html">
    Research
  </a>
  <div class="external_links">
    <a href="https://github.com/VowpalWabbit/vowpalwabbit.github.io/issues/new"
      target="_blank"
    >
      Feedback
    </a>

    <a class="active" href="index.html">
      Doc
    </a>

    <a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki" target="_blank">
      Wiki
    </a>

    <a href="https://github.com/VowpalWabbit/vowpal_wabbit" target="_blank" class="github_link">
      <?xml version="1.0" encoding="UTF-8"?>
<svg width="30px" height="30px" viewBox="0 0 30 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 53 (72520) - https://sketchapp.com -->
    <title>GitHub</title>
    <desc>Created with Sketch.</desc>
    <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="HD_Desktop_header_Home" transform="translate(-1538.000000, -58.000000)" fill="#FFFFFF">
            <g id="Header">
                <path d="M1568,73.7951128 C1567.94603,74.2583723 1567.89891,74.7224863 1567.83682,75.1847206 C1567.56271,77.2238487 1566.86543,79.1138828 1565.7732,80.8526868 C1564.55268,82.7956941 1562.9969,84.4188114 1561.05088,85.6538569 C1560.03339,86.2996179 1558.94817,86.8066231 1557.80753,87.1895684 C1557.17559,87.4016322 1556.73848,87.0743943 1556.73531,86.4093237 C1556.72907,85.1020808 1556.73745,83.7947524 1556.73164,82.487424 C1556.72804,81.6908602 1556.64825,80.9063436 1556.21259,80.2087201 C1556.0855,80.0052003 1555.92463,79.8226135 1555.77393,79.6234512 C1556.35935,79.5140871 1556.9463,79.4362506 1557.51632,79.2916849 C1559.04696,78.9034423 1560.41543,78.2275208 1561.34791,76.8924242 C1562.03287,75.9115647 1562.34632,74.7851144 1562.48436,73.6108172 C1562.59169,72.6982249 1562.62222,71.7826422 1562.42971,70.8740656 C1562.23608,69.9599354 1561.84044,69.1418405 1561.22834,68.4359293 C1561.07756,68.2620575 1561.04763,68.1215929 1561.12221,67.896713 C1561.52468,66.6818314 1561.3562,65.491984 1560.9042,64.3262309 C1560.87829,64.2595017 1560.76574,64.1973008 1560.68569,64.1853391 C1560.15364,64.1058793 1559.65196,64.2559986 1559.18533,64.4761793 C1558.42904,64.8332361 1557.69764,65.242668 1556.9487,65.6159585 C1556.82229,65.6790137 1556.64782,65.7219904 1556.51706,65.6889249 C1554.16941,65.0964789 1551.82595,65.097077 1549.47805,65.6883268 C1549.34078,65.7228448 1549.14638,65.677134 1549.02331,65.5987849 C1548.07109,64.9919849 1547.06446,64.5120644 1545.97001,64.2236166 C1545.9511,64.218661 1545.93272,64.2115694 1545.91364,64.2077246 C1545.22551,64.0670892 1545.09971,64.1456947 1544.9036,64.8108506 C1544.58682,65.884755 1544.5296,66.9550708 1544.90668,68.0296587 C1544.93627,68.1139033 1544.90129,68.2616303 1544.8404,68.3306664 C1543.60397,69.7341156 1543.31096,71.3989279 1543.46559,73.1936101 C1543.55933,74.2817831 1543.81162,75.3262104 1544.29869,76.3083514 C1544.97176,77.6654063 1546.11181,78.4952066 1547.4926,78.982475 C1548.35956,79.2884382 1549.27852,79.4473579 1550.18824,79.6758264 C1550.19526,79.6319098 1550.20056,79.6666842 1550.18568,79.6820635 C1549.71726,80.1697591 1549.45556,80.755028 1549.34531,81.4170227 C1549.33137,81.5007546 1549.27365,81.6203716 1549.20685,81.6454912 C1548.16482,82.0372369 1547.11706,82.2433199 1546.08683,81.6149888 C1545.61867,81.3295314 1545.27683,80.9169382 1545.00101,80.4479541 C1544.56852,79.712395 1543.95864,79.179074 1543.13923,78.9361661 C1542.84434,78.8487602 1542.50823,78.8709748 1542.19359,78.8892591 C1541.97909,78.9018189 1541.90862,79.062362 1542.05256,79.2422147 C1542.18529,79.4077988 1542.32025,79.5950849 1542.4978,79.6971865 C1543.28625,80.1507913 1543.72798,80.8753286 1544.08881,81.6641173 C1544.30382,82.1341266 1544.48812,82.6140471 1544.88675,82.9753759 C1545.52169,83.5510755 1546.29115,83.7682658 1547.11612,83.8044072 C1547.81434,83.834995 1548.51496,83.8107298 1549.24722,83.8107298 C1549.24611,83.8009041 1549.26073,83.8742123 1549.26167,83.9476058 C1549.27211,84.7377616 1549.2828,85.5279173 1549.28844,86.3180731 C1549.294,87.0913115 1548.82935,87.4109452 1548.0952,87.1563319 C1544.28705,85.8355039 1541.4928,83.3342269 1539.62819,79.7992882 C1538.22405,77.1372118 1537.78027,74.2780237 1538.09739,71.2935795 C1538.4294,68.1688416 1539.66702,65.4337134 1541.73193,63.0872551 C1543.89022,60.6347648 1546.57714,59.0045559 1549.78825,58.3523869 C1554.45335,57.4048494 1558.71409,58.3562318 1562.44442,61.3515269 C1565.27245,63.6222848 1567.02271,66.5767393 1567.72914,70.1361141 C1567.83314,70.6605492 1567.87265,71.197715 1567.94398,71.7286436 C1567.95792,71.832625 1567.9811,71.9354102 1568,72.0387934 L1568,73.7951128 Z" id="GitHub"></path>
            </g>
        </g>
    </g>
</svg>

      <div>
        GitHub
      </div>
    </a>
  </div>
</div>

<script script type="text/javascript">
  $(".mobile_nav_container").on("click", ".hamburger_icon", (e) => {
    e.stopPropagation();
    $(".mobile_nav").addClass("open");
  });

  $('body').on("click", ".mobile_nav .go_back_button", () => {
    $(".mobile_nav").removeClass("open");
  });
</script>


    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><a href="https://vowpalwabbit.org/docs/">
  latest
</a>

<i class="fas fa-angle-down"></i>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Tutorials
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="cmd_first_steps.html">
     Command line tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cmd_linear_regression.html">
     Linear Regression Tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="off_policy_evaluation.html">
     Offline policy evaluation using the VW command line
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Simulating a smart thermostat using CATS: a Contextual Bandit algorithm with a continuous action space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_classification.html">
     Classification with Vowpal Wabbit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_Contextual_bandits_and_Vowpal_Wabbit.html">
     Contextual bandits and Vowpal Wabbit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_Simulating_a_news_personalization_scenario_using_Contextual_Bandits.html">
     Simulating a news personalization scenario using Contextual Bandits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_first_steps.html">
     Basics with Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_slates.html">
     Slates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DFtoVW_tutorial.html">
     Using DFtoVW and exploring VW output
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../examples/index.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/basics.html">
     Python Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/contextual_bandit.html">
     Contextual Bandits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/mini_vw.html">
     Mini VW
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/poisson_regression.html">
     Poisson Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/predict.html">
     Predict comparison
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/search_covington.html">
     Search - Covington
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/search_sequence_ldf.html">
     Search - Sequence LDF
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/search_sequence.html">
     Search - Sequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/search_speech_tagger.html">
     Search - Speech Tagger
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../reference/index.html">
   API Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/vowpalwabbit.pyvw.html">
     vowpalwabbit.pyvw
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/vowpalwabbit.sklearn.html">
     vowpalwabbit.sklearn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/vowpalwabbit.DFtoVW.html">
     vowpalwabbit.DFtoVW
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/vowpalwabbit.pyvw.pylibvw.html">
     vowpalwabbit.pyvw.pylibvw
    </a>
   </li>
  </ul>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-reward">
   Simulate reward
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#getting-a-decision">
   Getting a decision
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulation-set-up">
   Simulation set up
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scenario-1">
   Scenario 1
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#with-learning">
     With Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#without-learning">
     Without Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameter-sweep">
   Parameter sweep
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     With Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Without Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scenario-2">
   Scenario 2
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#living-room">
     Living Room
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bedroom">
     Bedroom
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     With Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Without Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scenario-3">
   Scenario 3
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#better-cost-function">
     Better cost function
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                

<div class="tocsection editthispage">
    <a href="https://github.com/VowpalWabbit/vowpal_wabbit/edit/master/python/docs/source/tutorials/python_cats.ipynb">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
    
    
    <button title="Activate interactive cells" class="thebelab-button thebe-launch-button" onclick="initThebe()">
        Make live
    </button>
    <a class="binder-button" href="https://mybinder.org/v2/gh/VowpalWabbit/vowpal_wabbit/master?filepath=python/docs/source/tutorials/python_cats.ipynb">
        <img class="binder-button-logo" src="https://mybinder.org/badge_logo.svg" alt="Binder">
    </a>
    

              <div>
                
  <div class="section" id="simulating-a-smart-thermostat-using-cats-a-contextual-bandit-algorithm-with-a-continuous-action-space">
<h1>Simulating a smart thermostat using CATS: a Contextual Bandit algorithm with a continuous action space<a class="headerlink" href="#simulating-a-smart-thermostat-using-cats-a-contextual-bandit-algorithm-with-a-continuous-action-space" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial we will simulate the scenario of personalizing a thermostat for a household with two rooms using Contextual Bandits in a continuous action space. The goal is to maximize user satisfaction with the thermostat quantified by measuring thermostat accuracy or reward (TR). The thermostat proposes a temperature and the user will either accept the temperature or adjust it to fit their needs.</p>
<p>Let’s recall that in a CB setting, a data point has four components,</p>
<ul class="simple">
<li><p>Context</p></li>
<li><p>Chosen Action</p></li>
<li><p>Probability of chosen action</p></li>
<li><p>Reward/cost for chosen action</p></li>
</ul>
<p>In our simulator we will need to generate a context, get an action/decision for the given context, and also simulate generating a reward.</p>
<p>The goal of the learning agent is to maximize the reward or to minimize the loss.</p>
<p>The thermostat tracks two rooms: ‘Living Room’ and ‘Bedroom’.
Each room will need temperature adjustment either in the morning or in the afternoon.
The context is therefore (room, time_of_day).</p>
<p>In a continuous range we can’t specify actions since there are infinite actions we can take across the continuous range. We do however provide the minimum value and the maximum value of the range. Here we will range between 0 degrees Celsius and 32 degrees Celsius using 1 degree increments which gives us a continuous range of 33 degrees.</p>
<p>The reward is measured using the absolute difference between the proposed temperature and the one that was actually set by the people living in the house.</p>
<p>Let’s first start with importing the necessary packages:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">vowpalwabbit</span> <span class="kn">import</span> <span class="n">pyvw</span>
<span class="kn">import</span> <span class="nn">pylibvw</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">json</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># VW minimizes loss/cost, therefore we will pass cost as -reward</span>
<span class="n">USER_LIKED_TEMPERATURE</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
<span class="n">USER_DISLIKED_TEMPERATURE</span> <span class="o">=</span> <span class="mf">0.0</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="simulate-reward">
<h2>Simulate reward<a class="headerlink" href="#simulate-reward" title="Permalink to this headline">¶</a></h2>
<p>In the real world we will have to learn the room temperature preferences as we observe the interactions between the proposed temperature for each room and the one selected by the people living in the house. Since this is a simulation we will have to define the preference profile for each room. The reward that we provide to the learner will follow this preference profile. Our hope is to see if the learner can take better and better decisions as we see more samples which in turn means we are maximizing the reward.</p>
<p>We will also modify the reward function in a few different ways and see if the CB learner picks up the changes. We will compare the TR with and without learning.</p>
<p>VW minimizes the cost, which is defined as -reward. Therefore, we will pass the cost associated to each chosen action to VW.</p>
<p>The reward function below specifies that we want the living room to be cold in the morning but warm in the afternoon. In reverse, we prefer the bedroom to be warm in the morning and cold in the afternoon. It looks dense but we are just simulating our hypothetical world in the format of the feedback the learner understands: cost. If the learner recommends a temperature that aligns with the reward function, we give a positive reward. Max reward is -1.0, min reward is 0 since VW learns in terms of cost, so we return a negative reward. In our simulated world this is the difference between the temperature recommended and the temperature chosen. If the difference is smaller than 5 degrees then we give a reward to the thermostat. This is a steep cost function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_cost</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">):</span>
    <span class="nb">range</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">max_value</span> <span class="o">-</span> <span class="n">min_value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Living Room&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">29</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Bedroom&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">29</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This function modifies (context, temperature (i.e. action), cost, probability) to VW friendly json format</span>
<span class="k">def</span> <span class="nf">to_vw_example_format</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cats_label</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">example_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">cats_label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">chosen_temp</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">pdf_value</span> <span class="o">=</span> <span class="n">cats_label</span>
        <span class="n">example_dict</span><span class="p">[</span><span class="s1">&#39;_label_ca&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;action&#39;</span> <span class="p">:</span> <span class="n">chosen_temp</span><span class="p">,</span> <span class="s1">&#39;cost&#39;</span><span class="p">:</span> <span class="n">cost</span><span class="p">,</span> <span class="s1">&#39;pdf_value&#39;</span><span class="p">:</span> <span class="n">pdf_value</span><span class="p">}</span>
    <span class="n">example_dict</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;room=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]):</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;time_of_day=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">])</span> <span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">example_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="getting-a-decision">
<h2>Getting a decision<a class="headerlink" href="#getting-a-decision" title="Permalink to this headline">¶</a></h2>
<p>We call VW and get a predicted temperature and the value of the probability density function at that temperature. Since we are predicting over a continuous range VW will sample a pdf before returning the predicted value and the density of the pdf at that point. We are incorporating exploration into our strategy so the pdf will be more dense around the value that VW chooses to predict, and less dense in the rest of the continuous range. So it is more likely that VW will choose an action around the predicted value.</p>
<p>We have all of the information we need to choose a temperature for a specific room and time of day. To use VW to achieve this, we will do the following:</p>
<p>We convert our context into the json format we need.
We pass this example to VW and get the chosen action and the probability of chosing that action.
Finally we return the chosen temperature and the probability of choosing it (we are going to need the probability when we learn form this example)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_temperature</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="n">vw_text_example</span> <span class="o">=</span> <span class="n">to_vw_example_format</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">vw</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">vw_text_example</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="simulation-set-up">
<h2>Simulation set up<a class="headerlink" href="#simulation-set-up" title="Permalink to this headline">¶</a></h2>
<p>Now that we have done all of the setup work and know how to interact with VW, let’s simulate the world of our two rooms. The scenario is that the thermostat it turned on in each room and it has to propose a temperature. Remember that the reward function allows us to define the worlds reaction to what VW recommends.</p>
<p>We will choose between ‘Living Room’ and ‘Bedroom’ uniformly at random and also choose the time of day uniformly at random. We can think of this as tossing a coin to choose between the rooms (‘Living Room’ if heads and ‘Bedroom’ if tails) and another coin toss for choosing time of day.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rooms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Living Room&#39;</span><span class="p">,</span> <span class="s1">&#39;Bedroom&#39;</span><span class="p">]</span>
<span class="n">times_of_day</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;morning&#39;</span><span class="p">,</span> <span class="s1">&#39;afternoon&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">choose_room</span><span class="p">(</span><span class="n">rooms</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">rooms</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">choose_time_of_day</span><span class="p">(</span><span class="n">times_of_day</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">times_of_day</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will instantiate a CB learner in VW and then simulate the thermostat interaction num_iterations number of times. In each interaction, we:</p>
<ol class="simple">
<li><p>Decide between ‘Living Room’ and ‘Bedroom’</p></li>
<li><p>Decide time of day</p></li>
<li><p>Pass context i.e. (room, time of day) to learner to get a temperature i.e. a value between min (0 degrees) and max (32 degrees) and probability of choosing that temperature</p></li>
<li><p>Receive reward i.e. see if the proposed temperature was adjusted or not, and by how much. Remember that cost is just negative reward.</p></li>
<li><p>Format context, action (temperature), probability, and reward into VW format</p></li>
<li><p>Learn from the example</p></li>
</ol>
<p>The above steps are repeatedly executed during our simulations, so we define the process in the run_simulation function. The cost function must be supplied as this is essentially us simulating how the world works.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">cost_function</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="n">reward_rate</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">hits</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">cost_sum</span> <span class="o">=</span> <span class="mf">0.</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># 1. In each simulation choose a room</span>
        <span class="n">room</span> <span class="o">=</span> <span class="n">choose_room</span><span class="p">(</span><span class="n">rooms</span><span class="p">)</span>
        <span class="c1"># 2. Choose time of day for a given room</span>
        <span class="n">time_of_day</span> <span class="o">=</span> <span class="n">choose_time_of_day</span><span class="p">(</span><span class="n">times_of_day</span><span class="p">)</span>
        <span class="c1"># 3. Pass context to vw to get a temperature</span>
        <span class="n">context</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;room&#39;</span><span class="p">:</span> <span class="n">room</span><span class="p">,</span> <span class="s1">&#39;time_of_day&#39;</span><span class="p">:</span> <span class="n">time_of_day</span><span class="p">}</span>
        <span class="n">temperature</span><span class="p">,</span> <span class="n">pdf_value</span> <span class="o">=</span> <span class="n">predict_temperature</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        
        <span class="c1"># 4. Get cost of the action we chose</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">cost_function</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cost</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="mf">0.75</span><span class="p">:</span> <span class="c1"># count something as a hit only if it has a high reward</span>
            <span class="n">hits</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">cost_sum</span> <span class="o">+=</span> <span class="n">cost</span>

        <span class="k">if</span> <span class="n">do_learn</span><span class="p">:</span>
            <span class="c1"># 5. Inform VW of what happened so we can learn from it</span>
            <span class="n">txt_ex</span> <span class="o">=</span> <span class="n">to_vw_example_format</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cats_label</span><span class="o">=</span><span class="p">(</span><span class="n">temperature</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">pdf_value</span><span class="p">))</span>
            <span class="n">vw_format</span> <span class="o">=</span> <span class="n">vw</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">txt_ex</span><span class="p">,</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="o">.</span><span class="n">lContinuous</span><span class="p">)</span>
            <span class="c1"># 6. Learn</span>
            <span class="n">vw</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">vw_format</span><span class="p">)</span>
            <span class="c1"># 7. Let VW know you&#39;re done with these objects</span>
            <span class="n">vw</span><span class="o">.</span><span class="n">finish_example</span><span class="p">(</span><span class="n">vw_format</span><span class="p">)</span>

        <span class="c1"># We negate this so that on the plot instead of minimizing cost, we are maximizing reward</span>
        <span class="n">reward_rate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">cost_sum</span><span class="o">/</span><span class="n">i</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">reward_rate</span><span class="p">,</span> <span class="n">hits</span>
</pre></div>
</div>
</div>
</div>
<p>We want to be able to visualize what is occurring, so we are going to plot the reward rate over each iteration of the simulation. If VW is showing temperatures the that are close to what the simulated world wants, the reward will be higher. Below is a little utility function to make showing the plot easier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_reward_rate</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">reward_rate</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">reward_rate</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;num_iterations&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;reward rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="scenario-1">
<h2>Scenario 1<a class="headerlink" href="#scenario-1" title="Permalink to this headline">¶</a></h2>
<p>We will use the first reward function get_cost and assume that the preferences for room temperatures do not change over time and see what happens to the smart thermostat as we learn. We will also see what happens when there is no learning. We will use the “no learning” case as our baseline to compare to.</p>
<p>We will be using the CATS algorithm which does tree based learning with smoothing. That means that we need to provide the number of actions (buckets/tree leaves) that the continuous range will be discretized into, and then we need to define the bandwidth which is the radius around the chosen discreet action that the algorithm will sample a temperature from with higher probability.</p>
<p>For example, in our current range of 32 degrees celsius if we select the number of actions to be 8 that means that the algorithm will initially predict an action from the centre of one of 8 buckets:</p>
<p><code class="docutils literal notranslate"><span class="pre">(0</span> <span class="pre">-</span> <span class="pre">2</span> <span class="pre">-</span> <span class="pre">4),</span> <span class="pre">(4</span> <span class="pre">-</span> <span class="pre">6</span> <span class="pre">-</span> <span class="pre">8),</span> <span class="pre">(8</span> <span class="pre">-</span> <span class="pre">10</span> <span class="pre">-</span> <span class="pre">12),</span> <span class="pre">(12</span> <span class="pre">-</span> <span class="pre">14</span> <span class="pre">-</span> <span class="pre">16),</span> <span class="pre">(16</span> <span class="pre">-</span> <span class="pre">18</span> <span class="pre">-</span> <span class="pre">20),</span> <span class="pre">(20</span> <span class="pre">-</span> <span class="pre">22</span> <span class="pre">-</span> <span class="pre">24),</span> <span class="pre">(24</span> <span class="pre">-</span> <span class="pre">26</span> <span class="pre">-</span> <span class="pre">28),</span> <span class="pre">(28</span> <span class="pre">-</span> <span class="pre">30</span> <span class="pre">-</span> <span class="pre">32)</span></code></p>
<p>Let’s say that for a given context, it selects the third bucket that starts from 8 degrees celsius, goes until 12 degrees celsius, and has a center of 10 degrees celsius. For a smoothing radius (bandwidth) of 1 the resulting probability density function (pdf) that VW will have to sample from will have a higher density around</p>
<p><code class="docutils literal notranslate"><span class="pre">[bucket_centre</span> <span class="pre">-</span> <span class="pre">bandwidth,</span> <span class="pre">bucket_centre</span> <span class="pre">+</span> <span class="pre">bandwidth]</span></code></p>
<p>i.e. [9, 11]. If bandwidth was bigger, for example 5 then we would have higher density (and therefore higher probability of selecting an action) in the range [5, 15], providing a smoothing range that spans the discretized buckets. The bandwidth is defined in terms of the continuous range (max_value - min_value)</p>
<div class="section" id="with-learning">
<h3>With Learning<a class="headerlink" href="#with-learning" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="n">num_actions</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Instantiate VW learner</span>
<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidth</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
<span class="n">ctr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
<span class="n">plot_reward_rate</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">ctr</span><span class="p">,</span> <span class="s1">&#39;reward rate with num_actions = 32 and bandwidth = 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.611352,0.40625        6
0.000000 0.000000            4            4.0 {0.582045,0,0.40625} 2.23432,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.40591,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.566242,0,0.40625} 1.71644,0.40625        6
0.000000 0.000000           64           64.0 {2.1114,0,0.40625} 1.27354,0.40625        6
0.000000 0.000000          128          128.0 {0.78028,0,0.40625} 1.52519,0.40625        6
0.000000 0.000000          256          256.0 {2.05619,0,0.40625} 1.59455,0.40625        6
-0.091346 -0.182692          512          512.0 {21.261,-1,0.00625} 22.4398,0.00625        6
-0.274038 -0.456731         1024         1024.0 {18.1433,-1,0.40625} 18.182,0.40625        6
-0.769231 -1.264423         2048         2048.0 {16.7282,-1,0.40625} 17.5315,0.40625        6
-0.723558 -0.677885         4096         4096.0 {11.2007,0,0.40625} 11.8757,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.731370 -0.739183         8192         8192.0 {27.6797,-1,0.40625} 28.1343,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.703754
total feature number = 60000
</pre></div>
</div>
<img alt="../_images/python_cats_15_2.png" src="../_images/python_cats_15_2.png" />
</div>
</div>
</div>
<div class="section" id="without-learning">
<h3>Without Learning<a class="headerlink" href="#without-learning" title="Permalink to this headline">¶</a></h3>
<p>Let’s do the same but without learning. The reward rate never improves and just hovers around 0.5</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="n">num_actions</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Instantiate VW learner</span>
<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidth</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
<span class="n">ctr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
<span class="n">plot_reward_rate</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">ctr</span><span class="p">,</span> <span class="s1">&#39;click through rate with num_actions = 32 and bandwidth = 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2901; id=1, #l=815; id=2, #l=2736; id=3, #l=0; id=4, #l=757; id=5, #l=2183; id=6, #l=318; id=7, #l=0; id=8, #l=0; id=9, #l=114; id=10, #l=541; id=11, #l=673; id=12, #l=283; id=13, #l=420; id=14, #l=332; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.611352,0.40625        6
    n.a.     n.a.            4            4.0  unknown 2.23432,0.40625        6
    n.a. 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.71644,0.40625        6
    n.a.     n.a.           64           64.0  unknown 1.27354,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.52519,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.59455,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.837536,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.42812,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.77766,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 2.02957,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
</pre></div>
</div>
<img alt="../_images/python_cats_17_2.png" src="../_images/python_cats_17_2.png" />
</div>
</div>
</div>
</div>
<div class="section" id="parameter-sweep">
<h2>Parameter sweep<a class="headerlink" href="#parameter-sweep" title="Permalink to this headline">¶</a></h2>
<p>Next let’s do a parameter sweep for different values of <code class="docutils literal notranslate"><span class="pre">num_actions</span></code> and <code class="docutils literal notranslate"><span class="pre">bandwidth</span></code>. We will use the below function to help us plot the reward rates for different combinations of <code class="docutils literal notranslate"><span class="pre">num_actions</span></code> and <code class="docutils literal notranslate"><span class="pre">bandwidths</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_reward_sweep</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">bandwidths</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">n_actions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
    <span class="n">n_bandwidths</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">bandwidths</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">n_bandwidths</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bandwidths</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">bandwidths</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;NA&#39;</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="n">reward_rate</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="p">])][</span><span class="nb">str</span><span class="p">(</span><span class="n">bandwidths</span><span class="p">[</span><span class="n">j</span><span class="p">])]</span>
            <span class="n">hits_percentage</span> <span class="o">=</span> <span class="p">(</span><span class="n">hits</span><span class="o">/</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">))</span><span class="o">*</span><span class="mi">100</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">reward_rate</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;hits </span><span class="si">{:.2f}</span><span class="s1">% TR </span><span class="si">{:.2f}</span><span class="s1">%&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">hits_percentage</span><span class="p">,</span> <span class="n">reward_rate</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;b: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidths</span><span class="p">[</span><span class="n">j</span><span class="o">%</span><span class="k">len</span>(bandwidths)]), fontsize=14)
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;k: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="o">%</span><span class="k">len</span>(actions)]), fontsize=14)

    <span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="s1">&#39;num_iterations&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;reward_rate&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_figheight</span><span class="p">(</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_figwidth</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;#examples </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">))</span>

    <span class="c1"># Hide x labels and tick labels for top plots and y ticks for right plots.</span>
    <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axs</span><span class="o">.</span><span class="n">flat</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">label_outer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id1">
<h3>With Learning<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>We will try all the number of actions as powers of 2 from 8 until 2048. Since our continuous range stays the same (0-32) we are creating smaller range buckets as the number of actions grows. The number of actions needs to be a power of 2 as it represents the number of leaves that the internal binary tree will have. Small number of actions might result in coarser discretizaton leading to results similar to uniform random. On the other hand really large number of actions could mean that we need a lot more data in order to train all of the buckets.</p>
<p>We will also try all the combinaitons of the above action numbers with bandwidths ranging from 0 to 25. The smaller the bandwidth the smaller the smoothing range around the selected continuous value. Really large bandwidths will result in large smoothing ranges and could lead to results similar to uniform random.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># do parameter sweeping</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">]</span>
<span class="n">bandwidths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span>

<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="k">for</span> <span class="n">actions</span> <span class="ow">in</span> <span class="n">num_actions</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="n">bandwidths</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">bd</span> <span class="o">&gt;=</span> <span class="n">actions</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting simulation for: --cats </span><span class="si">{}</span><span class="s2"> --bandwidth </span><span class="si">{}</span><span class="s2"> --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
        <span class="n">rr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done with simulation for num_actions: </span><span class="si">{}</span><span class="s2"> and bandwidth: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)][</span><span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">rr</span><span class="p">,</span> <span class="n">hits</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Plotting...&quot;</span><span class="p">)</span>
<span class="n">plot_reward_sweep</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">bandwidths</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting simulation for: --cats 8 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
0.000000 0.000000            2            2.0 {3.64167e-05,0,0.20625} 0.234482,0.20625        6
0.000000 0.000000            4            4.0 {0.176755,0,0.20625} 3.43124,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.76921,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {4.80576,0,0.00625} 21.8051,0.20625        6
0.000000 0.000000           64           64.0 {22.5831,-1,0.20625} 20.9327,0.20625        6
0.000000 0.000000          128          128.0 {18.7182,-1,0.00625} 21.4284,0.20625        6
0.000000 0.000000          256          256.0 {22.4743,-1,0.20625} 21.565,0.20625        6
0.000000 0.000000          512          512.0 {16.1594,-1,0.20625} 16.1951,0.20625        6
0.000000 0.000000         1024         1024.0 {19.2519,-1,0.20625} 19.3281,0.20625        6
0.000000 0.000000         2048         2048.0 {24.2222,-1,0.20625} 25.8045,0.20625        6
0.000000 0.000000         4096         4096.0 {24.9711,-1,0.20625} 26.3007,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {30.2782,-1,0.20625} 31.1736,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3888; id=1, #l=502; id=2, #l=3449; id=3, #l=0; id=4, #l=512; id=5, #l=1838; id=6, #l=1693; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 1.10366,0.40625        6
0.000000 0.000000            4            4.0 {1.07435,0,0.40625} 2.72663,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.89821,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {1.05855,0,0.40625} 2.20875,0.40625        6
0.000000 0.000000           64           64.0 {2.60371,0,0.40625} 1.76585,0.40625        6
0.000000 0.000000          128          128.0 {1.27259,0,0.40625} 2.0175,0.40625        6
0.000000 0.000000          256          256.0 {2.5485,0,0.40625} 2.08686,0.40625        6
-0.177885 -0.355769          512          512.0 {13.1271,-1,0.40625} 13.1452,0.40625        6
-0.463942 -0.750000         1024         1024.0 {26.5125,-1,0.40625} 26.5512,0.40625        6
-0.641827 -0.819712         2048         2048.0 {13.282,-1,0.40625} 14.0854,0.40625        6
-0.695913 -0.750000         4096         4096.0 {25.4776,-1,0.40625} 26.1526,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 0

Starting simulation for: --cats 8 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.795072 -0.894231         8192         8192.0 {26.2028,-1,0.40625} 26.6574,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.803938
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3902; id=1, #l=423; id=2, #l=3518; id=3, #l=0; id=4, #l=429; id=5, #l=1725; id=6, #l=1866; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
0.000000 0.000000            2            2.0 {3.64167e-05,0,0.20625} 0.234482,0.20625        6
0.000000 0.000000            4            4.0 {0.176755,0,0.20625} 3.43124,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.76921,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.145629,0,0.20625} 2.41116,0.20625        6
0.000000 0.000000           64           64.0 {3.18912,0,0.20625} 1.53879,0.20625        6
0.000000 0.000000          128          128.0 {0.567218,0,0.20625} 2.03446,0.20625        6
0.000000 0.000000          256          256.0 {3.08037,0,0.20625} 2.17109,0.20625        6
-0.198864 -0.397727          512          512.0 {8.40185,0,0.20625} 8.43757,0.20625        6
-0.383523 -0.568182         1024         1024.0 {30.8883,-1,0.20625} 30.9645,0.20625        6
-0.535038 -0.686553         2048         2048.0 {12.5858,-1,0.20625} 14.1681,0.20625        6
-0.635653 -0.736269         4096         4096.0 {17.2135,-1,0.20625} 18.5431,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 1

Starting simulation for: --cats 8 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.735085 -0.834517         8192         8192.0 {14.7631,-1,0.20625} 15.6585,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.762182
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3785; id=1, #l=951; id=2, #l=2880; id=3, #l=0; id=4, #l=968; id=5, #l=1363; id=6, #l=1609; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 3.21214,0.139583        6
0.000000 0.000000            4            4.0 {3.12685,0,0.139583} 7.93571,0.139583        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {8.4351,0,0.139583} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {3.08085,0,0.139583} 6.42844,0.139583        6
-0.037313 -0.074627           64           64.0 {22.8615,-1,0.139583} 20.423,0.139583        6
-0.190299 -0.343284          128          128.0 {18.7182,-1,0.00625} 24.9763,0.139583        6
-0.248134 -0.305970          256          256.0 {26.5217,0,0.139583} 25.1782,0.139583        6
-0.374067 -0.500000          512          512.0 {11.4594,0,0.139583} 11.5122,0.139583        6
-0.447295 -0.520522         1024         1024.0 {16.029,-1,0.139583} 16.1415,0.139583        6
-0.558302 -0.669310         2048         2048.0 {15.7313,-1,0.139583} 18.0693,0.139583        6
-0.606771 -0.655239         4096         4096.0 {20.6588,-1,0.139583} 22.6234,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 2

Starting simulation for: --cats 8 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.659457 -0.712142         8192         8192.0 {22.7693,-1,0.139583} 24.0924,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.671045
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1986; id=1, #l=1779; id=2, #l=1954; id=3, #l=0; id=4, #l=1404; id=5, #l=1257; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 9.31589e-06,0.80625        6
0.000000 0.000000            2            2.0 {9.31589e-06,0,0.80625} 0.0599837,0.80625        6
0.000000 0.000000            4            4.0 {0.0452164,0,0.80625} 0.877758,0.80625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.964217,0,0.80625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0372539,0,0.80625} 0.616809,0.80625        6
0.000000 0.000000           64           64.0 {21.653,0,0.80625} 21.2309,0.80625        6
0.000000 0.000000          128          128.0 {18.7182,0,0.00625} 20.3654,0.80625        6
0.000000 0.000000          256          256.0 {20.633,-1,0.80625} 20.4004,0.80625        6
0.000000 0.000000          512          512.0 {21.002,-1,0.80625} 21.0112,0.80625        6
0.000000 0.000000         1024         1024.0 {21.7931,-1,0.80625} 21.8126,0.80625        6
0.000000 0.000000         2048         2048.0 {21.0801,-1,0.80625} 21.4849,0.80625        6
0.000000 0.000000         4096         4096.0 {24.2484,-1,0.80625} 24.5885,0.80625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {24.6138,-1,0.80625} 24.8429,0.80625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2899; id=1, #l=7; id=2, #l=2902; id=3, #l=0; id=4, #l=10; id=5, #l=1574; id=6, #l=1353; id=7, #l=0; id=8, #l=0; id=9, #l=3; id=10, #l=31; id=11, #l=25; id=12, #l=1574; id=13, #l=965; id=14, #l=408; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.611352,0.40625        6
0.000000 0.000000            4            4.0 {0.582045,0,0.40625} 2.23432,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.40591,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {4.80576,0,0.00625} 20.4241,0.40625        6
-0.115385 -0.230769           64           64.0 {20.8191,0,0.40625} 19.9812,0.40625        6
-0.250000 -0.384615          128          128.0 {18.7182,-1,0.00625} 20.2329,0.40625        6
-0.307692 -0.365385          256          256.0 {20.7639,0,0.40625} 20.3022,0.40625        6
-0.355769 -0.403846          512          512.0 {19.5271,0,0.40625} 19.5452,0.40625        6
-0.713942 -1.072115         1024         1024.0 {21.0971,-1,0.40625} 21.1358,0.40625        6
-0.848558 -0.983173         2048         2048.0 {22.6359,-1,0.40625} 23.4392,0.40625        6
-0.742188 -0.635817         4096         4096.0 {13.1699,-1,0.40625} 13.845,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 0

Starting simulation for: --cats 32 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.763522 -0.784856         8192         8192.0 {23.7413,0,0.40625} 24.1959,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.767754
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3624; id=1, #l=1278; id=2, #l=2063; id=3, #l=0; id=4, #l=1192; id=5, #l=2770; id=6, #l=568; id=7, #l=0; id=8, #l=0; id=9, #l=116; id=10, #l=1080; id=11, #l=1039; id=12, #l=1524; id=13, #l=830; id=14, #l=34; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.71933,0.20625        6
0.000000 0.000000            4            4.0 {0.661603,0,0.20625} 3.91608,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {4.25406,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.630478,0,0.20625} 2.89601,0.20625        6
0.000000 0.000000           64           64.0 {3.67397,0,0.20625} 2.02364,0.20625        6
-0.018939 -0.037879          128          128.0 {18.5066,0,0.20625} 19.9739,0.20625        6
-0.473485 -0.928030          256          256.0 {22.9592,-1,0.20625} 22.0499,0.20625        6
-0.754194 -1.034903          512          512.0 {15.6746,-1,0.20625} 15.7103,0.20625        6
-0.783482 -0.812771         1024         1024.0 {17.7974,-1,0.20625} 17.8736,0.20625        6
-0.735254 -0.687027         2048         2048.0 {27.6161,-1,0.20625} 29.1984,0.20625        6
-0.684338 -0.633421         4096         4096.0 {18.6681,-1,0.20625} 19.9976,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 1

Starting simulation for: --cats 32 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.741080 -0.797822         8192         8192.0 {19.1267,-1,0.20625} 20.0221,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.745759
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3307; id=1, #l=560; id=2, #l=2965; id=3, #l=0; id=4, #l=440; id=5, #l=1839; id=6, #l=1376; id=7, #l=0; id=8, #l=0; id=9, #l=117; id=10, #l=404; id=11, #l=745; id=12, #l=1476; id=13, #l=722; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.19857e-05,0.234821        6
0.000000 0.000000            2            2.0 {3.19857e-05,0,0.234821} 0.205952,0.234821        6
0.000000 0.000000            4            4.0 {0.155249,0,0.234821} 3.01375,0.234821        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.3106,0,0.234821} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.12791,0,0.234821} 2.11779,0.234821        6
0.000000 0.000000           64           64.0 {2.80109,0,0.234821} 1.35156,0.234821        6
0.000000 0.000000          128          128.0 {0.498203,0,0.234821} 1.78692,0.234821        6
0.000000 0.000000          256          256.0 {2.70558,0,0.234821} 1.90693,0.234821        6
-0.367057 -0.734114          512          512.0 {21.261,-1,0.00625} 22.4398,0.00625        6
-0.469245 -0.571433         1024         1024.0 {27.9693,-1,0.139583} 28.0818,0.139583        6
-0.592845 -0.716446         2048         2048.0 {16.2089,-1,0.139583} 18.5469,0.139583        6
-0.625159 -0.657473         4096         4096.0 {17.3155,-1,0.139583} 19.2801,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 2

Starting simulation for: --cats 32 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.675825 -0.726491         8192         8192.0 {17.5156,-1,0.139583} 18.8387,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.709723
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2769; id=1, #l=1224; id=2, #l=2296; id=3, #l=6; id=4, #l=0; id=5, #l=1610; id=6, #l=742; id=7, #l=0; id=8, #l=0; id=9, #l=165; id=10, #l=613; id=11, #l=562; id=12, #l=1273; id=13, #l=690; id=14, #l=663; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000199639,0.0376226        6
0.000000 0.000000            2            2.0 {0.000199639,0,0.0376226} 1.28545,0.0376226        6
0.000000 0.000000            4            4.0 {0.968985,0,0.0376226} 18.8103,0.0376226        6
0.000000 0.000000            8            8.0 {22.9832,0,0.0376226} 25.017,0.0376226        6
-0.103827 -0.207655           16           16.0 {20.6631,0,0.0376226} 22.8563,0.0376226        6
-0.265944 -0.428060           32           32.0 {0.798351,0,0.0376226} 13.2182,0.0376226        6
-0.432239 -0.598534           64           64.0 {17.483,0,0.0376226} 8.4358,0.0376226        6
-0.451938 -0.471638          128          128.0 {3.74364,0,0.03125} 13.4274,0.03125        6
-0.420377 -0.388815          256          256.0 {20.3305,-1,0.03125} 14.3292,0.03125        6
-0.359358 -0.298340          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.334471 -0.309584         1024         1024.0 {24.6628,-1,0.03125} 25.1656,0.03125        6
-0.334536 -0.334601         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.330309 -0.326081         4096         4096.0 {11.2093,-1,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.328730 -0.327152         8192         8192.0 {20.6363,-1,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.330381
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=2; id=2, #l=0; id=3, #l=151; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=137; id=8, #l=43; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=86; 
    n.a.     n.a.            1            1.0  unknown 4.67607e-06,1.60625        6
0.000000 0.000000            2            2.0 {4.67607e-06,0,1.60625} 0.0301085,1.60625        6
0.000000 0.000000            4            4.0 {0.0226962,0,1.60625} 0.440587,1.60625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.483984,0,1.60625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0186995,0,1.60625} 0.309605,1.60625        6
0.000000 0.000000           64           64.0 {0.409498,0,1.60625} 0.197588,1.60625        6
0.000000 0.000000          128          128.0 {0.0728334,0,1.60625} 0.261234,1.60625        6
0.000000 0.000000          256          256.0 {0.395535,0,1.60625} 0.278778,1.60625        6
0.000000 0.000000          512          512.0 {0.0827275,0,1.60625} 0.0873145,1.60625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 25

Starting simulation for: --cats 64 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         1024         1024.0 {0.479821,0,1.60625} 0.489602,1.60625        6
0.000000 0.000000         2048         2048.0 {0.121917,0,1.60625} 0.32509,1.60625        6
0.000000 0.000000         4096         4096.0 {17.1519,-1,1.60625} 17.3227,1.60625        6
0.000000 0.000000         8192         8192.0 {13.3509,-1,1.60625} 13.4659,1.60625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 0

Starting simulation for: --cats 64 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2487; id=1, #l=649; id=2, #l=1851; id=3, #l=0; id=4, #l=650; id=5, #l=1008; id=6, #l=859; id=7, #l=0; id=8, #l=0; id=9, #l=1; id=10, #l=654; id=11, #l=724; id=12, #l=292; id=13, #l=105; id=14, #l=763; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.365198,0.40625        6
0.000000 0.000000            4            4.0 {0.335891,0,0.40625} 1.98817,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,-1,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.15975,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.320089,0,0.40625} 1.47028,0.40625        6
0.000000 0.000000           64           64.0 {1.86525,0,0.40625} 1.02739,0.40625        6
0.000000 0.000000          128          128.0 {0.534126,0,0.40625} 1.27903,0.40625        6
0.000000 0.000000          256          256.0 {1.81004,0,0.40625} 1.3484,0.40625        6
-0.408654 -0.817308          512          512.0 {21.261,-1,0.00625} 22.4398,0.00625        6
-0.572115 -0.735577         1024         1024.0 {29.7125,0,0.40625} 29.7512,0.40625        6
-0.814904 -1.057692         2048         2048.0 {14.5128,-1,0.40625} 15.3161,0.40625        6
-0.789663 -0.764423         4096         4096.0 {16.3699,-1,0.40625} 17.045,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.769531 -0.749399         8192         8192.0 {20.5413,-1,0.40625} 20.9958,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.737969
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2896; id=1, #l=1067; id=2, #l=2837; id=3, #l=0; id=4, #l=958; id=5, #l=1700; id=6, #l=1071; id=7, #l=0; id=8, #l=0; id=9, #l=168; id=10, #l=946; id=11, #l=1148; id=12, #l=701; id=13, #l=291; id=14, #l=116; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.476906,0.20625        6
0.000000 0.000000            4            4.0 {0.419179,0,0.20625} 3.67366,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {4.01163,0,0.20625} 9.58583,0.00625        6
0.000000 0.000000           32           32.0 {0.388053,0,0.20625} 2.65359,0.20625        6
0.000000 0.000000           64           64.0 {3.43155,0,0.20625} 1.78122,0.20625        6
-0.037879 -0.075758          128          128.0 {18.2642,0,0.20625} 19.7314,0.20625        6
-0.208333 -0.378788          256          256.0 {20.7773,-1,0.20625} 19.8681,0.20625        6
-0.322285 -0.436237          512          512.0 {20.2806,-1,0.20625} 20.3164,0.20625        6
-0.495107 -0.667929         1024         1024.0 {23.3731,-1,0.20625} 23.4493,0.20625        6
-0.600300 -0.705492         2048         2048.0 {18.6464,-1,0.20625} 20.2287,0.20625        6
-0.668284 -0.736269         4096         4096.0 {15.0317,-1,0.20625} 16.3613,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 1

Starting simulation for: --cats 64 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.687184 -0.706084         8192         8192.0 {20.8237,-1,0.20625} 21.7191,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.709271
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3569; id=1, #l=957; id=2, #l=1855; id=3, #l=0; id=4, #l=840; id=5, #l=2003; id=6, #l=1196; id=7, #l=0; id=8, #l=0; id=9, #l=155; id=10, #l=414; id=11, #l=1269; id=12, #l=1480; id=13, #l=665; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.97576e-05,0.252404        6
0.000000 0.000000            2            2.0 {2.97576e-05,0,0.252404} 0.191605,0.252404        6
0.000000 0.000000            4            4.0 {0.144434,0,0.252404} 2.80381,0.252404        6
0.000000 0.000000            8            8.0 {10.3501,-1,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.07998,0,0.252404} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.119,0,0.252404} 1.97027,0.252404        6
0.000000 0.000000           64           64.0 {2.60597,0,0.252404} 1.25741,0.252404        6
0.000000 0.000000          128          128.0 {0.463498,0,0.252404} 1.66244,0.252404        6
-0.056376 -0.112751          256          256.0 {28.671,-1,0.139583} 27.3274,0.139583        6
-0.260439 -0.464502          512          512.0 {18.3848,0,0.139583} 18.4376,0.139583        6
-0.387923 -0.515406         1024         1024.0 {18.6558,-1,0.139583} 18.7684,0.139583        6
-0.540221 -0.692520         2048         2048.0 {21.2238,-1,0.139583} 23.5619,0.139583        6
-0.595978 -0.651734         4096         4096.0 {17.0767,-1,0.139583} 19.0413,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 2

Starting simulation for: --cats 64 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.705679 -0.815381         8192         8192.0 {20.1425,-1,0.139583} 21.4655,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.722694
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2638; id=1, #l=1121; id=2, #l=2544; id=3, #l=1; id=4, #l=0; id=5, #l=1622; id=6, #l=759; id=7, #l=0; id=8, #l=0; id=9, #l=152; id=10, #l=594; id=11, #l=590; id=12, #l=1153; id=13, #l=482; id=14, #l=434; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000198004,0.0379332        6
0.000000 0.000000            2            2.0 {0.000198004,0,0.0379332} 1.27492,0.0379332        6
0.000000 0.000000            4            4.0 {0.961051,0,0.0379332} 18.6563,0.0379332        6
-0.205954 -0.411909            8            8.0 {22.795,0,0.0379332} 24.8121,0.0379332        6
-0.308931 -0.411909           16           16.0 {20.4939,-1,0.0379332} 22.6691,0.0379332        6
-0.315766 -0.322601           32           32.0 {0.791813,0,0.0379332} 13.11,0.0379332        6
-0.476512 -0.637257           64           64.0 {17.3399,0,0.0379332} 8.36672,0.0379332        6
-0.434182 -0.391852          128          128.0 {3.74364,0,0.03125} 13.4274,0.03125        6
-0.377318 -0.320453          256          256.0 {20.3305,-1,0.03125} 14.3292,0.03125        6
-0.363393 -0.349469          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.335501 -0.307608         1024         1024.0 {24.6628,-1,0.03125} 25.1656,0.03125        6
-0.345852 -0.356203         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.331072 -0.316292         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 3

Starting simulation for: --cats 64 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.331155 -0.331237         8192         8192.0 {20.6363,0,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.331867
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=134; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=131; id=8, #l=29; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=84; 
    n.a.     n.a.            1            1.0  unknown 2.34259e-06,3.20625        6
0.000000 0.000000            2            2.0 {2.34259e-06,0,3.20625} 0.0150836,3.20625        6
0.000000 0.000000            4            4.0 {0.0113702,0,3.20625} 0.220723,3.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.242464,0,3.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00936795,0,3.20625} 0.155104,3.20625        6
0.000000 0.000000           64           64.0 {0.205148,0,3.20625} 0.0989867,3.20625        6
0.000000 0.000000          128          128.0 {0.0364877,0,3.20625} 0.130872,3.20625        6
0.000000 0.000000          256          256.0 {0.198153,0,3.20625} 0.139661,3.20625        6
0.000000 0.000000          512          512.0 {0.0414444,0,3.20625} 0.0437424,3.20625        6
0.000000 0.000000         1024         1024.0 {0.240378,0,3.20625} 0.245278,3.20625        6
0.000000 0.000000         2048         2048.0 {0.0610771,0,3.20625} 0.162862,3.20625        6
0.000000 0.000000         4096         4096.0 {14.3315,-1,3.20625} 14.417,3.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 25

Starting simulation for: --cats 128 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {14.4234,-1,3.20625} 14.481,3.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2467; id=1, #l=1305; id=2, #l=1167; id=3, #l=0; id=4, #l=1308; id=5, #l=540; id=6, #l=632; id=7, #l=0; id=8, #l=0; id=9, #l=3; id=10, #l=1311; id=11, #l=4; id=12, #l=542; id=13, #l=638; id=14, #l=3; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.242121,0.40625        6
0.000000 0.000000            4            4.0 {0.212814,0,0.40625} 1.86509,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.03668,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.197012,0,0.40625} 1.34721,0.40625        6
0.000000 0.000000           64           64.0 {1.74217,0,0.40625} 0.904311,0.40625        6
0.000000 0.000000          128          128.0 {0.411049,0,0.40625} 1.15596,0.40625        6
0.000000 0.000000          256          256.0 {1.68696,0,0.40625} 1.22532,0.40625        6
-0.009615 -0.019231          512          512.0 {19.1579,0,0.40625} 19.176,0.40625        6
-0.199519 -0.389423         1024         1024.0 {21.7125,-1,0.40625} 21.7512,0.40625        6
-0.525321 -0.851122         2048         2048.0 {24.2359,-1,0.40625} 25.0392,0.40625        6
-0.588982 -0.652644         4096         4096.0 {25.6007,-1,0.40625} 26.2757,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 0

Starting simulation for: --cats 128 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.632232 -0.675481         8192         8192.0 {17.7105,-1,0.40625} 18.1651,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.666355
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3558; id=1, #l=1283; id=2, #l=2466; id=3, #l=0; id=4, #l=1300; id=5, #l=1083; id=6, #l=1502; id=7, #l=0; id=8, #l=0; id=9, #l=19; id=10, #l=502; id=11, #l=411; id=12, #l=257; id=13, #l=438; id=14, #l=66; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.355694,0.20625        6
0.000000 0.000000            4            4.0 {0.297967,0,0.20625} 3.55245,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.89042,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.266841,0,0.20625} 2.53238,0.20625        6
0.000000 0.000000           64           64.0 {3.31033,0,0.20625} 1.66001,0.20625        6
0.000000 0.000000          128          128.0 {0.68843,0,0.20625} 2.15567,0.20625        6
0.000000 0.000000          256          256.0 {3.20159,0,0.20625} 2.2923,0.20625        6
-0.156250 -0.312500          512          512.0 {0.765484,0,0.20625} 0.801207,0.20625        6
-0.329072 -0.501894         1024         1024.0 {27.1307,-1,0.20625} 27.2069,0.20625        6
-0.605505 -0.881938         2048         2048.0 {19.0101,-1,0.20625} 20.5924,0.20625        6
-0.669150 -0.732794         4096         4096.0 {19.2741,-1,0.20625} 20.6037,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 1

Starting simulation for: --cats 128 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.710770 -0.752391         8192         8192.0 {26.5207,-1,0.20625} 27.4161,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.711475
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3388; id=1, #l=405; id=2, #l=2306; id=3, #l=0; id=4, #l=232; id=5, #l=1067; id=6, #l=1071; id=7, #l=0; id=8, #l=0; id=9, #l=207; id=10, #l=69; id=11, #l=1002; id=12, #l=1190; id=13, #l=578; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.86404e-05,0.26225        6
0.000000 0.000000            2            2.0 {2.86404e-05,0,0.26225} 0.184411,0.26225        6
0.000000 0.000000            4            4.0 {0.139011,0,0.26225} 2.69854,0.26225        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.96435,0,0.26225} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.114532,0,0.26225} 1.89629,0.26225        6
0.000000 0.000000           64           64.0 {24.8914,0,0.139583} 22.4528,0.139583        6
-0.659204 -1.318408          128          128.0 {18.7182,-1,0.00625} 21.036,0.139583        6
-0.745312 -0.831420          256          256.0 {21.1486,0,0.139583} 19.805,0.139583        6
-0.725757 -0.706201          512          512.0 {18.9818,0,0.139583} 19.0346,0.139583        6
-0.542449 -0.359142         1024         1024.0 {23.5514,-1,0.139583} 23.6639,0.139583        6
-0.632310 -0.722170         2048         2048.0 {18.4776,-1,0.139583} 20.8156,0.139583        6
-0.620881 -0.609453         4096         4096.0 {11.9424,0,0.139583} 13.907,0.139583 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 2

Starting simulation for: --cats 128 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>       6
-0.667348 -0.713814         8192         8192.0 {22.4111,-1,0.139583} 23.7342,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.649935
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2330; id=1, #l=1334; id=2, #l=1653; id=3, #l=7; id=4, #l=0; id=5, #l=1452; id=6, #l=952; id=7, #l=0; id=8, #l=0; id=9, #l=416; id=10, #l=467; id=11, #l=788; id=12, #l=778; id=13, #l=674; id=14, #l=274; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000197185,0.0380908        6
0.000000 0.000000            2            2.0 {0.000197185,0,0.0380908} 1.26965,0.0380908        6
0.000000 0.000000            4            4.0 {0.957074,0,0.0380908} 18.5791,0.0380908        6
0.000000 0.000000            8            8.0 {22.7007,0,0.0380908} 24.7095,0.0380908        6
-0.102551 -0.205102           16           16.0 {20.4091,-1,0.0380908} 22.5753,0.0380908        6
-0.102551 -0.102551           32           32.0 {0.788537,0,0.0380908} 13.0557,0.0380908        6
-0.192858 -0.283164           64           64.0 {17.2681,0,0.0380908} 8.3321,0.0380908        6
-0.232591 -0.272324          128          128.0 {3.07131,0,0.0380908} 11.016,0.0380908        6
-0.285071 -0.337550          256          256.0 {16.6793,-1,0.0380908} 11.7558,0.0380908        6
-0.295581 -0.306091          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.287396 -0.279211         1024         1024.0 {24.6628,0,0.03125} 25.1656,0.03125        6
-0.305941 -0.324487         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.319234 -0.332526         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 3

Starting simulation for: --cats 128 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.325118 -0.331002         8192         8192.0 {20.6363,-1,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.322706
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=154; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=134; id=8, #l=30; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=72; 
    n.a.     n.a.            1            1.0  unknown 1.17244e-06,6.40625        6
0.000000 0.000000            2            2.0 {1.17244e-06,0,6.40625} 0.00754917,6.40625        6
0.000000 0.000000            4            4.0 {0.00569065,0,6.40625} 0.110469,6.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.12135,0,6.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00468855,0,6.40625} 0.0776277,6.40625        6
0.000000 0.000000           64           64.0 {0.102674,0,6.40625} 0.0495416,6.40625        6
0.000000 0.000000          128          128.0 {0.0182616,0,6.40625} 0.0654997,6.40625        6
0.000000 0.000000          256          256.0 {0.099173,0,6.40625} 0.0698985,6.40625        6
0.000000 0.000000          512          512.0 {0.0207424,0,6.40625} 0.0218925,6.40625        6
0.000000 0.000000         1024         1024.0 {0.120306,0,6.40625} 0.122759,6.40625        6
0.000000 0.000000         2048         2048.0 {0.0305684,0,6.40625} 0.0815103,6.40625        6
0.000000 0.000000         4096         4096.0 {0.0546794,0,6.40625} 0.0974849,6.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 25

Starting simulation for: --cats 256 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {0.100665,0,6.40625} 4.73022,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=91; id=1, #l=0; id=2, #l=92; id=3, #l=0; id=4, #l=0; id=5, #l=1; id=6, #l=97; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=2; id=11, #l=2; id=12, #l=3; id=13, #l=94; id=14, #l=4; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.180583,0.40625        6
0.000000 0.000000            4            4.0 {0.151276,0,0.40625} 1.80355,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {1.97514,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.135473,0,0.40625} 1.28567,0.40625        6
0.000000 0.000000           64           64.0 {1.68063,0,0.40625} 0.842772,0.40625        6
-0.038462 -0.076923          128          128.0 {18.7182,0,0.00625} 20.7867,0.40625        6
-0.182692 -0.326923          256          256.0 {21.3177,0,0.40625} 20.8561,0.40625        6
-0.336538 -0.490385          512          512.0 {20.0809,-1,0.40625} 20.0991,0.40625        6
-0.370192 -0.403846         1024         1024.0 {23.1279,0,0.40625} 23.1666,0.40625        6
-0.602202 -0.834212         2048         2048.0 {28.482,-1,0.40625} 29.2854,0.40625        6
-0.635837 -0.669471         4096         4096.0 {20.9853,-1,0.40625} 21.6603,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 0

Starting simulation for: --cats 256 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.689313 -0.742788         8192         8192.0 {13.4643,-1,0.40625} 13.9189,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.667085
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3253; id=1, #l=928; id=2, #l=2354; id=3, #l=0; id=4, #l=538; id=5, #l=1514; id=6, #l=640; id=7, #l=0; id=8, #l=0; id=9, #l=406; id=10, #l=885; id=11, #l=657; id=12, #l=1549; id=13, #l=640; id=14, #l=114; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.295088,0.20625        6
0.000000 0.000000            4            4.0 {0.237361,0,0.20625} 3.49184,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.82982,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.206235,0,0.20625} 2.47177,0.20625        6
0.000000 0.000000           64           64.0 {3.24973,0,0.20625} 1.5994,0.20625        6
0.000000 0.000000          128          128.0 {0.627824,0,0.20625} 2.09507,0.20625        6
-0.094697 -0.189394          256          256.0 {28.3531,-1,0.20625} 27.4438,0.20625        6
-0.265227 -0.435756          512          512.0 {21.0685,0,0.20625} 21.1042,0.20625        6
-0.378825 -0.492424         1024         1024.0 {29.0095,0,0.20625} 29.0857,0.20625        6
-0.618684 -0.858542         2048         2048.0 {27.6767,-1,0.20625} 29.259,0.20625        6
-0.693437 -0.768190         4096         4096.0 {18.0014,-1,0.20625} 19.331,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 1

Starting simulation for: --cats 256 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.730585 -0.767734         8192         8192.0 {19.4297,-1,0.20625} 20.3252,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.725768
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3434; id=1, #l=333; id=2, #l=3030; id=3, #l=0; id=4, #l=329; id=5, #l=2118; id=6, #l=1331; id=7, #l=0; id=8, #l=0; id=9, #l=32; id=10, #l=287; id=11, #l=796; id=12, #l=1500; id=13, #l=916; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.80809e-05,0.267474    
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 2

Starting simulation for: --cats 256 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    6
0.000000 0.000000            2            2.0 {2.80809e-05,0,0.267474} 0.180809,0.267474        6
0.000000 0.000000            4            4.0 {0.136296,0,0.267474} 2.64583,0.267474        6
0.000000 0.000000            8            8.0 {10.35,-1,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.90644,0,0.267474} 9.58581,0.00625        6
0.000000 0.000000           32           32.0 {0.112295,0,0.267474} 1.85925,0.267474        6
0.000000 0.000000           64           64.0 {2.45914,0,0.267474} 1.18657,0.267474        6
0.000000 0.000000          128          128.0 {0.437383,0,0.267474} 1.56878,0.267474        6
0.000000 0.000000          256          256.0 {2.37528,0,0.267474} 1.67413,0.267474        6
-0.095109 -0.190217          512          512.0 {17.4893,-1,0.139583} 17.5421,0.139583        6
-0.262107 -0.429105         1024         1024.0 {25.0439,-1,0.139583} 25.1565,0.139583        6
-0.406629 -0.551151         2048         2048.0 {17.5821,-1,0.139583} 19.9201,0.139583        6
-0.462565 -0.518501         4096         4096.0 {22.1513,-1,0.139583} 24.1159,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.602275 -0.741984         8192         8192.0 {16.9783,-1,0.139583} 18.3014,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.626018
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2679; id=1, #l=918; id=2, #l=1605; id=3, #l=0; id=4, #l=0; id=5, #l=1141; id=6, #l=1294; id=7, #l=0; id=8, #l=0; id=9, #l=160; id=10, #l=568; id=11, #l=1072; id=12, #l=1137; id=13, #l=743; id=14, #l=349; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196775,0.0381702        6
0.000000 0.000000            2            2.0 {0.000196775,0,0.0381702} 1.26701,0.0381702        6
0.000000 0.000000            4            4.0 {0.955083,0,0.0381702} 18.5404,0.0381702        6
-0.204675 -0.409351            8            8.0 {22.6535,-1,0.0381702} 24.6581,0.0381702        6
-0.307013 -0.409351           16           16.0 {20.3667,0,0.0381702} 22.5283,0.0381702        6
-0.364846 -0.422679           32           32.0 {0.786897,0,0.0381702} 13.0286,0.0381702        6
-0.467689 -0.570533           64           64.0 {17.2322,-1,0.0381702} 8.31476,0.0381702        6
-0.352660 -0.237631          128          128.0 {3.06492,0,0.0381702} 10.9931,0.0381702        6
-0.286287 -0.219913          256          256.0 {16.6446,0,0.0381702} 11.7313,0.0381702        6
-0.312858 -0.339430          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.324532 -0.336206         1024         1024.0 {24.6628,-1,0.03125} 25.1656,0.03125        6
-0.330736 -0.336940         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.326213 -0.321690         4096         4096.0 {11.2093,-1,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 3

Starting simulation for: --cats 256 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.322054 -0.317895         8192         8192.0 {20.6363,0,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.316907
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=147; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=139; id=8, #l=36; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=70; 
    n.a.     n.a.            1            1.0  unknown 5.86506e-07,12.8063        6
0.000000 0.000000            2            2.0 {5.86506e-07,0,12.8063} 0.00377643,12.8063        6
0.000000 0.000000            4            4.0 {0.00284671,0,12.8063} 0.0552615,12.8063        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0607047,0,12.8063} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00234542,0,12.8063} 0.0388328,12.8063        6
0.000000 0.000000           64           64.0 {0.0513621,0,12.8063} 0.0247829,12.8063        6
0.000000 0.000000          128          128.0 {0.00913528,0,12.8063} 0.0327658,12.8063        6
0.000000 0.000000          256          256.0 {0.0496107,0,12.8063} 0.0349663,12.8063        6
0.000000 0.000000          512          512.0 {0.0103763,0,12.8063} 0.0109516,12.8063        6
0.000000 0.000000         1024         1024.0 {0.0601825,0,12.8063} 0.0614093,12.8063        6
0.000000 0.000000         2048         2048.0 {0.0152916,0,12.8063} 0.040775,12.8063        6
0.000000 0.000000         4096         4096.0 {0.027353,0,12.8063} 0.0487662,12.8063        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 25

Starting simulation for: --cats 512 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {22.352,-1,12.8063} 22.3664,12.8063        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1372; id=1, #l=0; id=2, #l=1378; id=3, #l=0; id=4, #l=0; id=5, #l=1221; id=6, #l=159; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=592; id=12, #l=633; id=13, #l=160; id=14, #l=2; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.149814,0.40625        6
0.000000 0.000000            4            4.0 {0.120506,0,0.40625} 1.77278,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {1.94437,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.104704,0,0.40625} 1.2549,0.40625        6
0.000000 0.000000           64           64.0 {1.64986,0,0.40625} 0.812003,0.40625        6
0.000000 0.000000          128          128.0 {0.318741,0,0.40625} 1.06365,0.40625        6
0.000000 0.000000          256          256.0 {1.59465,0,0.40625} 1.13301,0.40625        6
-0.408654 -0.817308          512          512.0 {21.0348,-1,0.40625} 21.0529,0.40625        6
-0.338942 -0.269231         1024         1024.0 {24.0818,-1,0.40625} 24.1204,0.40625        6
-0.379808 -0.420673         2048         2048.0 {24.1436,-1,0.40625} 24.9469,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 0

Starting simulation for: --cats 512 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.499409 -0.619009         4096         4096.0 {20.2776,-1,0.40625} 20.9526,0.40625        6
-0.581435 -0.663462         8192         8192.0 {23.772,-1,0.40625} 24.2266,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.564681
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 1

Starting simulation for: --cats 512 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2880; id=1, #l=44; id=2, #l=2469; id=3, #l=0; id=4, #l=28; id=5, #l=2205; id=6, #l=734; id=7, #l=0; id=8, #l=0; id=9, #l=43; id=10, #l=65; id=11, #l=564; id=12, #l=1772; id=13, #l=569; id=14, #l=16; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.264785,0.20625        6
0.000000 0.000000            4            4.0 {0.207058,0,0.20625} 3.46154,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.79951,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.175932,0,0.20625} 2.44147,0.20625        6
0.000000 0.000000           64           64.0 {3.21943,0,0.20625} 1.5691,0.20625        6
-0.056818 -0.113636          128          128.0 {18.0521,-1,0.20625} 19.5193,0.20625        6
-0.198864 -0.340909          256          256.0 {20.5652,-1,0.20625} 19.6559,0.20625        6
-0.383523 -0.568182          512          512.0 {21.261,0,0.00625} 22.4398,0.00625        6
-0.537405 -0.691288         1024         1024.0 {28.9792,-1,0.20625} 29.0554,0.20625        6
-0.767877 -0.998349         2048         2048.0 {27.6464,-1,0.20625} 29.2287,0.20625        6
-0.874048 -0.980219         4096         4096.0 {14.8196,-1,0.20625} 16.1492,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.788882 -0.703717         8192         8192.0 {21.3388,0,0.20625} 22.2342,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.771101
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3259; id=1, #l=783; id=2, #l=2179; id=3, #l=0; id=4, #l=618; id=5, #l=1953; id=6, #l=1396; id=7, #l=0; id=8, #l=0; id=9, #l=204; id=10, #l=287; id=11, #l=882; id=12, #l=963; id=13, #l=1203; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7801e-05,0.270168        6
0.000000 0.000000            2            2.0 {2.7801e-05,0,0.270168} 0.179007,0.270168        6
0.000000 0.000000            4            4.0 {0.134937,0,0.270168} 2.61946,0.270168        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.87747,0,0.270168} 9.58582,0.00625        6
-0.074627 -0.149254           32           32.0 {4.80576,0,0.00625} 19.8314,0.139583        6
-0.261194 -0.447761           64           64.0 {20.9809,0,0.139583} 18.5424,0.139583        6
-0.354478 -0.447761          128          128.0 {17.1068,-1,0.139583} 19.2748,0.139583        6
-0.345149 -0.335821          256          256.0 {20.8203,0,0.139583} 19.4767,0.139583        6
-0.377799 -0.410448          512          512.0 {17.2206,-1,0.139583} 17.2734,0.139583        6
-0.405981 -0.434164         1024         1024.0 {25.6111,-1,0.139583} 25.7236,0.139583        6
-0.506178 -0.606375         2048         2048.0 {17.791,-1,0.139583} 20.129,0.139583        6
-0.546747 -0.587315         4096         4096.0 {18.8976,-1,0.139583} 20.8622,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 2

Starting simulation for: --cats 512 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.591371 -0.635996         8192         8192.0 {24.6499,-1,0.139583} 25.973,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.607927
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2459; id=1, #l=1184; id=2, #l=2045; id=3, #l=0; id=4, #l=0; id=5, #l=1793; id=6, #l=894; id=7, #l=0; id=8, #l=0; id=9, #l=367; id=10, #l=380; id=11, #l=807; id=12, #l=1025; id=13, #l=633; id=14, #l=473; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00019657,0.0382101        6
0.000000 0.000000            2            2.0 {0.00019657,0,0.0382101} 1.26568,0.0382101        6
0.000000 0.000000            4            4.0 {0.954087,0,0.0382101} 18.5211,0.0382101        6
-0.204462 -0.408924            8            8.0 {22.6299,-1,0.0382101} 24.6323,0.0382101        6
-1.033924 -1.863386           16           16.0 {20.3454,-1,0.0382101} 22.5049,0.0382101        6
-0.677030 -0.320135           32           32.0 {0.786076,0,0.0382101} 13.015,0.0382101        6
-0.761795 -0.846560           64           64.0 {19.4565,-1,0.0338065} 9.38802,0.0338065        6
-0.514681 -0.267568          128          128.0 {3.46054,0,0.0338065} 12.412,0.0338065        6
-0.432669 -0.350656          256          256.0 {18.793,0,0.0338065} 13.2456,0.0338065        6
-0.375964 -0.319258          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.345653 -0.315342         1024         1024.0 {24.6628,-1,0.03125} 25.1656,0.03125        6
-0.350489 -0.355326         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.330833 -0.311176         4096         4096.0 {11.2093,0,0.03125}
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 3

Starting simulation for: --cats 512 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 19.9844,0.03125        6
-0.324689 -0.318544         8192         8192.0 {20.6363,0,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.326244
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=170; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=146; id=8, #l=45; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=70; 
    n.a.     n.a.            1            1.0  unknown 2.93324e-07,25.6063        6
0.000000 0.000000            2            2.0 {2.93324e-07,0,25.6063} 0.00188867,25.6063        6
0.000000 0.000000            4            4.0 {0.0014237,0,25.6063} 0.0276375,25.6063        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0303598,0,25.6063} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00117299,0,25.6063} 0.0194211,25.6063        6
0.000000 0.000000           64           64.0 {0.0256873,0,25.6063} 0.0123945,25.6063        6
0.000000 0.000000          128          128.0 {0.00456875,0,25.6063} 0.0163869,25.6063        6
0.000000 0.000000          256          256.0 {0.0248114,0,25.6063} 0.0174874,25.6063        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 25

Starting simulation for: --cats 1024 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000          512          512.0 {0.0051894,0,25.6063} 0.00547714,25.6063        6
0.000000 0.000000         1024         1024.0 {0.0300986,0,25.6063} 0.0307122,25.6063        6
0.000000 0.000000         2048         2048.0 {0.00764769,0,25.6063} 0.0203925,25.6063        6
0.000000 0.000000         4096         4096.0 {0.0136799,0,25.6063} 0.0243891,25.6063        6
0.000000 0.000000         8192
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>         8192.0 {0.0251847,0,25.6063} 4.73021,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=0; id=2, #l=1; id=3, #l=0; id=4, #l=0; id=5, #l=1; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=1; id=11, #l=1; id=12, #l=1; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.134429,0.40625        6
0.000000 0.000000            4            4.0 {0.105122,0,0.40625} 1.7574,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {1.92898,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0893194,0,0.40625} 1.23951,0.40625        6
0.000000 0.000000           64           64.0 {1.63448,0,0.40625} 0.796618,0.40625        6
0.000000 0.000000          128          128.0 {0.303357,0,0.40625} 1.04826,0.40625        6
0.000000 0.000000          256          256.0 {1.57927,0,0.40625} 1.11763,0.40625        6
-0.326923 -0.653846          512          512.0 {21.261,0,0.00625} 22.4398,0.00625        6
-0.312639 -0.298355         1024         1024.0 {13.7279,-1,0.40625} 13.7666,0.40625        6
-0.556560 -0.800481         2048         2048.0 {19.8205,-1,0.40625} 20.6238,0.40625        6
-0.768665 -0.980769         4096         4096.0 {20.1084,-1,0.40625} 20.7834,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 0

Starting simulation for: --cats 1024 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.713058 -0.657452         8192         8192.0 {22.772,0,0.40625} 23.2266,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.699583
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2870; id=1, #l=1546; id=2, #l=1326; id=3, #l=0; id=4, #l=1220; id=5, #l=820; id=6, #l=243; id=7, #l=0; id=8, #l=0; id=9, #l=390; id=10, #l=1349; id=11, #l=382; id=12, #l=815; id=13, #l=204; id=14, #l=119; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.249633,0.20625        6
0.000000 0.000000            4            4.0 {0.191906,0,0.20625} 3.44639,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.78436,0,0.20625} 9.58583,0.00625        6
0.000000 0.000000           32           32.0 {4.80576,0,0.00625} 19.8809,0.20625        6
-0.151515 -0.303030           64           64.0 {20.6588,-1,0.20625} 19.0085,0.20625        6
-0.170455 -0.189394          128          128.0 {18.0369,-1,0.20625} 19.5042,0.20625        6
-0.558712 -0.946970          256          256.0 {22.4895,-1,0.20625} 21.5802,0.20625        6
-0.658144 -0.757576          512          512.0 {18.114,-1,0.20625} 18.1497,0.20625        6
-0.572917 -0.487689         1024         1024.0 {18.2368,-1,0.20625} 18.313,0.20625        6
-0.763494 -0.954072         2048         2048.0 {14.7525,-1,0.20625} 16.3348,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 1

Starting simulation for: --cats 1024 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.733902 -0.704309         4096         4096.0 {19.8953,-1,0.20625} 21.2249,0.20625        6
-0.763494 -0.793087         8192         8192.0 {26.2934,-1,0.20625} 27.1888,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.792970
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 2

Starting simulation for: --cats 1024 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3148; id=1, #l=586; id=2, #l=2715; id=3, #l=0; id=4, #l=644; id=5, #l=2093; id=6, #l=1432; id=7, #l=0; id=8, #l=0; id=9, #l=30; id=10, #l=585; id=11, #l=745; id=12, #l=1396; id=13, #l=505; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7661e-05,0.271535        6
0.000000 0.000000            2            2.0 {2.7661e-05,0,0.271535} 0.178105,0.271535        6
0.000000 0.000000            4            4.0 {0.134258,0,0.271535} 2.60627,0.271535        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.86298,0,0.271535} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.110616,0,0.271535} 1.83145,0.271535        6
0.000000 0.000000           64           64.0 {2.42236,0,0.271535} 1.16882,0.271535        6
0.000000 0.000000          128          128.0 {0.430842,0,0.271535} 1.54532,0.271535        6
-0.273632 -0.547264          256          256.0 {13.1635,-1,0.139583} 11.82,0.139583        6
-0.274030 -0.274427          512          512.0 {11.4744,0,0.139583} 11.5272,0.139583        6
-0.538947 -0.803865         1024         1024.0 {27.8648,-1,0.139583} 27.9774,0.139583        6
-0.596443 -0.653938         2048         2048.0 {17.6567,-1,0.139583} 19.9947,0.139583        6
-0.588250 -0.580058         4096         4096.0 {18.9125,-1,0.139583} 20.8771,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.699025 -0.809800         8192         8192.0 {15.3514,-1,0.139583} 16.6745,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.694710
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3159; id=1, #l=1308; id=2, #l=2245; id=3, #l=1; id=4, #l=0; id=5, #l=1129; id=6, #l=492; id=7, #l=0; id=8, #l=0; id=9, #l=376; id=10, #l=429; id=11, #l=469; id=12, #l=947; id=13, #l=840; id=14, #l=513; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196467,0.03823        6
0.000000 0.000000            2            2.0 {0.000196467,0,0.03823} 1.26502,0.03823        6
0.000000 0.000000            4            4.0 {0.953589,0,0.03823} 18.5114,0.03823        6
0.000000 0.000000            8            8.0 {22.618,0,0.03823} 24.6195,0.03823        6
-0.829355 -1.658710           16           16.0 {20.3348,-1,0.03823} 22.4931,0.03823        6
-0.567944 -0.306533           32           32.0 {0.785665,0,0.03823} 13.0082,0.03823        6
-0.583012 -0.598081           64           64.0 {19.448,-1,0.0338214} 9.3839,0.0338214        6
-0.437839 -0.292665          128          128.0 {3.45902,0,0.0338214} 12.4066,0.0338214        6
-0.325427 -0.213015          256          256.0 {18.7848,-1,0.0338214} 13.2398,0.0338214        6
-0.321209 -0.316992          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.340201 -0.359193         1024         1024.0 {24.6628,-1,0.03125} 25.1656,0.03125        6
-0.320609 -0.301017         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 3

Starting simulation for: --cats 1024 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.315433 -0.310257         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
-0.322168 -0.328903         8192         8192.0 {20.6363,-1,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.322969
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=160; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=132; id=8, #l=51; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=73; 
    n.a.     n.a.            1            1.0  unknown 1.4668e-07,51.2062        6
0.000000 0.000000            2            2.0 {1.4668e-07,0,51.2062} 0.000944452,51.2062        6
0.000000 0.000000            4            4.0 {0.000711939,0,51.2062} 0.0138204,51.2062        6
0.000000 0.000000            8            8.0 {10.3501,-1,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0151817,0,51.2062} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.000586569,0,51.2062} 0.00971176,51.2062        6
0.000000 0.000000           64           64.0 {0.0128452,0,51.2062} 0.006198,51.2062        6
0.000000 0.000000          128          128.0 {0.00228466,0,51.2062} 0.00819446,51.2062        6
0.000000 0.000000          256          256.0 {0.0124072,0,51.2062} 0.00874478,51.2062        6
0.000000 0.000000          512          512.0 {0.00259502,0,51.2062} 0.0027389,51.2062        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 25

Starting simulation for: --cats 2048 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         1024         1024.0 {0.0150511,0,51.2062} 0.015358,51.2062        6
0.000000 0.000000         2048         2048.0 {0.00382431,0,51.2062} 0.0101975,51.2062        6
0.000000 0.000000         4096         4096.0 {0.00684076,0,51.2062} 0.012196,51.2062        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {0.0125939,0,51.2062} 4.73022,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.126737,0.40625        6
0.000000 0.000000            4            4.0 {0.0974294,0,0.40625} 1.7497,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {1.92129,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0816271,0,0.40625} 1.23182,0.40625        6
0.000000 0.000000           64           64.0 {1.62679,0,0.40625} 0.788926,0.40625        6
0.000000 0.000000          128          128.0 {0.295664,0,0.40625} 1.04057,0.40625        6
0.000000 0.000000          256          256.0 {1.57158,0,0.40625} 1.10994,0.40625        6
-0.312500 -0.625000          512          512.0 {0.334784,0,0.40625} 0.352921,0.40625        6
-0.502404 -0.692308         1024         1024.0 {24.551,-1,0.40625} 24.5897,0.40625        6
-0.707933 -0.913462         2048         2048.0 {16.982,-1,0.40625} 17.7854,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 0

Starting simulation for: --cats 2048 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.746394 -0.784856         4096         4096.0 {23.7623,-1,0.40625} 24.4373,0.40625        6
-0.769231 -0.792067         8192         8192.0 {24.7336,-1,0.40625} 25.1882,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.743385
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 1

Starting simulation for: --cats 2048 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3659; id=1, #l=390; id=2, #l=3175; id=3, #l=0; id=4, #l=277; id=5, #l=2275; id=6, #l=1360; id=7, #l=0; id=8, #l=0; id=9, #l=151; id=10, #l=256; id=11, #l=703; id=12, #l=859; id=13, #l=1008; id=14, #l=38; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.242057,0.20625        6
0.000000 0.000000            4            4.0 {0.184331,0,0.20625} 3.43881,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.77679,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.153205,0,0.20625} 2.41874,0.20625        6
0.000000 0.000000           64           64.0 {3.1967,0,0.20625} 1.54637,0.20625        6
0.000000 0.000000          128          128.0 {0.574794,0,0.20625} 2.04204,0.20625        6
0.000000 0.000000          256          256.0 {3.08795,0,0.20625} 2.17867,0.20625        6
-0.165720 -0.331439          512          512.0 {18.1064,0,0.20625} 18.1421,0.20625        6
-0.317235 -0.468750         1024         1024.0 {28.9565,-1,0.20625} 29.0327,0.20625        6
-0.501257 -0.685279         2048         2048.0 {27.6237,-1,0.20625} 29.206,0.20625        6
-0.644098 -0.786939         4096         4096.0 {16.0999,-1,0.20625} 17.4295,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.732207 -0.820316         8192         8192.0 {27.1191,-1,0.20625} 28.0146,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.758416
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3276; id=1, #l=1471; id=2, #l=2660; id=3, #l=0; id=4, #l=884; id=5, #l=1102; id=6, #l=600; id=7, #l=0; id=8, #l=0; id=9, #l=579; id=10, #l=250; id=11, #l=690; id=12, #l=268; id=13, #l=987; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7591e-05,0.272224        6
0.000000 0.000000            2            2.0 {2.7591e-05,0,0.272224} 0.177655,0.272224        6
0.000000 0.000000            4            4.0 {0.133918,0,0.272224} 2.59967,0.272224        6
0.000000 0.000000            8            8.0 {10.35,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.85573,0,0.272224} 9.58581,0.00625        6
0.000000 0.000000           32           32.0 {0.110336,0,0.272224} 1.82681,0.272224        6
0.000000 0.000000           64           64.0 {2.41623,0,0.272224} 1.16586,0.272224        6
0.000000 0.000000          128          128.0 {0.429751,0,0.272224} 1.54141,0.272224        6
0.000000 0.000000          256          256.0 {2.33384,0,0.272224} 1.64492,0.272224        6
-0.180356 -0.360712          512          512.0 {21.261,-1,0.00625} 22.4398,0.00625        6
-0.428954 -0.677552         1024         1024.0 {29.1708,-1,0.139583} 29.2833,0.139583        6
-0.504646 -0.580337         2048         2048.0 {11.3209,-1,0.139583} 13.6589,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 2

Starting simulation for: --cats 2048 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.584430 -0.664215         4096         4096.0 {21.5916,-1,0.139583} 23.5562,0.139583        6
-0.704945 -0.825459         8192         8192.0 {27.3738,-1,0.139583} 28.6969,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.717896
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 3

Starting simulation for: --cats 2048 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3145; id=1, #l=1676; id=2, #l=1357; id=3, #l=1; id=4, #l=0; id=5, #l=1367; id=6, #l=876; id=7, #l=0; id=8, #l=0; id=9, #l=589; id=10, #l=367; id=11, #l=1075; id=12, #l=808; id=13, #l=515; id=14, #l=361; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196416,0.03824        6
0.000000 0.000000            2            2.0 {0.000196416,0,0.03824} 1.26469,0.03824        6
0.000000 0.000000            4            4.0 {0.953339,0,0.03824} 18.5066,0.03824        6
-0.408604 -0.817207            8            8.0 {22.6121,-1,0.03824} 24.613,0.03824        6
-0.510754 -0.612905           16           16.0 {20.3295,-1,0.03824} 22.4872,0.03824        6
-0.357528 -0.204302           32           32.0 {0.78546,0,0.03824} 13.0048,0.03824        6
-0.313467 -0.269407           64           64.0 {17.2007,0,0.03824} 8.29959,0.03824        6
-0.247440 -0.181413          128          128.0 {3.05933,0,0.03824} 10.973,0.03824        6
-0.224178 -0.200916          256          256.0 {16.6142,0,0.03824} 11.7099,0.03824        6
-0.236072 -0.247965          512          512.0 {3.47492,0,0.03824} 3.6676,0.03824        6
-0.286500 -0.336928         1024         1024.0 {24.6628,-1,0.03125} 25.1656,0.03125        6
-0.321620 -0.356741         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.319474 -0.317328         4096         4096.0 {11.2093,-1,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.325989 -0.332505         8192         8192.0 {20.6363,-1,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.323575
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 25

Plotting...
</pre></div>
</div>
<img alt="../_images/python_cats_21_88.png" src="../_images/python_cats_21_88.png" />
</div>
</div>
</div>
<div class="section" id="id2">
<h3>Without Learning<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># do parameter sweeping</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">]</span>
<span class="n">bandwidths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span>

<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="k">for</span> <span class="n">actions</span> <span class="ow">in</span> <span class="n">num_actions</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="n">bandwidths</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">bd</span> <span class="o">&gt;=</span> <span class="n">actions</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting simulation for: --cats </span><span class="si">{}</span><span class="s2"> --bandwidth </span><span class="si">{}</span><span class="s2"> --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
        <span class="n">rr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done with simulation for num_actions: </span><span class="si">{}</span><span class="s2"> and bandwidth: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)][</span><span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">rr</span><span class="p">,</span> <span class="n">hits</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Plotting...&quot;</span><span class="p">)</span>
<span class="n">plot_reward_sweep</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">bandwidths</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting simulation for: --cats 8 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 8 and bandwidth: 0

Starting simulation for: --cats 8 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=169; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=128; id=8, #l=43; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=81; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
    n.a.     n.a.            2            2.0  unknown 0.234482,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.43124,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.41116,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.53879,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.03446,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.17109,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.679995,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.81296,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.53176,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.02794,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 1.10366,0.40625        6
    n.a.     n.a.            4            4.0  unknown 2.72663,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.20875,0.40625        6
    n.a.     n.a.           64           64.0  unknown 1.76585,0.40625        6
    n.a.     n.a.          128          128.0  unknown 2.0175,0.40625        6
    n.a.     n.a.          256          256.0  unknown 2.08686,0.40625        6
    n.a.     n.a.          512          512.0  unknown 1.32984,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.92043,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         2048         2048.0  unknown 2.26997,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 2.52188,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
    n.a.     n.a.            2            2.0  unknown 0.234482,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.43124,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.41116,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.53879,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.03446,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.17109,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.679995,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.81296,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.53176,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.02794,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 1

Starting simulation for: --cats 8 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 8 and bandwidth: 2

Starting simulation for: --cats 8 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 3.21214,0.139583        6
    n.a.     n.a.            4            4.0  unknown 7.93571,0.139583        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 6.42844,0.139583        6
    n.a.     n.a.           64           64.0  unknown 5.13941,0.139583        6
    n.a.     n.a.          128          128.0  unknown 5.87181,0.139583        6
    n.a.     n.a.          256          256.0  unknown 6.0737,0.139583        6
    n.a.     n.a.          512          512.0  unknown 3.87044,0.139583        6
    n.a.     n.a.         1024         1024.0  unknown 8.49975,0.139583        6
    n.a.     n.a.         2048         2048.0  unknown 6.60663,0.139583        6
    n.a.     n.a.         4096         4096.0  unknown 7.33979,0.139583        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 9.31589e-06,0.80625        6
    n.a.     n.a.            2            2.0  unknown 0.0599837,0.80625        6
    n.a.     n.a.            4            4.0  unknown 0.877758,0.80625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.616809,0.80625        6
    n.a.     n.a.           64           64.0  unknown 0.393645,0.80625        6
    n.a.     n.a.          128          128.0  unknown 0.520443,0.80625        6
    n.a.     n.a.          256          256.0  unknown 0.555395,0.80625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 32 and bandwidth: 0

Starting simulation for: --cats 32 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.          512          512.0  unknown 0.173952,0.80625        6
    n.a.     n.a.         1024         1024.0  unknown 0.975409,0.80625        6
    n.a.     n.a.         2048         2048.0  unknown 0.647659,0.80625        6
    n.a.     n.a.         4096         4096.0  unknown 0.774589,0.80625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.611352,0.40625        6
    n.a.     n.a.            4            4.0  unknown 2.23432,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.71644,0.40625        6
    n.a.     n.a.           64           64.0  unknown 1.27354,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.52519,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.59455,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.837536,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.42812,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         2048         2048.0  unknown 1.77766,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 2.02957,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.71933,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.91608,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.89601,0.20625        6
    n.a.     n.a.           64           64.0  unknown 2.02364,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.51931,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.65594,0.20625        6
    n.a.     n.a.          512          512.0  unknown 1.16484,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 4.29781,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 3.01661,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 1

Starting simulation for: --cats 32 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 32 and bandwidth: 2

Starting simulation for: --cats 32 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 3.51279,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.19857e-05,0.234821        6
    n.a.     n.a.            2            2.0  unknown 0.205952,0.234821        6
    n.a.     n.a.            4            4.0  unknown 3.01375,0.234821        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.11779,0.234821        6
    n.a.     n.a.           64           64.0  unknown 1.35156,0.234821        6
    n.a.     n.a.          128          128.0  unknown 1.78692,0.234821        6
    n.a.     n.a.          256          256.0  unknown 1.90693,0.234821        6
    n.a.     n.a.          512          512.0  unknown 0.597258,0.234821        6
    n.a.     n.a.         1024         1024.0  unknown 3.34903,0.234821        6
    n.a.     n.a.         2048         2048.0  unknown 2.22371,0.234821        6
    n.a.     n.a.         4096         4096.0  unknown 2.65952,0.234821        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000199639,0.0376226        6
    n.a.     n.a.            2            2.0  unknown 1.28545,0.0376226        6
    n.a.     n.a.            4            4.0  unknown 18.8103,0.0376226        6
    n.a.     n.a.            8            8.0  unknown 25.017,0.0376226        6
    n.a.     n.a.           16           16.0  unknown 22.8563,0.0376226        6
    n.a.     n.a.           32           32.0  unknown 13.2182,0.0376226        6
    n.a.     n.a.           64           64.0  unknown 8.4358,0.0376226        6
    n.a.     n.a.          128          128.0  unknown 11.1531,0.0376226        6
    n.a.     n.a.          256          256.0  unknown 11.9021,0.0376226        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 32 and bandwidth: 25

Starting simulation for: --cats 64 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.          512          512.0  unknown 3.72779,0.0376226        6
    n.a.     n.a.         1024         1024.0  unknown 20.903,0.0376226        6
    n.a.     n.a.         2048         2048.0  unknown 13.8793,0.0376226        6
    n.a.     n.a.         4096         4096.0  unknown 16.5994,0.0376226        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 4.67607e-06,1.60625        6
    n.a.     n.a.            2            2.0  unknown 0.0301085,1.60625        6
    n.a.     n.a.            4            4.0  unknown 0.440587,1.60625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.309605,1.60625        6
    n.a.     n.a.           64           64.0  unknown 0.197588,1.60625        6
    n.a.     n.a.          128          128.0  unknown 0.261234,1.60625        6
    n.a.     n.a.          256          256.0  unknown 0.278778,1.60625        6
    n.a.     n.a.          512          512.0  unknown 0.0873145,1.60625        6
    n.a.     n.a.         1024         1024.0  unknown 0.489602,1.60625        6
    n.a.     n.a.         2048         2048.0  unknown 0.32509,1.60625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 0.388802,1.60625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.365198,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.98817,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.47028,0.40625        6
    n.a.     n.a.           64           64.0  unknown 1.02739,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.27903,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.3484,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.591382,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.18197,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.53151,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 1.78342,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.476906,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.67366,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58583,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.65359,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.78122,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.27689,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.41351,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 0

Starting simulation for: --cats 64 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 64 and bandwidth: 1

Starting simulation for: --cats 64 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.          512          512.0  unknown 0.922419,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 4.05539,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.77418,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.27036,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.97576e-05,0.252404        6
    n.a.     n.a.            2            2.0  unknown 0.191605,0.252404        6
    n.a.     n.a.            4            4.0  unknown 2.80381,0.252404        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.97027,0.252404        6
    n.a.     n.a.           64           64.0  unknown 1.25741,0.252404        6
    n.a.     n.a.          128          128.0  unknown 1.66244,0.252404        6
    n.a.     n.a.          256          256.0  unknown 1.77409,0.252404        6
    n.a.     n.a.          512          512.0  unknown 0.555653,0.252404        6
    n.a.     n.a.         1024         1024.0  unknown 3.11573,0.252404        6
    n.a.     n.a.         2048         2048.0  unknown 2.06881,0.252404        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 2

Starting simulation for: --cats 64 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 64 and bandwidth: 3

Starting simulation for: --cats 64 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 2.47426,0.252404        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000198004,0.0379332        6
    n.a.     n.a.            2            2.0  unknown 1.27492,0.0379332        6
    n.a.     n.a.            4            4.0  unknown 18.6563,0.0379332        6
    n.a.     n.a.            8            8.0  unknown 24.8121,0.0379332        6
    n.a.     n.a.           16           16.0  unknown 22.6691,0.0379332        6
    n.a.     n.a.           32           32.0  unknown 13.11,0.0379332        6
    n.a.     n.a.           64           64.0  unknown 8.36672,0.0379332        6
    n.a.     n.a.          128          128.0  unknown 11.0618,0.0379332        6
    n.a.     n.a.          256          256.0  unknown 11.8046,0.0379332        6
    n.a.     n.a.          512          512.0  unknown 3.69726,0.0379332        6
    n.a.     n.a.         1024         1024.0  unknown 20.7318,0.0379332        6
    n.a.     n.a.         2048         2048.0  unknown 13.7657,0.0379332        6
    n.a.     n.a.         4096         4096.0  unknown 16.4635,0.0379332        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; i
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 25

Starting simulation for: --cats 128 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 128 and bandwidth: 0

Starting simulation for: --cats 128 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>d=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.34259e-06,3.20625        6
    n.a.     n.a.            2            2.0  unknown 0.0150836,3.20625        6
    n.a.     n.a.            4            4.0  unknown 0.220723,3.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.155104,3.20625        6
    n.a.     n.a.           64           64.0  unknown 0.0989867,3.20625        6
    n.a.     n.a.          128          128.0  unknown 0.130872,3.20625        6
    n.a.     n.a.          256          256.0  unknown 0.139661,3.20625        6
    n.a.     n.a.          512          512.0  unknown 0.0437424,3.20625        6
    n.a.     n.a.         1024         1024.0  unknown 0.245278,3.20625        6
    n.a.     n.a.         2048         2048.0  unknown 0.162862,3.20625        6
    n.a.     n.a.         4096         4096.0  unknown 0.19478,3.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.242121,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.86509,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.34721,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.904311,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.15596,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.22532,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.468305,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.05889,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.40843,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 1.66034,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.355694,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.55245,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.53238,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.66001,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.15567,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.2923,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.801207,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.93417,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.65297,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.14915,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 1

Starting simulation for: --cats 128 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 128 and bandwidth: 2

Starting simulation for: --cats 128 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.86404e-05,0.26225        6
    n.a.     n.a.            2            2.0  unknown 0.184411,0.26225        6
    n.a.     n.a.            4            4.0  unknown 2.69854,0.26225        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.89629,0.26225        6
    n.a.     n.a.           64           64.0  unknown 1.2102,0.26225        6
    n.a.     n.a.          128          128.0  unknown 1.60003,0.26225        6
    n.a.     n.a.          256          256.0  unknown 1.70748,0.26225        6
    n.a.     n.a.          512          512.0  unknown 0.534791,0.26225        6
    n.a.     n.a.         1024         1024.0  unknown 2.99875,0.26225        6
    n.a.     n.a.         2048         2048.0  unknown 1.99114,0.26225        6
    n.a.     n.a.         4096         4096.0  unknown 2.38136,0.26225        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000197185,0.0380908        6
    n.a.     n.a.            2            2.0  unknown 1.26965,0.0380908        6
    n.a.     n.a.            4            4.0  unknown 18.5791,0.0380908        6
    n.a.     n.a.            8            8.0  unknown 24.7095,0.0380908        6
    n.a.     n.a.           16           16.0  unknown 22.5753,0.0380908        6
    n.a.     n.a.           32           32.0  unknown 13.0557,0.0380908        6
    n.a.     n.a.           64           64.0  unknown 8.3321,0.0380908        6
    n.a.     n.a.          128          128.0  unknown 11.016,0.0380908        6
    n.a.     n.a.          256          256.0  unknown 11.7558,0.0380908        6
    n.a.     n.a.          512          512.0  unknown 3.68196,0.0380908        6
    n.a.     n.a.         1024         1024.0  unknown 20.646,0.0380908        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 3

Starting simulation for: --cats 128 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 128 and bandwidth: 25

Starting simulation for: --cats 256 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         2048         2048.0  unknown 13.7087,0.0380908        6
    n.a.     n.a.         4096         4096.0  unknown 16.3954,0.0380908        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 1.17244e-06,6.40625        6
    n.a.     n.a.            2            2.0  unknown 0.00754917,6.40625        6
    n.a.     n.a.            4            4.0  unknown 0.110469,6.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.0776277,6.40625        6
    n.a.     n.a.           64           64.0  unknown 0.0495416,6.40625        6
    n.a.     n.a.          128          128.0  unknown 0.0654997,6.40625        6
    n.a.     n.a.          256          256.0  unknown 0.0698985,6.40625        6
    n.a.     n.a.          512          512.0  unknown 0.0218925,6.40625        6
    n.a.     n.a.         1024         1024.0  unknown 0.122759,6.40625        6
    n.a.     n.a.         2048         2048.0  unknown 0.0815103,6.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 0.0974849,6.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.180583,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.80355,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.28567,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.842772,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.09442,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.16378,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.406767,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 1.99735,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.34689,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 1.5988,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.295088,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.49184,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.47177,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.5994,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.09507,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.2317,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.740601,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 0

Starting simulation for: --cats 256 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 256 and bandwidth: 1

Starting simulation for: --cats 256 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         1024         1024.0  unknown 3.87357,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.59236,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.08855,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.80809e-05,0.267474        6
    n.a.     n.a.            2            2.0  unknown 0.180809,0.267474        6
    n.a.     n.a.            4            4.0  unknown 2.64583,0.267474        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58581,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.85925,0.267474        6
    n.a.     n.a.           64           64.0  unknown 1.18657,0.267474        6
    n.a.     n.a.          128          128.0  unknown 1.56878,0.267474        6
    n.a.     n.a.          256          256.0  unknown 1.67413,0.267474        6
    n.a.     n.a.          512          512.0  unknown 0.524345,0.267474        6
    n.a.     n.a.         1024         1024.0  unknown 2.94018,0.267474        6
    n.a.     n.a.         2048         2048.0  unknown 1.95224,0.267474        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 2

Starting simulation for: --cats 256 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 256 and bandwidth: 3

Starting simulation for: --cats 256 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 2.33485,0.267474        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196775,0.0381702        6
    n.a.     n.a.            2            2.0  unknown 1.26701,0.0381702        6
    n.a.     n.a.            4            4.0  unknown 18.5404,0.0381702        6
    n.a.     n.a.            8            8.0  unknown 24.6581,0.0381702        6
    n.a.     n.a.           16           16.0  unknown 22.5283,0.0381702        6
    n.a.     n.a.           32           32.0  unknown 13.0286,0.0381702        6
    n.a.     n.a.           64           64.0  unknown 8.31476,0.0381702        6
    n.a.     n.a.          128          128.0  unknown 10.9931,0.0381702        6
    n.a.     n.a.          256          256.0  unknown 11.7313,0.0381702        6
    n.a.     n.a.          512          512.0  unknown 3.67431,0.0381702        6
    n.a.     n.a.         1024         1024.0  unknown 20.6031,0.0381702        6
    n.a.     n.a.         2048         2048.0  unknown 13.6802,0.0381702        6
    n.a.     n.a.         4096         4096.0  unknown 16.3613,0.0381702        6

finished run
number of examples = 5000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 25

Starting simulation for: --cats 512 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 512 and bandwidth: 0

Starting simulation for: --cats 512 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 5.86506e-07,12.8063        6
    n.a.     n.a.            2            2.0  unknown 0.00377643,12.8063        6
    n.a.     n.a.            4            4.0  unknown 0.0552615,12.8063        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.0388328,12.8063        6
    n.a.     n.a.           64           64.0  unknown 0.0247829,12.8063        6
    n.a.     n.a.          128          128.0  unknown 0.0327658,12.8063        6
    n.a.     n.a.          256          256.0  unknown 0.0349663,12.8063        6
    n.a.     n.a.          512          512.0  unknown 0.0109516,12.8063        6
    n.a.     n.a.         1024         1024.0  unknown 0.0614093,12.8063        6
    n.a.     n.a.         2048         2048.0  unknown 0.040775,12.8063        6
    n.a.     n.a.         4096         4096.0  unknown 0.0487662,12.8063        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.149814,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.77278,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.2549,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.812003,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.06365,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.13301,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.375997,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         1024         1024.0  unknown 1.96658,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.31612,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 1.56803,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.264785,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.46154,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.44147,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.5691,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.06476,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.20139,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.710298,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.84327,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.56206,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 1

Starting simulation for: --cats 512 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 512 and bandwidth: 2

Starting simulation for: --cats 512 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 3.05824,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7801e-05,0.270168        6
    n.a.     n.a.            2            2.0  unknown 0.179007,0.270168        6
    n.a.     n.a.            4            4.0  unknown 2.61946,0.270168        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.84072,0.270168        6
    n.a.     n.a.           64           64.0  unknown 1.17474,0.270168        6
    n.a.     n.a.          128          128.0  unknown 1.55314,0.270168        6
    n.a.     n.a.          256          256.0  unknown 1.65744,0.270168        6
    n.a.     n.a.          512          512.0  unknown 0.519119,0.270168        6
    n.a.     n.a.         1024         1024.0  unknown 2.91087,0.270168        6
    n.a.     n.a.         2048         2048.0  unknown 1.93278,0.270168        6
    n.a.     n.a.         4096         4096.0  unknown 2.31157,0.270168        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00019657,0.0382101        6
    n.a.     n.a.   
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 3

Starting simulation for: --cats 512 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 512 and bandwidth: 25

Starting simulation for: --cats 1024 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>         2            2.0  unknown 1.26568,0.0382101        6
    n.a.     n.a.            4            4.0  unknown 18.5211,0.0382101        6
    n.a.     n.a.            8            8.0  unknown 24.6323,0.0382101        6
    n.a.     n.a.           16           16.0  unknown 22.5049,0.0382101        6
    n.a.     n.a.           32           32.0  unknown 13.015,0.0382101        6
    n.a.     n.a.           64           64.0  unknown 8.30609,0.0382101        6
    n.a.     n.a.          128          128.0  unknown 10.9816,0.0382101        6
    n.a.     n.a.          256          256.0  unknown 11.7191,0.0382101        6
    n.a.     n.a.          512          512.0  unknown 3.67047,0.0382101        6
    n.a.     n.a.         1024         1024.0  unknown 20.5816,0.0382101        6
    n.a.     n.a.         2048         2048.0  unknown 13.6659,0.0382101        6
    n.a.     n.a.         4096         4096.0  unknown 16.3442,0.0382101        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.93324e-07,25.6063        6
    n.a.     n.a.            2            2.0  unknown 0.00188867,25.6063        6
    n.a.     n.a.            4            4.0  unknown 0.0276375,25.6063        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.0194211,25.6063        6
    n.a.     n.a.           64           64.0  unknown 0.0123945,25.6063        6
    n.a.     n.a.          128          128.0  unknown 0.0163869,25.6063        6
    n.a.     n.a.          256          256.0  unknown 0.0174874,25.6063        6
    n.a.     n.a.          512          512.0  unknown 0.00547714,25.6063        6
    n.a.     n.a.         1024         1024.0  unknown 0.0307122,25.6063        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         2048         2048.0  unknown 0.0203925,25.6063        6
    n.a.     n.a.         4096         4096.0  unknown 0.0243891,25.6063        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.134429,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.7574,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.23951,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.796618,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.04826,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.11763,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.360613,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 1.9512,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.30074,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 0

Starting simulation for: --cats 1024 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 1024 and bandwidth: 1

Starting simulation for: --cats 1024 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 1.55265,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.249633,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.44639,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58583,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.42632,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.55395,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.04961,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.18624,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.695147,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.82811,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.54691,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.04309,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 2

Starting simulation for: --cats 1024 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 1024 and bandwidth: 3

Starting simulation for: --cats 1024 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7661e-05,0.271535        6
    n.a.     n.a.            2            2.0  unknown 0.178105,0.271535        6
    n.a.     n.a.            4            4.0  unknown 2.60627,0.271535        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.83145,0.271535        6
    n.a.     n.a.           64           64.0  unknown 1.16882,0.271535        6
    n.a.     n.a.          128          128.0  unknown 1.54532,0.271535        6
    n.a.     n.a.          256          256.0  unknown 1.6491,0.271535        6
    n.a.     n.a.          512          512.0  unknown 0.516504,0.271535        6
    n.a.     n.a.         1024         1024.0  unknown 2.89621,0.271535        6
    n.a.     n.a.         2048         2048.0  unknown 1.92305,0.271535        6
    n.a.     n.a.         4096         4096.0  unknown 2.29993,0.271535        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196467,0.03823        6
    n.a.     n.a.            2            2.0  unknown 1.26502,0.03823        6
    n.a.     n.a.            4            4.0  unknown 18.5114,0.03823        6
    n.a.     n.a.            8            8.0  unknown 24.6195,0.03823        6
    n.a.     n.a.           16           16.0  unknown 22.4931,0.03823        6
    n.a.     n.a.           32           32.0  unknown 13.0082,0.03823        6
    n.a.     n.a.           64           64.0  unknown 8.30175,0.03823        6
    n.a.     n.a.          128          128.0  unknown 10.9759,0.03823        6
    n.a.     n.a.          256          256.0  unknown 11.713,0.03823        6
    n.a.     n.a.          512          512.0  unknown 3.66856,0.03823        6
    n.a.     n.a.         1024         1024.0  unknown 20.5708,0.03823        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         2048         2048.0  unknown 13.6588,0.03823        6
    n.a.     n.a.         4096         4096.0  unknown 16.3357,0.03823        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 1.4668e-07,51.2062        6
    n.a.     n.a.            2            2.0  unknown 0.000944452,51.2062        6
    n.a.     n.a.            4            4.0  unknown 0.0138204,51.2062        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.00971176,51.2062        6
    n.a.     n.a.           64           64.0  unknown 0.006198,51.2062        6
    n.a.     n.a.          128          128.0  unknown 0.00819446,51.2062        6
    n.a.     n.a.          256          256.0  unknown 0.00874478,51.2062        6
    n.a.     n.a.          512          512.0  unknown 0.0027389,51.2062        6
    n.a.     n.a.         1024         1024.0  unknown 0.015358,51.2062        6
    n.a.     n.a.         2048         2048.0  unknown 0.0101975,51.2062        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 25

Starting simulation for: --cats 2048 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 2048 and bandwidth: 0

Starting simulation for: --cats 2048 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 0.012196,51.2062        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.126737,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.7497,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.23182,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.788926,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.04057,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.10994,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.352921,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 1.9435,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.29305,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 1.54495,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.242057,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.43881,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.41874,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.54637,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.04204,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 1

Starting simulation for: --cats 2048 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 2048 and bandwidth: 2

Starting simulation for: --cats 2048 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.          256          256.0  unknown 2.17867,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.687571,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.82054,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.53933,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.03551,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7591e-05,0.272224        6
    n.a.     n.a.            2            2.0  unknown 0.177655,0.272224        6
    n.a.     n.a.            4            4.0  unknown 2.59967,0.272224        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58581,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.82681,0.272224        6
    n.a.     n.a.           64           64.0  unknown 1.16586,0.272224        6
    n.a.     n.a.          128          128.0  unknown 1.54141,0.272224        6
    n.a.     n.a.          256          256.0  unknown 1.64492,0.272224        6
    n.a.     n.a.          512          512.0  unknown 0.515197,0.272224        6
    n.a.     n.a.         1024         1024.0  unknown 2.88888,0.272224        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         2048         2048.0  unknown 1.91818,0.272224        6
    n.a.     n.a.         4096         4096.0  unknown 2.29411,0.272224        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196416,0.03824        6
    n.a.     n.a.            2            2.0  unknown 1.26469,0.03824        6
    n.a.     n.a.            4            4.0  unknown 18.5066,0.03824        6
    n.a.     n.a.            8            8.0  unknown 24.613,0.03824        6
    n.a.     n.a.           16           16.0  unknown 22.4872,0.03824        6
    n.a.     n.a.           32           32.0  unknown 13.0048,0.03824        6
    n.a.     n.a.           64           64.0  unknown 8.29959,0.03824        6
    n.a.     n.a.          128          128.0  unknown 10.973,0.03824        6
    n.a.     n.a.          256          256.0  unknown 11.7099,0.03824        6
    n.a.     n.a.          512          512.0  unknown 3.6676,0.03824        6
    n.a.     n.a.         1024         1024.0  unknown 20.5655,0.03824        6
    n.a.     n.a.         2048         2048.0  unknown 13.6552,0.03824        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 3

Starting simulation for: --cats 2048 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 2048 and bandwidth: 25

Plotting...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 16.3314,0.03824        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
</pre></div>
</div>
<img alt="../_images/python_cats_23_49.png" src="../_images/python_cats_23_49.png" />
</div>
</div>
</div>
</div>
<div class="section" id="scenario-2">
<h2>Scenario 2<a class="headerlink" href="#scenario-2" title="Permalink to this headline">¶</a></h2>
<p>In the real world peoples preferences change as e.g. the seasons change. So now in the simulation we are going to incorporate two different cost functions, and swap over to the second one halfway through. Below is a a table of the new cost function we are going to use, get_cost_1:</p>
<div class="section" id="living-room">
<h3>Living Room<a class="headerlink" href="#living-room" title="Permalink to this headline">¶</a></h3>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p></p></th>
<th class="text-align:center head"><p>get_cost</p></th>
<th class="text-align:center head"><p>get_cost_1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><strong>Morning</strong></p></td>
<td class="text-align:center"><p>Cold</p></td>
<td class="text-align:center"><p>Hot</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><strong>Afternoon</strong></p></td>
<td class="text-align:center"><p>Hot</p></td>
<td class="text-align:center"><p>Cold</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="bedroom">
<h3>Bedroom<a class="headerlink" href="#bedroom" title="Permalink to this headline">¶</a></h3>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p></p></th>
<th class="text-align:center head"><p>get_cost</p></th>
<th class="text-align:center head"><p>get_cost_1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><strong>Morning</strong></p></td>
<td class="text-align:center"><p>Hot</p></td>
<td class="text-align:center"><p>Cold</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><strong>Afternoon</strong></p></td>
<td class="text-align:center"><p>Cold</p></td>
<td class="text-align:center"><p>Cold</p></td>
</tr>
</tbody>
</table>
<p>Below we define the new cost function</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_cost_1</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">):</span>
    <span class="nb">range</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">max_value</span> <span class="o">-</span> <span class="n">min_value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Living Room&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">29</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Bedroom&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
</pre></div>
</div>
</div>
</div>
<p>To make it easy to show the effect of the cost function changing we are going to modify the run_simulation function. It is a little less readable now, but it supports accepting a list of cost functions and it will operate over each cost function in turn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_simulation_multiple_cost_functions</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">cost_functions</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="n">reward_rate</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">hits</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">cost_sum</span> <span class="o">=</span> <span class="mf">0.</span>

    <span class="n">start_counter</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">end_counter</span> <span class="o">=</span> <span class="n">start_counter</span> <span class="o">+</span> <span class="n">num_iterations</span>
    <span class="k">for</span> <span class="n">cost_function</span> <span class="ow">in</span> <span class="n">cost_functions</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_counter</span><span class="p">,</span> <span class="n">end_counter</span><span class="p">):</span>
            <span class="c1"># 1. In each simulation choose a room</span>
            <span class="n">room</span> <span class="o">=</span> <span class="n">choose_room</span><span class="p">(</span><span class="n">rooms</span><span class="p">)</span>
            <span class="c1"># 2. Choose time of day for a given room</span>
            <span class="n">time_of_day</span> <span class="o">=</span> <span class="n">choose_time_of_day</span><span class="p">(</span><span class="n">times_of_day</span><span class="p">)</span>
            <span class="c1"># 3. Pass context to vw to get a temperature</span>
            <span class="n">context</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;room&#39;</span><span class="p">:</span> <span class="n">room</span><span class="p">,</span> <span class="s1">&#39;time_of_day&#39;</span><span class="p">:</span> <span class="n">time_of_day</span><span class="p">}</span>
            <span class="n">temperature</span><span class="p">,</span> <span class="n">pdf_value</span> <span class="o">=</span> <span class="n">predict_temperature</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
            
            <span class="c1"># 4. Get cost of the action we chose</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="n">cost_function</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">cost</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="mf">0.75</span><span class="p">:</span> <span class="c1"># count something as a hit only if it has a high reward</span>
                <span class="n">hits</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">cost_sum</span> <span class="o">+=</span> <span class="n">cost</span>

            <span class="k">if</span> <span class="n">do_learn</span><span class="p">:</span>
                <span class="c1"># 5. Inform VW of what happened so we can learn from it</span>
                <span class="n">txt_ex</span> <span class="o">=</span> <span class="n">to_vw_example_format</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cats_label</span><span class="o">=</span><span class="p">(</span><span class="n">temperature</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">pdf_value</span><span class="p">))</span>
                <span class="n">vw_format</span> <span class="o">=</span> <span class="n">vw</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">txt_ex</span><span class="p">,</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="o">.</span><span class="n">lContinuous</span><span class="p">)</span>
                <span class="c1"># 6. Learn</span>
                <span class="n">vw</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">vw_format</span><span class="p">)</span>
                <span class="c1"># 7. Let VW know you&#39;re done with these objects</span>
                <span class="n">vw</span><span class="o">.</span><span class="n">finish_example</span><span class="p">(</span><span class="n">vw_format</span><span class="p">)</span>

            <span class="c1"># We negate this so that on the plot instead of minimizing cost, we are maximizing reward</span>
            <span class="n">reward_rate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">cost_sum</span><span class="o">/</span><span class="n">i</span><span class="p">)</span>
        
        <span class="n">start_counter</span> <span class="o">=</span> <span class="n">end_counter</span>
        <span class="n">end_counter</span> <span class="o">=</span> <span class="n">start_counter</span> <span class="o">+</span> <span class="n">num_iterations</span>

    <span class="k">return</span> <span class="n">reward_rate</span><span class="p">,</span> <span class="n">hits</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id3">
<h3>With Learning<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>Now that we have run a parameter sweep we can better pick the values of num_actions and bandwidth. For the next scenario we will pick <code class="docutils literal notranslate"><span class="pre">num_actions</span> <span class="pre">128</span></code> and <code class="docutils literal notranslate"><span class="pre">bandwidth</span> <span class="pre">2</span></code>.</p>
<p>Let us now switch to the second cost function after a few samples (running the first cost function). Recall that this cost function changes the preferences of the room temperatures but it is still working with the same continuous action space as before. We should see the learner pick up these changes and optimize towards the new preferences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># use first reward function initially and then switch to second reward function</span>

<span class="c1"># Instantiate learner in VW</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Instantiate VW learner</span>
<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidth</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>

<span class="n">num_iterations_per_cost_func</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">cost_functions</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_cost</span><span class="p">,</span> <span class="n">get_cost_1</span><span class="p">]</span>
<span class="n">total_iterations</span> <span class="o">=</span> <span class="n">num_iterations_per_cost_func</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">cost_functions</span><span class="p">)</span>

<span class="n">ctr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation_multiple_cost_functions</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations_per_cost_func</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">cost_functions</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
<span class="n">plot_reward_rate</span><span class="p">(</span><span class="n">total_iterations</span><span class="p">,</span> <span class="n">ctr</span><span class="p">,</span> <span class="s1">&#39;reward rate with num_actions = 32 and bandwidth = 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.355694,0.20625        6
0.000000 0.000000            4            4.0 {0.297967,0,0.20625} 3.55245,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.89042,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.266841,0,0.20625} 2.53238,0.20625        6
-0.037879 -0.075758           64           64.0 {20.7649,0,0.20625} 19.1146,0.20625        6
-0.227273 -0.416667          128          128.0 {18.143,0,0.20625} 19.6102,0.20625        6
-0.558712 -0.890152          256          256.0 {20.6561,0,0.20625} 19.7468,0.20625        6
-0.506629 -0.454545          512          512.0 {12.4018,-1,0.20625} 12.4376,0.20625        6
-0.485322 -0.464015         1024         1024.0 {29.0701,-1,0.20625} 29.1463,0.20625        6
-0.877500 -1.269679         2048         2048.0 {13.4343,-1,0.20625} 15.0166,0.20625        6
-0.853641 -0.829782         4096         4096.0 {14.1832,-1,0.20625} 15.5128,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.871376 -0.889110         8192         8192.0 {27.7328,-1,0.20625} 28.6282,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.708993 -0.546610        16384        16384.0 {12.1502,-1,0.20625} 9.50664,0.00625        6

finished run
number of examples = 20000
weighted example sum = 20000.000000
weighted label sum = 20000.000000
average loss = -0.716245
total feature number = 120000
</pre></div>
</div>
<img alt="../_images/python_cats_29_3.png" src="../_images/python_cats_29_3.png" />
</div>
</div>
</div>
<div class="section" id="id4">
<h3>Without Learning<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># use first reward function initially and then switch to second reward function</span>

<span class="c1"># Instantiate learner in VW</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Instantiate VW learner</span>
<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidth</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>

<span class="n">num_iterations_per_cost_func</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">cost_functions</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_cost</span><span class="p">,</span> <span class="n">get_cost_1</span><span class="p">]</span>
<span class="n">total_iterations</span> <span class="o">=</span> <span class="n">num_iterations_per_cost_func</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">cost_functions</span><span class="p">)</span>

<span class="n">ctr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation_multiple_cost_functions</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations_per_cost_func</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">cost_functions</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
<span class="n">plot_reward_rate</span><span class="p">(</span><span class="n">total_iterations</span><span class="p">,</span> <span class="n">ctr</span><span class="p">,</span> <span class="s1">&#39;reward rate with num_actions = 32 and bandwidth = 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=6214; id=1, #l=4049; id=2, #l=3278; id=3, #l=0; id=4, #l=3115; id=5, #l=2521; id=6, #l=941; id=7, #l=0; id=8, #l=0; id=9, #l=984; id=10, #l=1649; id=11, #l=1618; id=12, #l=850; id=13, #l=1043; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.355694,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.55245,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.53238,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.66001,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.15567,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.2923,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.801207,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.93417,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.65297,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.14915,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         8192         8192.0  unknown 4.73022,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = n.a.
total feature number = 60000
</pre></div>
</div>
<img alt="../_images/python_cats_31_2.png" src="../_images/python_cats_31_2.png" />
</div>
</div>
</div>
</div>
<div class="section" id="scenario-3">
<h2>Scenario 3<a class="headerlink" href="#scenario-3" title="Permalink to this headline">¶</a></h2>
<div class="section" id="better-cost-function">
<h3>Better cost function<a class="headerlink" href="#better-cost-function" title="Permalink to this headline">¶</a></h3>
<p>The cost function we have been using until now has been a bit too simplistic but has served us well enough to showcase the differences in learning and also in showing CB pickup the new cost cost function and adjust to it.</p>
<p>A slightly better cost function for our simulated world could be the difference between the temperature recommended and the temperature chosen. The smaller the difference the better the thermostat is doing. We are going to model that by taking the absolute cost: <code class="docutils literal notranslate"><span class="pre">1.0</span> <span class="pre">-</span> <span class="pre">|selected_temperature</span> <span class="pre">-</span> <span class="pre">predicted_temerature|</span> <span class="pre">/</span> <span class="pre">range</span></code> and the transforming that cost into a reward by multiplying it with <code class="docutils literal notranslate"><span class="pre">-1</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_smooth_cost</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">):</span>
    <span class="nb">range</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">max_value</span> <span class="o">-</span> <span class="n">min_value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Living Room&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">29</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">/</span> <span class="nb">range</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">cost</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">/</span> <span class="nb">range</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">cost</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Bedroom&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">/</span> <span class="nb">range</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">cost</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">/</span> <span class="nb">range</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">cost</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s try the original paramter sweep with the new cost function <code class="docutils literal notranslate"><span class="pre">get_smooth_cost</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># do parameter sweeping</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">]</span>
<span class="n">bandwidths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span>

<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="k">for</span> <span class="n">actions</span> <span class="ow">in</span> <span class="n">num_actions</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="n">bandwidths</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">bd</span> <span class="o">&gt;=</span> <span class="n">actions</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting simulation for: --cats </span><span class="si">{}</span><span class="s2"> --bandwidth </span><span class="si">{}</span><span class="s2"> --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
        <span class="n">rr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_smooth_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done with simulation for num_actions: </span><span class="si">{}</span><span class="s2"> and bandwidth: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)][</span><span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">rr</span><span class="p">,</span> <span class="n">hits</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Plotting...&quot;</span><span class="p">)</span>
<span class="n">plot_reward_sweep</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">bandwidths</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
0.000000 0.000000            2            2.0 {3.64167e-05,-0.443311,0.20625} 0.234482,0.20625        6
0.000000 0.000000            4            4.0 {0.176755,-0.504406,0.20625} 3.43124,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,-0.785238,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.76921,-0.333898,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {4.80576,-0.680836,0.00625} 21.8051,0.20625        6
0.000000 0.000000           64           64.0 {3.18912,-0.619475,0.20625} 1.53879,0.20625        6
0.000000 0.000000          128          128.0 {4.44601,-0.616343,0.20625} 5.91325,0.20625        6
0.000000 0.000000          256          256.0 {22.4743,-0.843263,0.20625} 21.565,0.20625        6
0.000000 0.000000          512          512.0 {20.0382,-0.866843,0.20625} 20.0739,0.20625        6
0.000000 0.000000         1024         1024.0 {15.3731,-0.918742,0.20625} 15.4493,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting simulation for: --cats 8 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         2048         2048.0 {20.3434,-0.82445,0.20625} 21.9257,0.20625        6
0.000000 0.000000         4096         4096.0 {21.0923,-0.77541,0.20625} 22.4219,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {22.5207,-0.906696,0.20625} 23.4161,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4267; id=1, #l=859; id=2, #l=3654; id=3, #l=306; id=4, #l=803; id=5, #l=3156; id=6, #l=735; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,-0.443597,0.00625} 1.10366,0.40625        6
-0.296280 -0.592560            4            4.0 {1.07435,-0.481455,0.40625} 2.72663,0.40625        6
-0.148140 0.000000            8            8.0 {10.3501,-0.844123,0.00625} 22.5925,0.00625        6
-0.283943 -0.419746           16           16.0 {10.7751,-0.82298,0.40625} 10.9782,0.40625        6
-0.320749 -0.357555           32           32.0 {4.80576,-0.661596,0.00625} 10.0857,0.40625        6
-0.477008 -0.633267           64           64.0 {10.4806,-0.809476,0.40625} 9.64277,0.40625        6
-0.571897 -0.666786          128          128.0 {18.7182,-0.721692,0.00625} 21.7098,0.40625        6
-0.576824 -0.581750          256          256.0 {22.2408,-0.796179,0.40625} 21.7792,0.40625        6
-0.633913 -0.691002          512          512.0 {13.1271,-0.937684,0.40625} 13.1452,0.40625        6
-0.622416 -0.610919         1024         1024.0 {14.6971,-0.932694,0.40625} 14.7358,0.40625        6
-0.644232 -0.666048         2048         2048.0 {25.0974,-0.995499,0.40625} 25.9007,0.40625        6
-0.676417 -0.708602         4096         4096.0 {25.4776,-0.748919,0.40625} 26.1526,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 0

Starting simulation for: --cats 8 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.772550 -0.868684         8192         8192.0 {14.3874,-0.956434,0.40625} 14.842,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.803767
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4254; id=1, #l=2025; id=2, #l=2487; id=3, #l=267; id=4, #l=2012; id=5, #l=876; id=6, #l=1845; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
-0.564079 -0.564079            2            2.0 {3.64167e-05,-0.465365,0.20625} 0.234482,0.20625        6
-0.357658 -0.151237            4            4.0 {0.176755,-0.12477,0.20625} 3.43124,0.20625        6
-0.178829 0.000000            8            8.0 {10.3501,-0.834706,0.00625} 22.5925,0.00625        6
-0.257098 -0.335367           16           16.0 {11.5268,-0.551138,0.20625} 11.9268,0.20625        6
-0.207353 -0.157607           32           32.0 {4.80576,-0.65176,0.00625} 10.1687,0.20625        6
-0.323806 -0.440259           64           64.0 {7.06791,-0.712992,0.20625} 5.41758,0.20625        6
-0.458756 -0.593706          128          128.0 {4.44601,-0.657437,0.20625} 5.91325,0.20625        6
-0.490926 -0.523095          256          256.0 {6.95916,-0.378997,0.20625} 6.04988,0.20625        6
-0.715887 -0.940848          512          512.0 {20.0382,-0.87381,0.20625} 20.0739,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.717832 -0.719778         1024         1024.0 {30.8883,-0.89535,0.20625} 30.9645,0.20625        6
-0.731619 -0.745405         2048         2048.0 {20.3434,-0.894063,0.20625} 21.9257,0.20625        6
-0.764180 -0.796741         4096         4096.0 {24.9711,-0.981302,0.20625} 26.3007,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 1

Starting simulation for: --cats 8 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.790395 -0.816610         8192         8192.0 {22.5207,-0.837959,0.20625} 23.4161,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.808997
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4275; id=1, #l=498; id=2, #l=4022; id=3, #l=286; id=4, #l=460; id=5, #l=3008; id=6, #l=1246; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-16.753428 -16.753428            2            2.0 {0.00120175,-0.523545,0.00625} 3.21214,0.139583        6
-8.705129 -0.656831            4            4.0 {3.12685,-0.550096,0.139583} 7.93571,0.139583        6
-4.352565 0.000000            8            8.0 {10.3501,-0.475367,0.00625} 22.5925,0.00625        6
-2.393552 -0.434540           16           16.0 {8.4351,-0.750796,0.139583} 9.58582,0.00625        6
-1.450813 -0.508074           32           32.0 {3.08085,-0.613646,0.139583} 6.42844,0.139583        6
-0.924668 -0.398523           64           64.0 {26.6824,-0.676724,0.139583} 24.2439,0.139583        6
-0.708369 -0.492070          128          128.0 {18.7182,-0.790103,0.00625} 24.9763,0.139583        6
-0.560226 -0.412084          256          256.0 {18.88,-0.903138,0.139583} 17.5364,0.139583        6
-0.689501 -0.818776          512          512.0 {21.261,-0.78212,0.00625} 22.4398,0.00625        6
-0.765718 -0.841934         1024         1024.0 {27.4917,-0.928844,0.139583} 27.6042,0.139583        6
-0.848173 -0.930628         2048         2048.0 {23.3731,-0.930766,0.139583} 25.7111,0.139583        6
-0.867837 -0.887501         4096         4096.0 {16.8379,-0.974633,0.139583} 18.8025,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 2

Starting simulation for: --cats 8 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.866502 -0.865167         8192         8192.0 {18.9484,-0.911503,0.139583} 20.2715,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.857788
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1970; id=1, #l=2922; id=2, #l=3103; id=3, #l=0; id=4, #l=2247; id=5, #l=1375; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 9.31589e-06,0.80625        6
0.000000 0.000000            2            2.0 {9.31589e-06,-0.514122,0.80625} 0.0599837,0.80625        6
0.000000 0.000000            4            4.0 {0.0452164,-0.515178,0.80625} 0.877758,0.80625        6
0.000000 0.000000            8            8.0 {10.3501,-0.789965,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.964217,-0.539277,0.80625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0372539,-0.448869,0.80625} 0.616809,0.80625        6
0.000000 0.000000           64           64.0 {0.815822,-0.546193,0.80625} 0.393645,0.80625        6
0.000000 0.000000          128          128.0 {18.7182,-0.796313,0.00625} 21.3577,0.80625        6
0.000000 0.000000          256          256.0 {20.633,-0.835737,0.80625} 20.4004,0.80625        6
0.000000 0.000000          512          512.0 {21.002,-0.759014,0.80625} 21.0112,0.80625        6
0.000000 0.000000         1024         1024.0 {28.7389,-0.646539,0.80625} 28.7584,0.80625        6
0.000000 0.000000         2048         2048.0 {13.1421,-0.570303,0.80625} 13.5469,0.80625        6
0.000000 0.000000         4096         4096.0 {17.3027,-0.984315,0.80625} 17.6428,0.80625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {17.6681,-0.980891,0.80625} 17.8971,0.80625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4071; id=1, #l=1519; id=2, #l=2622; id=3, #l=136; id=4, #l=1451; id=5, #l=1503; id=6, #l=1178; id=7, #l=140; id=8, #l=57; id=9, #l=64; id=10, #l=1457; id=11, #l=1037; id=12, #l=535; id=13, #l=928; id=14, #l=307; id=15, #l=122; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-10.802723 -10.802723            2            2.0 {0.00120175,-0.101276,0.00625} 0.611352,0.40625        6
-5.401361 0.000000            4            4.0 {0.582045,-0.18225,0.40625} 2.23432,0.40625        6
-2.700681 0.000000            8            8.0 {10.3501,-0.835381,0.00625} 22.5925,0.00625        6
-1.431581 -0.162480           16           16.0 {2.40591,-0.515167,0.40625} 9.58582,0.00625        6
-0.773779 -0.115977           32           32.0 {4.80576,-0.645656,0.00625} 20.4241,0.40625        6
-1.950526 -3.127273           64           64.0 {5.06525,-0.602698,0.40625} 4.22739,0.40625        6
-1.164223 -0.377919          128          128.0 {11.611,-0.879867,0.40625} 12.356,0.40625        6
-0.744458 -0.324694          256          256.0 {12.887,-0.900932,0.40625} 12.4253,0.40625        6
-0.578443 -0.412429          512          512.0 {10.6656,-0.790444,0.40625} 10.6837,0.40625        6
-0.516180 -0.453916         1024         1024.0 {23.0664,-0.824642,0.40625} 23.105,0.40625        6
-0.772697 -1.029214         2048         2048.0 {22.6359,-0.780386,0.40625} 23.4392,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 0

Starting simulation for: --cats 32 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.801292 -0.829887         4096         4096.0 {23.0161,-0.833112,0.40625} 23.6911,0.40625        6
-0.766202 -0.731113         8192         8192.0 {23.7413,-0.887316,0.40625} 24.1959,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.799601
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4159; id=1, #l=1940; id=2, #l=1769; id=3, #l=233; id=4, #l=1489; id=5, #l=2284; id=6, #l=915; id=7, #l=164; id=8, #l=203; id=9, #l=499; id=10, #l=641; id=11, #l=293; id=12, #l=1198; id=13, #l=880; id=14, #l=109; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-11.428674 -11.428674            2            2.0 {0.00120175,-0.178573,0.00625} 0.71933,0.20625        6
-5.714337 0.000000            4            4.0 {0.661603,-0.503938,0.20625} 3.91608,0.20625        6
-2.857168 0.000000            8            8.0 {10.3501,-0.837514,0.00625} 22.5925,0.00625        6
-1.521064 -0.184960           16           16.0 {4.25406,-0.575179,0.20625} 9.58582,0.00625        6
-2.474778 -3.428493           32           32.0 {4.80576,-0.621162,0.00625} 8.7142,0.20625        6
-1.446112 -0.417446           64           64.0 {21.1285,-0.873458,0.20625} 19.4782,0.20625        6
-0.949620 -0.453128          128          128.0 {10.749,-0.846525,0.20625} 12.2163,0.20625        6
-0.679944 -0.410269          256          256.0 {13.2622,-0.937091,0.20625} 12.3529,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 1

Starting simulation for: --cats 32 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.746261 -0.812577          512          512.0 {18.5837,-0.710434,0.20625} 18.6194,0.20625        6
-0.685406 -0.624552         1024         1024.0 {18.7671,-0.942802,0.20625} 18.8433,0.20625        6
-0.837443 -0.989481         2048         2048.0 {20.8283,-0.899766,0.20625} 22.4105,0.20625        6
-0.890863 -0.944282         4096         4096.0 {19.6378,-0.884826,0.20625} 20.9673,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.887157 -0.883452         8192         8192.0 {21.0661,-0.874646,0.20625} 21.9615,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.878283
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3682; id=1, #l=897; id=2, #l=3483; id=3, #l=265; id=4, #l=811; id=5, #l=2744; id=6, #l=942; id=7, #l=0; id=8, #l=146; id=9, #l=147; id=10, #l=448; id=11, #l=2146; id=12, #l=1220; id=13, #l=625; id=14, #l=0; id=15, #l=51; 
    n.a.     n.a.            1            1.0  unknown 3.19857e-05,0.234821        6
-0.573999 -0.573999            2            2.0 {3.19857e-05,-0.471755,0.234821} 0.205952,0.234821        6
-0.286999 0.000000            4            4.0 {0.155249,-0.522073,0.234821} 3.01375,0.234821        6
-0.143500 0.000000            8            8.0 {10.3501,-0.767421,0.00625} 22.5925,0.00625        6
-0.100236 -0.056973           16           16.0 {3.3106,-0.570008,0.234821} 9.58582,0.00625        6
-0.687986 -1.275735           32           32.0 {4.80576,-0.366404,0.00625} 24.1001,0.139583        6
-0.570531 -0.453077           64           64.0 {6.14512,-0.694679,0.139583} 3.70658,0.139583        6
-0.572144 -0.573756          128          128.0 {18.7182,-0.970741,0.00625} 22.5882,0.139583        6
-0.681393 -0.790643          256          256.0 {25.0889,-0.937844,0.139583} 23.7453,0.139583        6
-0.800371 -0.919348          512          512.0 {10.0266,-0.784932,0.139583} 10.0794,0.139583        6
-0.719752 -0.639133         1024         1024.0 {26.0588,-0.971072,0.139583} 26.1714,0.139583        6
-0.716836 -0.713920         2048         2048.0 {13.3432,-0.904376,0.139583} 15.6813,0.139583        6
-0.799523 -0.882209         4096         4096.0 {13.4946,-0.949962,0.139583} 15.4592,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 2

Starting simulation for: --cats 32 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.836837 -0.874151         8192         8192.0 {16.5604,-0.99055,0.139583} 17.8834,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.852749
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2832; id=1, #l=2916; id=2, #l=2235; id=3, #l=357; id=4, #l=0; id=5, #l=1819; id=6, #l=864; id=7, #l=66; id=8, #l=0; id=9, #l=988; id=10, #l=957; id=11, #l=1282; id=12, #l=878; id=13, #l=410; id=14, #l=371; id=15, #l=37; 
    n.a.     n.a.            1            1.0  unknown 0.000199639,0.0376226        6
-0.464668 -0.464668            2            2.0 {0.000199639,-0.463273,0.0376226} 1.28545,0.0376226        6
-0.308798 -0.152927            4            4.0 {0.968985,-0.184112,0.0376226} 18.8103,0.0376226        6
-0.481201 -0.653604            8            8.0 {22.9832,-0.832984,0.0376226} 25.017,0.0376226        6
-0.561958 -0.642716           16           16.0 {20.6631,-0.845361,0.0376226} 22.8563,0.0376226        6
-0.571600 -0.581241           32           32.0 {0.798351,-0.549225,0.0376226} 13.2182,0.0376226        6
-0.686331 -0.801063           64           64.0 {17.483,-0.687583,0.0376226} 8.4358,0.0376226        6
-0.731409 -0.776486          128          128.0 {3.74364,-0.229971,0.03125} 13.4274,0.03125        6
-0.732007 -0.732605          256          256.0 {20.3305,-0.732044,0.03125} 14.3292,0.03125        6
-0.747745 -0.763483          512          512.0 {4.25219,-0.324901,0.03125} 4.48797,0.03125        6
-0.741939 -0.736134         1024         1024.0 {24.6628,-0.737928,0.03125} 25.1656,0.03125        6
-0.739559 -0.737178         2048         2048.0 {6.26651,-0.41164,0.03125} 16.7096,0.03125        6
-0.737455 -0.735352         4096         4096.0 {11.2093,-0.805182,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.737060 -0.736665         8192         8192.0 {20.6363,-0.867335,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.736577
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=2; id=2, #l=0; id=3, #l=459; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=301; id=8, #l=146; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=281; id=15, #l=161; 
    n.a.     n.a.            1            1.0  unknown 4.67607e-06,1.60625        6
0.000000 0.000000            2            2.0 {4.67607e-06,-0.44713,1.60625} 0.0301085,1.60625        6
0.000000 0.000000            4            4.0 {0.0226962,-0.469297,1.60625} 0.440587,1.60625        6
0.000000 0.000000            8            8.0 {10.3501,-0.519416,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.483984,-0.469885,1.60625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {4.80576,-0.658041,0.00625} 20.2318,1.60625        6
0.000000 0.000000           64           64.0 {4.39393,-0.597458,1.60625} 4.18202,1.60625        6
0.000000 0.000000          128          128.0 {4.05727,-0.623183,1.60625} 4.24567,1.60625        6
0.000000 0.000000          256          256.0 {0.395535,-0.216243,1.60625} 0.278778,1.60625        6
0.000000 0.000000          512          512.0 {20.0049,-0.910681,1.60625} 20.0095,1.60625        6
0.000000 0.000000         1024         1024.0 {6.45647,-0.686862,1.60625} 6.46626,1.60625        6
0.000000 0.000000         2048         2048.0 {24.0285,-0.799492,1.60625} 24.2317,1.60625        6
0.000000 0.000000         4096         4096.0 {18.6461,-0.909985,1.60625} 18.8168,1.60625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 25

Starting simulation for: --cats 64 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {21.8178,-0.860633,1.60625} 21.9328,1.60625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4068; id=1, #l=706; id=2, #l=3391; id=3, #l=391; id=4, #l=353; id=5, #l=1927; id=6, #l=1505; id=7, #l=92; id=8, #l=332; id=9, #l=36; id=10, #l=353; id=11, #l=628; id=12, #l=1329; id=13, #l=1482; id=14, #l=45; id=15, #l=85; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-66.633919 -66.633919            2            2.0 {0.00120175,-0.520577,0.00625} 0.365198,0.40625        6
-33.316959 0.000000            4            4.0 {0.335891,-0.515672,0.40625} 1.98817,0.40625        6
-16.658480 0.000000            8            8.0 {10.3501,-0.821558,0.00625} 22.5925,0.00625        6
-8.418563 -0.178645           16           16.0 {2.15975,-0.513873,0.40625} 9.58582,0.00625        6
-4.228149 -0.037735           32           32.0 {4.80576,-0.618047,0.00625} 20.178,0.40625        6
-2.258050 -0.287951           64           64.0 {4.81909,-0.666923,0.40625} 3.98123,0.40625        6
-2.096610 -1.935169          128          128.0 {3.48797,-0.614503,0.40625} 4.23288,0.40625        6
-1.198791 -0.300972          256          256.0 {4.76388,-0.629626,0.40625} 4.30225,0.40625        6
-1.049966 -0.901141          512          512.0 {20.2656,-0.873144,0.40625} 20.2837,0.40625        6
-0.759957 -0.469947         1024         1024.0 {24.7894,-0.772727,0.40625} 24.8281,0.40625        6
-0.825784 -0.891612         2048         2048.0 {19.9282,-0.932095,0.40625} 20.7315,0.40625        6
-0.796952 -0.768121         4096         4096.0 {24.7392,-0.706322,0.40625} 25.4142,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 0

Starting simulation for: --cats 64 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.744474 -0.691995         8192         8192.0 {21.5259,-0.883334,0.40625} 21.9805,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.763713
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4086; id=1, #l=1241; id=2, #l=3008; id=3, #l=255; id=4, #l=1004; id=5, #l=1985; id=6, #l=742; id=7, #l=205; id=8, #l=216; id=9, #l=206; id=10, #l=720; id=11, #l=1171; id=12, #l=1463; id=13, #l=461; id=14, #l=87; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-34.880119 -34.880119            2            2.0 {0.00120175,-0.490502,0.00625} 0.476906,0.20625        6
-17.440060 0.000000            4            4.0 {0.419179,-0.4706,0.20625} 3.67366,0.20625        6
-8.720030 0.000000            8            8.0 {10.3501,-0.811645,0.00625} 22.5925,0.00625        6
-4.475685 -0.231340           16           16.0 {9.82982,-0.763423,0.20625} 10.2299,0.20625        6
-2.308396 -0.141106           32           32.0 {0.388053,-0.499541,0.20625} 2.65359,0.20625        6
-1.365023 -0.421650           64           64.0 {3.43155,-0.624207,0.20625} 1.78122,0.20625        6
-0.928011 -0.491000          128          128.0 {10.5066,-0.779828,0.20625} 11.9739,0.20625        6
-0.884961 -0.841910          256          256.0 {22.7167,-0.764042,0.20625} 21.8075,0.20625        6
-1.107884 -1.330807          512          512.0 {10.5837,-0.826396,0.20625} 10.6194,0.20625        6
-0.908686 -0.709488         1024         1024.0 {18.0398,-0.99785,0.20625} 18.116,0.20625        6
-0.898324 -0.887962         2048         2048.0 {13.798,-0.962387,0.20625} 15.3802,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 1

Starting simulation for: --cats 64 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.941328 -0.984333         4096         4096.0 {15.0317,-0.923315,0.20625} 16.3613,0.20625        6
-0.927785 -0.914242         8192         8192.0 {21.3085,-0.837733,0.20625} 22.2039,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.923267
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3397; id=1, #l=2442; id=2, #l=2469; id=3, #l=283; id=4, #l=2196; id=5, #l=1844; id=6, #l=1307; id=7, #l=0; id=8, #l=160; id=9, #l=308; id=10, #l=968; id=11, #l=1144; id=12, #l=470; id=13, #l=936; id=14, #l=0; id=15, #l=51; 
    n.a.     n.a.            1            1.0  unknown 2.97576e-05,0.252404        6
-0.114423 -0.114423            2            2.0 {2.97576e-05,-0.0938627,0.252404} 0.191605,0.252404        6
-0.212026 -0.309628            4            4.0 {0.144434,-0.44937,0.252404} 2.80381,0.252404        6
-0.106013 0.000000            8            8.0 {10.3501,-0.45337,0.00625} 22.5925,0.00625        6
-0.258324 -0.410634           16           16.0 {14.4053,-0.911788,0.139583} 14.9964,0.139583        6
-0.345882 -0.433440           32           32.0 {4.80576,-0.653242,0.00625} 12.3986,0.139583        6
-0.489865 -0.633849           64           64.0 {13.5481,-0.87309,0.139583} 11.1096,0.139583        6
-0.562112 -0.634358          128          128.0 {9.67395,-0.785544,0.139583} 11.842,0.139583        6
-0.539095 -0.516078          256          256.0 {6.22324,-0.710382,0.139583} 4.87967,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 2

Starting simulation for: --cats 64 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.667357 -0.795618          512          512.0 {19.34,-0.890096,0.139583} 19.3928,0.139583        6
-0.651680 -0.636004         1024         1024.0 {15.7902,-0.982167,0.139583} 15.9027,0.139583        6
-0.785661 -0.919642         2048         2048.0 {21.7015,-0.871158,0.139583} 24.0395,0.139583        6
-0.770439 -0.755217         4096         4096.0 {22.808,-0.918956,0.139583} 24.7726,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.806786 -0.843133         8192         8192.0 {14.8887,-0.972228,0.139583} 16.2118,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.826268
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4103; id=1, #l=1095; id=2, #l=1328; id=3, #l=216; id=4, #l=0; id=5, #l=2691; id=6, #l=1775; id=7, #l=67; id=8, #l=0; id=9, #l=425; id=10, #l=496; id=11, #l=1676; id=12, #l=1051; id=13, #l=1247; id=14, #l=515; id=15, #l=32; 
    n.a.     n.a.            1            1.0  unknown 0.000198004,0.0379332        6
-0.189797 -0.189797            2            2.0 {0.000198004,-0.18899,0.0379332} 1.27492,0.0379332        6
-0.293227 -0.396657            4            4.0 {0.961051,-0.481486,0.0379332} 18.6563,0.0379332        6
-0.478011 -0.662795            8            8.0 {22.795,-0.812366,0.0379332} 24.8121,0.0379332        6
-0.951692 -1.425373           16           16.0 {20.4939,-0.865875,0.0379332} 22.6691,0.0379332        6
-0.779503 -0.607315           32           32.0 {0.791813,-0.16685,0.0379332} 13.11,0.0379332        6
-0.827361 -0.875218           64           64.0 {17.3399,-0.996005,0.0379332} 8.36672,0.0379332        6
-0.808268 -0.789176          128          128.0 {3.74364,-0.568578,0.03125} 13.4274,0.03125        6
-0.782090 -0.755912          256          256.0 {20.3305,-0.75238,0.03125} 14.3292,0.03125        6
-0.766677 -0.751265          512          512.0 {4.25219,-0.59269,0.03125} 4.48797,0.03125        6
-0.751699 -0.736720         1024         1024.0 {24.6628,-0.926447,0.03125} 25.1656,0.03125        6
-0.744210 -0.736721         2048         2048.0 {6.26651,-0.678309,0.03125} 16.7096,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 3

Starting simulation for: --cats 64 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.743315 -0.742421         4096         4096.0 {11.2093,-0.792745,0.03125} 19.9844,0.03125        6
-0.740451 -0.737586         8192         8192.0 {20.6363,-0.857536,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.742353
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=459; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=301; id=8, #l=146; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=281; id=15, #l=161; 
    n.a.     n.a.            1            1.0  unknown 2.34259e-06,3.20625        6
0.000000 0.000000            2            2.0 {2.34259e-06,-0.0992641,3.20625} 0.0150836,3.20625        6
0.000000 0.000000            4            4.0 {0.0113702,-0.124101,3.20625} 0.220723,3.20625        6
0.000000 0.000000            8            8.0 {10.3501,-0.813861,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.242464,-0.222978,3.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00936795,-0.512465,3.20625} 0.155104,3.20625        6
0.000000 0.000000           64           64.0 {0.205148,-0.48753,3.20625} 0.0989867,3.20625        6
0.000000 0.000000          128          128.0 {0.0364877,-0.492806,3.20625} 0.130872,3.20625        6
0.000000 0.000000          256          256.0 {5.43792,-0.68439,3.20625} 5.37943,3.20625        6
0.000000 0.000000          512          512.0 {21.261,-0.883017,0.00625} 21.5018,3.20625        6
0.000000 0.000000         1024         1024.0 {5.48014,-0.608839,3.20625} 5.48504,3.20625        6
0.000000 0.000000         2048         2048.0 {5.30084,-0.615479,3.20625} 5.40263,3.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 25

Starting simulation for: --cats 128 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {26.0586,-0.722109,3.20625} 26.1441,3.20625        6
0.000000 0.000000         8192         8192.0 {24.4039,-0.950528,3.20625} 24.4615,3.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 0

Starting simulation for: --cats 128 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4078; id=1, #l=1018; id=2, #l=3080; id=3, #l=529; id=4, #l=504; id=5, #l=293; id=6, #l=2796; id=7, #l=277; id=8, #l=264; id=9, #l=15; id=10, #l=499; id=11, #l=10; id=12, #l=293; id=13, #l=2796; id=14, #l=9; id=15, #l=276; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-69.851952 -69.851952            2            2.0 {0.00120175,-0.491147,0.00625} 0.242121,0.40625        6
-34.925976 0.000000            4            4.0 {0.212814,-0.196601,0.40625} 1.86509,0.40625        6
-17.462988 0.000000            8            8.0 {10.3501,-0.793849,0.00625} 22.5925,0.00625        6
-8.731494 0.000000           16           16.0 {2.03668,-0.520675,0.40625} 9.58582,0.00625        6
-4.407015 -0.082536           32           32.0 {0.197012,-0.486758,0.40625} 1.34721,0.40625        6
-2.421689 -0.436363           64           64.0 {4.69602,-0.632648,0.40625} 3.85816,0.40625        6
-1.442647 -0.463606          128          128.0 {18.7182,-0.738033,0.00625} 20.356,0.40625        6
-0.896207 -0.349766          256          256.0 {21.1331,-0.835202,0.40625} 20.6715,0.40625        6
-1.213317 -1.530427          512          512.0 {5.86555,-0.633179,0.40625} 5.88369,0.40625        6
-0.838765 -0.464214         1024         1024.0 {21.4664,-0.791227,0.40625} 21.505,0.40625        6
-0.854249 -0.869733         2048         2048.0 {24.2359,-0.950461,0.40625} 25.0392,0.40625        6
-0.866550 -0.878851         4096         4096.0 {16.0007,-0.975928,0.40625} 16.6757,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.876251 -0.885952         8192         8192.0 {21.4028,-0.876276,0.40625} 21.8574,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.874082
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4085; id=1, #l=507; id=2, #l=3605; id=3, #l=345; id=4, #l=298; id=5, #l=2043; id=6, #l=1825; id=7, #l=142; id=8, #l=262; id=9, #l=136; id=10, #l=247; id=11, #l=538; id=12, #l=1810; id=13, #l=1234; id=14, #l=72; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-13.864547 -13.864547            2            2.0 {0.00120175,-0.205802,0.00625} 0.355694,0.20625        6
-6.932273 0.000000            4            4.0 {0.297967,-0.105813,0.20625} 3.55245,0.20625        6
-3.466137 0.000000            8            8.0 {10.3501,-0.803411,0.00625} 22.5925,0.00625        6
-1.733068 0.000000           16           16.0 {3.89042,-0.560664,0.20625} 9.58582,0.00625        6
-0.905840 -0.078611           32           32.0 {2.20624,-0.596039,0.20625} 4.47177,0.20625        6
-0.640123 -0.374406           64           64.0 {20.7649,-0.869098,0.20625} 19.1146,0.20625        6
-0.597486 -0.554850          128          128.0 {18.143,-0.964811,0.20625} 19.6102,0.20625        6
-0.522726 -0.447966          256          256.0 {20.6561,-0.900008,0.20625} 19.7468,0.20625        6
-0.654871 -0.787015          512          512.0 {18.22,-0.939721,0.20625} 18.2558,0.20625        6
-0.649978 -0.645085         1024         1024.0 {21.3125,-0.805645,0.20625} 21.3887,0.20625        6
-0.770602 -0.891227         2048         2048.0 {20.707,-0.911029,0.20625} 22.2893,0.20625        6
-0.785627
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 1

Starting simulation for: --cats 128 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> -0.800652         4096         4096.0 {22.6681,-0.822125,0.20625} 23.9976,0.20625        6
-0.845687 -0.905747         8192         8192.0 {20.9449,-0.891023,0.20625} 21.8403,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.850145
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 2

Starting simulation for: --cats 128 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4277; id=1, #l=1238; id=2, #l=2368; id=3, #l=284; id=4, #l=908; id=5, #l=2422; id=6, #l=1250; id=7, #l=0; id=8, #l=158; id=9, #l=526; id=10, #l=136; id=11, #l=1676; id=12, #l=1351; id=13, #l=629; id=14, #l=0; id=15, #l=50; 
    n.a.     n.a.            1            1.0  unknown 2.86404e-05,0.26225        6
-0.647851 -0.647851            2            2.0 {2.86404e-05,-0.530934,0.26225} 0.184411,0.26225        6
-0.482660 -0.317468            4            4.0 {0.139011,-0.468315,0.26225} 2.69854,0.26225        6
-0.241330 0.000000            8            8.0 {10.3501,-0.839312,0.00625} 22.5925,0.00625        6
-0.277447 -0.313565           16           16.0 {14.2858,-0.913047,0.139583} 14.877,0.139583        6
-0.301421 -0.325395           32           32.0 {0.114532,-0.491569,0.26225} 1.89629,0.26225        6
-0.388970 -0.476518           64           64.0 {2.50813,-0.604238,0.26225} 1.2102,0.26225        6
-0.503615 -0.618261          128          128.0 {9.55455,-0.762029,0.139583} 11.7226,0.139583        6
-0.476512 -0.449409          256          256.0 {23.7755,-0.814265,0.139583} 22.4319,0.139583        6
-0.760321 -1.044130          512          512.0 {16.8326,-0.968343,0.139583} 16.8854,0.139583        6
-0.684294 -0.608268         1024         1024.0 {20.6857,-0.90156,0.139583} 20.7983,0.139583        6
-0.760690 -0.837086         2048         2048.0 {21.1044,-0.868257,0.139583} 23.4424,0.139583        6
-0.766151 -0.771613         4096         4096.0 {18.6289,-0.904207,0.139583} 20.5935,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.777309 -0.788467         8192         8192.0 {20.9783,-0.862795,0.139583} 22.3014,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.787578
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3848; id=1, #l=809; id=2, #l=2585; id=3, #l=242; id=4, #l=0; id=5, #l=1400; id=6, #l=1783; id=7, #l=67; id=8, #l=0; id=9, #l=135; id=10, #l=688; id=11, #l=1432; id=12, #l=1345; id=13, #l=1548; id=14, #l=169; id=15, #l=32; 
    n.a.     n.a.            1            1.0  unknown 0.000197185,0.0380908        6
-0.486754 -0.486754            2            2.0 {0.000197185,-0.489015,0.0380908} 1.26965,0.0380908        6
-0.312688 -0.138621            4            4.0 {0.957074,-0.168966,0.0380908} 18.5791,0.0380908        6
-0.484817 -0.656946            8            8.0 {22.7007,-0.847407,0.0380908} 24.7095,0.0380908        6
-0.964943 -1.445069           16           16.0 {20.4091,-0.792506,0.0380908} 22.5753,0.0380908        6
-0.779797 -0.594651           32           32.0 {0.788537,-0.508825,0.0380908} 13.0557,0.0380908        6
-0.779495 -0.779192           64           64.0 {19.5077,-0.877623,0.0337178} 9.41272,0.0337178        6
-0.808386 -0.837277          128          128.0 {3.74364,-0.586339,0.03125} 13.4274,0.03125        6
-0.775829 -0.743271          256          256.0 {20.3305,-0.782337,0.03125} 14.3292,0.03125        6
-0.755101 -0.734374          512          512.0 {4.25219,-0.260233,0.03125} 4.48797,0.03125        6
-0.745101 -0.735100         1024         1024.0 {24.6628,-0.749886,0.03125} 25.1656,0.03125        6
-0.738466 -0.731831         2048         2048.0 {6.26651,-0.317064,0.03125} 16.7096,0.03125        6
-0.738504 -0.738542         4096         4096.0 {11.2093,-0.870761,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 3

Starting simulation for: --cats 128 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.735993 -0.733482         8192         8192.0 {20.6363,-0.906924,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.738799
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=460; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=302; id=8, #l=147; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=280; id=15, #l=162; 
    n.a.     n.a.            1            1.0  unknown 1.17244e-06,6.40625        6
0.000000 0.000000            2            2.0 {1.17244e-06,-0.47238,6.40625} 0.00754917,6.40625        6
0.000000 0.000000            4            4.0 {0.00569065,-0.474627,6.40625} 0.110469,6.40625        6
0.000000 0.000000            8            8.0 {10.3501,-0.824436,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.12135,-0.480678,6.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00468855,-0.105745,6.40625} 0.0776277,6.40625        6
0.000000 0.000000           64           64.0 {0.102674,-0.517932,6.40625} 0.0495416,6.40625        6
0.000000 0.000000          128          128.0 {0.0182616,-0.183449,6.40625} 0.0654997,6.40625        6
0.000000 0.000000          256          256.0 {0.099173,-0.216069,6.40625} 0.0698985,6.40625        6
0.000000 0.000000          512          512.0 {0.0207424,-0.441659,6.40625} 0.0218925,6.40625        6
0.000000 0.000000         1024         1024.0 {0.120306,-0.157835,6.40625} 0.122759,6.40625        6
0.000000 0.000000         2048         2048.0 {1.27935,-0.528901,6.40625} 1.33029,6.40625        6
0.000000 0.000000         4096         4096.0 {3.17663,-0.539587,6.40625} 3.21944,6.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 25

Starting simulation for: --cats 256 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {1.5992,-0.194919,6.40625} 4.73022,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4006; id=1, #l=3398; id=2, #l=613; id=3, #l=3099; id=4, #l=303; id=5, #l=4; id=6, #l=615; id=7, #l=2640; id=8, #l=464; id=9, #l=4; id=10, #l=308; id=11, #l=9; id=12, #l=4; id=13, #l=614; id=14, #l=6; id=15, #l=2114; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-16.657280 -16.657280            2            2.0 {0.00120175,-0.123628,0.00625} 0.180583,0.40625        6
-8.328640 0.000000            4            4.0 {0.151276,-0.513772,0.40625} 1.80355,0.40625        6
-4.164320 0.000000            8            8.0 {10.3501,-0.834832,0.00625} 22.5925,0.00625        6
-2.163115 -0.161910           16           16.0 {1.97514,-0.554028,0.40625} 9.58582,0.00625        6
-2.759801 -3.356487           32           32.0 {3.58163,-0.209998,0.40625} 4.73182,0.40625        6
-1.583300 -0.406798           64           64.0 {21.3729,-0.806386,0.40625} 20.5351,0.40625        6
-1.036231 -0.489162          128          128.0 {18.7182,-0.915786,0.00625} 20.7867,0.40625        6
-0.704076 -0.371921          256          256.0 {5.68696,-0.344867,0.40625} 5.22532,0.40625        6
-0.893771 -1.083467          512          512.0 {20.0809,-0.756365,0.40625} 20.0991,0.40625        6
-0.834384 -0.774997         1024         1024.0 {21.651,-0.796787,0.40625} 21.6897,0.40625        6
-0.797952 -0.761519         2048         2048.0 {12.359,-0.894722,0.40625} 13.1623,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 0

Starting simulation for: --cats 256 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.754540 -0.711128         4096         4096.0 {12.7392,-0.860197,0.40625} 13.4142,0.40625        6
-0.775108 -0.795675         8192         8192.0 {14.0797,-0.882513,0.40625} 14.5343,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.826822
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4101; id=1, #l=2082; id=2, #l=2151; id=3, #l=159; id=4, #l=1949; id=5, #l=1549; id=6, #l=543; id=7, #l=137; id=8, #l=146; id=9, #l=154; id=10, #l=1109; id=11, #l=717; id=12, #l=1052; id=13, #l=229; id=14, #l=81; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-34.091286 -34.091286            2            2.0 {0.00120175,-0.492726,0.00625} 0.295088,0.20625        6
-17.045643 0.000000            4            4.0 {0.237361,-0.139188,0.20625} 3.49184,0.20625        6
-8.522821 0.000000            8            8.0 {10.3501,-0.844034,0.00625} 22.5925,0.00625        6
-4.353143 -0.183466           16           16.0 {3.82982,-0.602604,0.20625} 9.58582,0.00625        6
-2.216339 -0.079534           32           32.0 {2.14563,-0.547231,0.20625} 4.41116,0.20625        6
-1.318075 -0.419811           64           64.0 {12.9467,-0.852825,0.20625} 11.2964,0.20625        6
-0.928976 -0.539876          128          128.0 {10.3248,-0.797103,0.20625} 11.792,0.20625        6
-0.649542 -0.370109          256          256.0 {12.838,-0.538078,0.20625} 11.9287,0.20625        6
-1.042091 -1.434640          512          512.0 {18.1594,-0.986077,0.20625} 18.1951,0.20625        6
-0.839881 -0.637670         1024         1024.0 {23.1913,-0.922975,0.20625} 23.2675,0.20625        6
-0.808996 -0.778112         2048         2048.0 {14.5858,-0.959026,0.20625} 16.1681,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 1

Starting simulation for: --cats 256 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.768577 -0.728158         4096         4096.0 {24.4256,-0.887832,0.20625} 25.7552,0.20625        6
-0.840029 -0.911481         8192         8192.0 {26.3388,-0.944811,0.20625} 27.2342,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.841457
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 2

Starting simulation for: --cats 256 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3158; id=1, #l=1440; id=2, #l=2766; id=3, #l=267; id=4, #l=1287; id=5, #l=3641; id=6, #l=1698; id=7, #l=0; id=8, #l=156; id=9, #l=165; id=10, #l=950; id=11, #l=1034; id=12, #l=1570; id=13, #l=1129; id=14, #l=0; id=15, #l=50; 
    n.a.     n.a.            1            1.0  unknown 2.80809e-05,0.267474        6
-0.576651 -0.576651            2            2.0 {2.80809e-05,-0.491638,0.267474} 0.180809,0.267474        6
-0.449389 -0.322128            4            4.0 {0.136296,-0.490041,0.267474} 2.64583,0.267474        6
-0.224695 0.000000            8            8.0 {10.35,-0.804794,0.00625} 22.5925,0.00625        6
-0.305364 -0.386032           16           16.0 {14.2261,-0.913087,0.139583} 14.8173,0.139583        6
-0.298619 -0.291874           32           32.0 {4.80576,-0.599616,0.00625} 12.2195,0.139583        6
-0.427866 -0.557113           64           64.0 {5.72721,-0.6186,0.139583} 3.28867,0.139583        6
-0.512834 -0.597802          128          128.0 {18.7182,-0.746866,0.00625} 23.1255,0.139583        6
-0.670688 -0.828541          256          256.0 {22.0441,-0.875445,0.139583} 20.7006,0.139583        6
-0.864978 -1.059268          512          512.0 {17.7281,-0.757977,0.139583} 17.7809,0.139583        6
-0.814858 -0.764739         1024         1024.0 {20.9842,-0.857094,0.139583} 21.0968,0.139583        6
-0.890625 -0.966391         2048         2048.0 {13.5224,-0.933472,0.139583} 15.8604,0.139583        6
-0.889093 -0.887560         4096         4096.0 {14.8677,-0.957844,0.139583} 16.8323,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.909990 -0.930887         8192         8192.0 {15.6649,-0.929394,0.139583} 16.9879,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.912257
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3095; id=1, #l=2639; id=2, #l=2080; id=3, #l=234; id=4, #l=0; id=5, #l=1784; id=6, #l=736; id=7, #l=74; id=8, #l=0; id=9, #l=770; id=10, #l=903; id=11, #l=1184; id=12, #l=970; id=13, #l=585; id=14, #l=223; id=15, #l=36; 
    n.a.     n.a.            1            1.0  unknown 0.000196775,0.0381702        6
-0.176507 -0.176507            2            2.0 {0.000196775,-0.177276,0.0381702} 1.26701,0.0381702        6
-0.159485 -0.142463            4            4.0 {0.955083,-0.174011,0.0381702} 18.5404,0.0381702        6
-0.397443 -0.635401            8            8.0 {22.6535,-0.84025,0.0381702} 24.6581,0.0381702        6
-0.874242 -1.351041           16           16.0 {20.3667,-0.831833,0.0381702} 22.5283,0.0381702        6
-0.732934 -0.591626           32           32.0 {0.786897,-0.502868,0.0381702} 13.0286,0.0381702        6
-0.831076 -0.929217           64           64.0 {19.4736,-0.783975,0.0337769} 9.39625,0.0337769        6
-0.809238 -0.787400          128          128.0 {3.74364,-0.64357,0.03125} 13.4274,0.03125        6
-0.770453 -0.731668          256          256.0 {20.3305,-0.917795,0.03125} 14.3292,0.03125        6
-0.756743 -0.743034          512          512.0 {4.25219,-0.59106,0.03125} 4.48797,0.03125        6
-0.748811 -0.740878         1024         1024.0 {24.6628,-0.77448,0.03125} 25.1656,0.03125        6
-0.741267 -0.733724         2048         2048.0 {6.26651,-0.293987,0.03125} 16.7096,0.03125        6
-0.739243 -0.737220         4096         4096.0 {11.2093,-0.849781,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 3

Starting simulation for: --cats 256 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.738364 -0.737484         8192         8192.0 {20.6363,-0.903567,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.738489
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=461; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=302; id=8, #l=148; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=280; id=15, #l=162; 
    n.a.     n.a.            1            1.0  unknown 5.86506e-07,12.8063        6
0.000000 0.000000            2            2.0 {5.86506e-07,-0.134607,12.8063} 0.00377643,12.8063        6
0.000000 0.000000            4            4.0 {0.00284671,-0.456243,12.8063} 0.0552615,12.8063        6
0.000000 0.000000            8            8.0 {10.3501,-0.426247,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0607047,-0.450838,12.8063} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00234542,-0.503803,12.8063} 0.0388328,12.8063        6
0.000000 0.000000           64           64.0 {0.0513621,-0.530018,12.8063} 0.0247829,12.8063        6
0.000000 0.000000          128          128.0 {0.00913528,-0.50723,12.8063} 0.0327658,12.8063        6
0.000000 0.000000          256          256.0 {0.0496107,-0.495797,12.8063} 0.0349663,12.8063        6
0.000000 0.000000          512          512.0 {0.0103763,-0.522487,12.8063} 0.0109516,12.8063        6
0.000000 0.000000         1024         1024.0 {13.6785,-0.604896,12.8063} 13.6798,12.8063        6
0.000000 0.000000         2048         2048.0 {1.0148,-0.542632,12.8063} 1.04029,12.8063        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 25

Starting simulation for: --cats 512 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {2.52613,-0.562552,12.8063} 2.54755,12.8063        6
0.000000 0.000000         8192         8192.0 {2.54914,-0.605002,12.8063} 4.73021,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4023; id=1, #l=2860; id=2, #l=1166; id=3, #l=2633; id=4, #l=230; id=5, #l=1168; id=6, #l=1; id=7, #l=2595; id=8, #l=42; id=9, #l=2; id=10, #l=229; id=11, #l=5; id=12, #l=1168; id=13, #l=3; id=14, #l=0; id=15, #l=1850; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-68.349846 -68.349846            2            2.0 {0.00120175,-0.493934,0.00625} 0.149814,0.40625        6
-34.174923 0.000000            4            4.0 {0.120506,-0.498136,0.40625} 1.77278,0.40625        6
-17.087461 0.000000            8            8.0 {10.3501,-0.838343,0.00625} 22.5925,0.00625        6
-8.579178 -0.070895           16           16.0 {1.94437,-0.566189,0.40625} 9.58582,0.00625        6
-7.392604 -6.206031           32           32.0 {0.104704,-0.482579,0.40625} 1.2549,0.40625        6
-3.831823 -0.271042           64           64.0 {21.3422,-0.802569,0.40625} 20.5043,0.40625        6
-2.156036 -0.480249          128          128.0 {9.18028,-0.392447,0.40625} 9.92519,0.40625        6
-1.256779 -0.357521          256          256.0 {21.287,-0.84123,0.40625} 20.8253,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 0

Starting simulation for: --cats 512 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-1.039281 -0.821783          512          512.0 {20.0502,-0.869333,0.40625} 20.0683,0.40625        6
-0.776213 -0.513144         1024         1024.0 {18.6664,-0.907289,0.40625} 18.705,0.40625        6
-0.840317 -0.904421         2048         2048.0 {20.0205,-0.820773,0.40625} 20.8238,0.40625        6
-0.774251 -0.708185         4096         4096.0 {20.5853,-0.891195,0.40625} 21.2603,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.822238 -0.870226         8192         8192.0 {24.0182,-0.907199,0.40625} 24.4728,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.821527
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4112; id=1, #l=227; id=2, #l=3757; id=3, #l=123; id=4, #l=189; id=5, #l=3829; id=6, #l=367; id=7, #l=136; id=8, #l=131; id=9, #l=92; id=10, #l=115; id=11, #l=975; id=12, #l=2274; id=13, #l=420; id=14, #l=101; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-35.195007 -35.195007            2            2.0 {0.00120175,-0.501804,0.00625} 0.264785,0.20625        6
-17.597504 0.000000            4            4.0 {0.207058,-0.500859,0.20625} 3.46154,0.20625        6
-8.798752 0.000000            8            8.0 {10.3501,-0.819396,0.00625} 22.5925,0.00625        6
-4.502482 -0.206211           16           16.0 {3.79951,-0.575411,0.20625} 9.58582,0.00625        6
-2.287266 -0.072051           32           32.0 {1.63048,-0.503899,0.20625} 3.89601,0.20625        6
-1.325706 -0.364146           64           64.0 {20.674,-0.864432,0.20625} 19.0236,0.20625        6
-0.883342 -0.440978          128          128.0 {18.0521,-0.975259,0.20625} 19.5193,0.20625        6
-0.918902 -0.954462          256          256.0 {20.5652,-0.873993,0.20625} 19.6559,0.20625        6
-0.887722 -0.856541          512          512.0 {18.1291,-0.905379,0.20625} 18.1648,0.20625        6
-0.818894 -0.750067         1024         1024.0 {24.1307,-0.901661,0.20625} 24.2069,0.20625        6
-0.880528 -0.942161         2048         2048.0 {20.9798,-0.8756,0.20625} 22.5621,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 1

Starting simulation for: --cats 512 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.845372 -0.810216         4096         4096.0 {22.6984,-0.804633,0.20625} 24.0279,0.20625        6
-0.789914 -0.734455         8192         8192.0 {23.4601,-0.825202,0.20625} 24.3555,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 2

Starting simulation for: --cats 512 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.798146
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4115; id=1, #l=433; id=2, #l=2259; id=3, #l=277; id=4, #l=313; id=5, #l=3305; id=6, #l=2120; id=7, #l=0; id=8, #l=146; id=9, #l=154; id=10, #l=183; id=11, #l=963; id=12, #l=1735; id=13, #l=1427; id=14, #l=0; id=15, #l=59; 
    n.a.     n.a.            1            1.0  unknown 2.7801e-05,0.270168        6
-0.591325 -0.591325            2            2.0 {2.7801e-05,-0.504232,0.270168} 0.179007,0.270168        6
-0.443554 -0.295783            4            4.0 {0.134937,-0.447002,0.270168} 2.61946,0.270168        6
-0.221777 0.000000            8            8.0 {10.3501,-0.770018,0.00625} 22.5925,0.00625        6
-0.170188 -0.118598           16           16.0 {2.87747,-0.563434,0.270168} 9.58582,0.00625        6
-0.185607 -0.201027           32           32.0 {1.20026,-0.492079,0.139583} 4.54784,0.139583        6
-0.296869 -0.408131           64           64.0 {13.3392,-0.870818,0.139583} 10.9006,0.139583        6
-0.384456 -0.472042          128          128.0 {18.7182,-0.907899,0.00625} 23.0957,0.139583        6
-0.410898 -0.437340          256          256.0 {13.1785,-0.940786,0.139583} 11.8349,0.139583        6
-0.737783 -1.064668          512          512.0 {9.57885,-0.488835,0.139583} 9.63163,0.139583        6
-0.632723 -0.527663         1024         1024.0 {23.7603,-0.869807,0.139583} 23.8729,0.139583        6
-0.727645 -0.822568         2048         2048.0 {20.7761,-0.849985,0.139583} 23.1141,0.139583        6
-0.760203 -0.792760         4096         4096.0 {19.8528,-0.921479,0.139583} 21.8174,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.785478 -0.810754         8192         8192.0 {23.9932,-0.94138,0.139583} 25.3163,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.781845
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4111; id=1, #l=498; id=2, #l=1976; id=3, #l=283; id=4, #l=0; id=5, #l=1632; id=6, #l=1977; id=7, #l=70; id=8, #l=0; id=9, #l=186; id=10, #l=383; id=11, #l=1711; id=12, #l=1366; id=13, #l=1559; id=14, #l=393; id=15, #l=35; 
    n.a.     n.a.            1            1.0  unknown 0.00019657,0.0382101        6
-0.177163 -0.177163            2            2.0 {0.00019657,-0.177908,0.0382101} 1.26568,0.0382101        6
-0.316646 -0.456129            4            4.0 {0.954087,-0.557718,0.0382101} 18.5211,0.0382101        6
-0.482781 -0.648916            8            8.0 {22.6299,-0.792699,0.0382101} 24.6323,0.0382101        6
-0.967955 -1.453129           16           16.0 {20.3454,-0.838955,0.0382101} 22.5049,0.0382101        6
-0.803866 -0.639777           32           32.0 {0.786076,-0.537324,0.0382101} 13.015,0.0382101        6
-0.807569 -0.811273           64           64.0 {19.4565,-0.921991,0.0338065} 9.38802,0.0338065        6
-0.817093 -0.826616          128          128.0 {3.74364,-0.645731,0.03125} 13.4274,0.03125        6
-0.779204 -0.741316          256          256.0 {20.3305,-0.862924,0.03125} 14.3292,0.03125        6
-0.765353 -0.751502          512          512.0 {4.25219,-0.595514,0.03125} 4.48797,0.03125        6
-0.744962 -0.724571         1024         1024.0 {24.6628,-0.73763,0.03125} 25.1656,0.03125        6
-0.742615 -0.740267         2048         2048.0 {6.26651,-0.725507,0.03125} 16.7096,0.03125        6
-0.741576 -0.740537         4096         4096.0 {11.2093,-0.858437,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 3

Starting simulation for: --cats 512 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.738942 -0.736307         8192         8192.0 {20.6363,-0.846584,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.739043
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=462; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=302; id=8, #l=149; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=280; id=15, #l=162; 
    n.a.     n.a.            1            1.0  unknown 2.93324e-07,25.6063        6
0.000000 0.000000            2            2.0 {2.93324e-07,-0.522327,25.6063} 0.00188867,25.6063        6
0.000000 0.000000            4            4.0 {0.0014237,-0.454416,25.6063} 0.0276375,25.6063        6
0.000000 0.000000            8            8.0 {10.3501,-0.780755,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0303598,-0.484786,25.6063} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00117299,-0.500768,25.6063} 0.0194211,25.6063        6
0.000000 0.000000           64           64.0 {0.0256873,-0.526841,25.6063} 0.0123945,25.6063        6
0.000000 0.000000          128          128.0 {0.00456875,-0.516277,25.6063} 0.0163869,25.6063        6
0.000000 0.000000          256          256.0 {0.0248114,-0.525532,25.6063} 0.0174874,25.6063        6
0.000000 0.000000          512          512.0 {0.0051894,-0.106437,25.6063} 0.00547714,25.6063        6
0.000000 0.000000         1024         1024.0 {0.0300986,-0.484547,25.6063} 0.0307122,25.6063        6
0.000000 0.000000         2048         2048.0 {1.0074,-0.561727,25.6063} 1.02015,25.6063        6
0.000000 0.000000         4096         4096.0 {0.0136799,-0.211369,25.6063} 0.0243891,25.6063        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 25

Starting simulation for: --cats 1024 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {3.02445,-0.533472,25.6063} 4.73021,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4036; id=1, #l=3257; id=2, #l=785; id=3, #l=2543; id=4, #l=716; id=5, #l=765; id=6, #l=21; id=7, #l=2544; id=8, #l=1; id=9, #l=0; id=10, #l=717; id=11, #l=764; id=12, #l=3; id=13, #l=21; id=14, #l=1; id=15, #l=2069; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-28.050837 -28.050837            2            2.0 {0.00120175,-0.199972,0.00625} 0.134429,0.40625        6
-14.025418 0.000000            4            4.0 {0.105122,-0.453114,0.40625} 1.7574,0.40625        6
-7.012709 0.000000            8            8.0 {10.3501,-0.814718,0.00625} 22.5925,0.00625        6
-3.595641 -0.178572           16           16.0 {1.92898,-0.540547,0.40625} 9.58582,0.00625        6
-1.812908 -0.030175           32           32.0 {3.04317,-0.611889,0.40625} 4.19336,0.40625        6
-1.107421 -0.401935           64           64.0 {21.3268,-0.808236,0.40625} 20.4889,0.40625        6
-0.778388 -0.449354          128          128.0 {18.7182,-0.974474,0.00625} 20.4944,0.40625        6
-1.134860 -1.491333          256          256.0 {21.2716,-0.834657,0.40625} 20.8099,0.40625        6
-1.638399 -2.141937          512          512.0 {21.261,-0.778405,0.00625} 21.5298,0.40625        6
-1.069279 -0.500159         1024         1024.0 {22.0664,-0.866867,0.40625} 22.105,0.40625        6
-0.966593 -0.863908         2048         2048.0 {22.8974,-0.755276,0.40625} 23.7007,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 0

Starting simulation for: --cats 1024 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.860149 -0.753705         4096         4096.0 {23.2776,-0.794197,0.40625} 23.9526,0.40625        6
-0.801991 -0.743834         8192         8192.0 {21.5105,-0.797203,0.40625} 21.9651,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 1

Starting simulation for: --cats 1024 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.826826
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4106; id=1, #l=171; id=2, #l=3912; id=3, #l=139; id=4, #l=169; id=5, #l=3663; id=6, #l=267; id=7, #l=136; id=8, #l=103; id=9, #l=98; id=10, #l=98; id=11, #l=1079; id=12, #l=2831; id=13, #l=250; id=14, #l=47; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-35.830204 -35.830204            2            2.0 {0.00120175,-0.500363,0.00625} 0.249633,0.20625        6
-17.915102 0.000000            4            4.0 {0.191906,-0.187578,0.20625} 3.44639,0.20625        6
-8.957551 0.000000            8            8.0 {10.3501,-0.815093,0.00625} 22.5925,0.00625        6
-4.524674 -0.091796           16           16.0 {3.78436,-0.277938,0.20625} 9.58583,0.00625        6
-2.304375 -0.084077           32           32.0 {2.10017,-0.513107,0.20625} 4.36571,0.20625        6
-1.356355 -0.408335           64           64.0 {20.6588,-0.846177,0.20625} 19.0085,0.20625        6
-0.931461 -0.506567          128          128.0 {18.0369,-0.944898,0.20625} 19.5042,0.20625        6
-0.671358 -0.411255          256          256.0 {20.5501,-0.911476,0.20625} 19.6408,0.20625        6
-0.710052 -0.748746          512          512.0 {18.114,-0.917888,0.20625} 18.1497,0.20625        6
-0.616708 -0.523363         1024         1024.0 {23.6307,-0.823547,0.20625} 23.7069,0.20625        6
-0.712525 -0.808343         2048         2048.0 {21.8131,-0.789377,0.20625} 23.3954,0.20625        6
-0.731074 -0.749623         4096         4096.0 {19.865,-0.866082,0.20625} 21.1946,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.735901 -0.740728         8192         8192.0 {21.2934,-0.832106,0.20625} 22.1888,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.733103
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4039; id=1, #l=587; id=2, #l=2610; id=3, #l=256; id=4, #l=450; id=5, #l=2907; id=6, #l=1987; id=7, #l=0; id=8, #l=146; id=9, #l=204; id=10, #l=312; id=11, #l=1245; id=12, #l=1654; id=13, #l=1207; id=14, #l=0; id=15, #l=49; 
    n.a.     n.a.            1            1.0  unknown 2.7661e-05,0.271535        6
-0.551882 -0.551882            2            2.0 {2.7661e-05,-0.475322,0.271535} 0.178105,0.271535        6
-0.443601 -0.335320            4            4.0 {0.134258,-0.51074,0.271535} 2.60627,0.271535        6
-0.221800 0.000000            8            8.0 {10.3501,-0.78205,0.00625} 22.5925,0.00625        6
-0.142941 -0.064081           16           16.0 {2.86298,-0.608651,0.271535} 9.58582,0.00625        6
-0.303772 -0.464604           32           32.0 {4.80576,-0.630034,0.00625} 12.1747,0.139583        6
-0.345631 -0.387489           64           64.0 {6.63766,-0.369437,0.139583} 4.19911,0.139583        6
-0.544648 -0.743665          128          128.0 {17.0919,-0.676257,0.139583} 19.2599,0.139583        6
-0.890915 -1.237183          256          256.0 {15.7904,-0.998101,0.139583} 14.4468,0.139583        6
-0.938104 -0.985293          512          512.0 {10.758,-0.831714,0.139583} 10.8107,0.139583        6
-0.753326 -0.568548         1024         1024.0 {15.417,-0.620545,0.139583} 15.5296,0.139583        6
-0.743709 -0.734092         2048         2048.0 {11.1492,-0.498097,0.139583} 13.4872,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 2

Starting simulation for: --cats 1024 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.754215 -0.764721         4096         4096.0 {14.7036,-0.982178,0.139583} 16.6681,0.139583        6
-0.785575 -0.816935         8192         8192.0 {15.829,-0.997221,0.139583} 17.1521,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.801996
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 3

Starting simulation for: --cats 1024 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2870; id=1, #l=2955; id=2, #l=1509; id=3, #l=378; id=4, #l=0; id=5, #l=2021; id=6, #l=667; id=7, #l=109; id=8, #l=0; id=9, #l=878; id=10, #l=1458; id=11, #l=1208; id=12, #l=464; id=13, #l=457; id=14, #l=124; id=15, #l=58; 
    n.a.     n.a.            1            1.0  unknown 0.000196467,0.03823        6
-0.487734 -0.487734            2            2.0 {0.000196467,-0.489751,0.03823} 1.26502,0.03823        6
-0.298081 -0.108428            4            4.0 {0.953589,-0.132646,0.03823} 18.5114,0.03823        6
-0.463596 -0.629110            8            8.0 {22.618,-0.807248,0.03823} 24.6195,0.03823        6
-1.128484 -1.793372           16           16.0 {20.3348,-0.914344,0.03823} 22.4931,0.03823        6
-0.843510 -0.558537           32           32.0 {0.785665,-0.481404,0.03823} 13.0082,0.03823        6
-0.813703 -0.783896           64           64.0 {19.448,-0.722265,0.0338214} 9.3839,0.0338214        6
-0.795147 -0.776591          128          128.0 {3.74364,-0.603415,0.03125} 13.4274,0.03125        6
-0.778828 -0.762510          256          256.0 {20.3305,-0.895068,0.03125} 14.3292,0.03125        6
-0.765196 -0.751564          512          512.0 {4.25219,-0.614423,0.03125} 4.48797,0.03125        6
-0.750502 -0.735807         1024         1024.0 {24.6628,-0.769182,0.03125} 25.1656,0.03125        6
-0.747729 -0.744957         2048         2048.0 {6.26651,-0.358665,0.03125} 16.7096,0.03125        6
-0.737744 -0.727758         4096         4096.0 {11.2093,-0.803519,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.735915 -0.734086         8192         8192.0 {20.6363,-0.793727,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.736438
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=463; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=302; id=8, #l=150; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=280; id=15, #l=162; 
    n.a.     n.a.            1            1.0  unknown 1.4668e-07,51.2062        6
0.000000 0.000000            2            2.0 {1.4668e-07,-0.465826,51.2062} 0.000944452,51.2062        6
0.000000 0.000000            4            4.0 {0.000711939,-0.504398,51.2062} 0.0138204,51.2062        6
0.000000 0.000000            8            8.0 {10.3501,-0.842583,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0151817,-0.460838,51.2062} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.000586569,-0.443027,51.2062} 0.00971176,51.2062        6
0.000000 0.000000           64           64.0 {0.0128452,-0.155047,51.2062} 0.006198,51.2062        6
0.000000 0.000000          128          128.0 {0.00228466,-0.490066,51.2062} 0.00819446,51.2062        6
0.000000 0.000000          256          256.0 {0.0124072,-0.506605,51.2062} 0.00874478,51.2062        6
0.000000 0.000000          512          512.0 {0.00259502,-0.164122,51.2062} 0.0027389,51.2062        6
0.000000 0.000000         1024         1024.0 {0.0150511,-0.440906,51.2062} 0.015358,51.2062        6
0.000000 0.000000         2048         2048.0 {0.00382431,-0.494809,51.2062} 0.0101975,51.2062        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 25

Starting simulation for: --cats 2048 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {0.00684076,-0.0982447,51.2062} 0.012196,51.2062        6
0.000000 0.000000         8192         8192.0 {2.05922,-0.532425,51.2062} 4.73022,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 0

Starting simulation for: --cats 2048 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4016; id=1, #l=3227; id=2, #l=789; id=3, #l=3227; id=4, #l=0; id=5, #l=789; id=6, #l=1; id=7, #l=3229; id=8, #l=0; id=9, #l=0; id=10, #l=1; id=11, #l=790; id=12, #l=0; id=13, #l=0; id=14, #l=1; id=15, #l=2826; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-25.407206 -25.407206            2            2.0 {0.00120175,-0.179885,0.00625} 0.126737,0.40625        6
-12.703603 0.000000            4            4.0 {0.0974294,-0.18413,0.40625} 1.7497,0.40625        6
-6.351801 0.000000            8            8.0 {10.3501,-0.822104,0.00625} 22.5925,0.00625        6
-3.201675 -0.051549           16           16.0 {1.92129,-0.512574,0.40625} 9.58582,0.00625        6
-1.638606 -0.075538           32           32.0 {1.06624,-0.507715,0.40625} 2.21644,0.40625        6
-1.014492 -0.390378           64           64.0 {22.3037,-0.826699,0.40625} 21.4658,0.40625        6
-0.765052 -0.515611          128          128.0 {18.7182,-0.928925,0.00625} 20.7329,0.40625        6
-1.073160 -1.381269          256          256.0 {21.2639,-0.826852,0.40625} 20.8022,0.40625        6
-1.506106 -1.939052          512          512.0 {20.0271,-0.848103,0.40625} 20.0452,0.40625        6
-1.124317 -0.742527         1024         1024.0 {21.5971,-0.859536,0.40625} 21.6358,0.40625        6
-0.950384 -0.776451         2048         2048.0 {14.2743,-0.928299,0.40625} 15.0777,0.40625        6
-0.804845 -0.659306         4096         4096.0 {14.6546,-0.896202,0.40625} 15.3296,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.785430 -0.766016         8192         8192.0 {15.3797,-0.991788,0.40625} 15.8343,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.807693
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4085; id=1, #l=1703; id=2, #l=2520; id=3, #l=149; id=4, #l=1608; id=5, #l=1242; id=6, #l=1119; id=7, #l=163; id=8, #l=148; id=9, #l=133; id=10, #l=1184; id=11, #l=1016; id=12, #l=1194; id=13, #l=69; id=14, #l=408; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-37.110710 -37.110710            2            2.0 {0.00120175,-0.520057,0.00625} 0.242057,0.20625        6
-18.555355 0.000000            4            4.0 {0.184331,-0.461696,0.20625} 3.43881,0.20625        6
-9.277678 0.000000            8            8.0 {10.3501,-0.762487,0.00625} 22.5925,0.00625        6
-4.733601 -0.189525           16           16.0 {3.77679,-0.591653,0.20625} 9.58582,0.00625        6
-2.406972 -0.080344           32           32.0 {2.0926,-0.516853,0.20625} 4.35813,0.20625        6
-1.377913 -0.348854           64           64.0 {5.13609,-0.371495,0.20625} 3.48576,0.20625        6
-0.959610 -0.541307          128          128.0 {10.2718,-0.776273,0.20625} 11.739,0.20625        6
-0.965354 -0.971097          256          256.0 {5.02734,-0.672788,0.20625} 4.11806,0.20625        6
-0.890234 -0.815114          512          512.0 {19.5003,-0.874403,0.20625} 19.5361,0.20625        6
-0.995019 -1.099804         1024         1024.0 {23.1383,-0.818487,0.20625} 23.2145,0.20625        6
-0.993254 -0.991489         2048         2048.0 {23.6237,-0.896613,0.20625} 25.206,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 1

Starting simulation for: --cats 2048 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.846820 -0.700386         4096         4096.0 {22.5847,-0.820847,0.20625} 23.9143,0.20625        6
-0.839142 -0.831463         8192         8192.0 {24.0131,-0.898478,0.20625} 24.9085,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 2

Starting simulation for: --cats 2048 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.826607
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4229; id=1, #l=443; id=2, #l=2717; id=3, #l=266; id=4, #l=251; id=5, #l=3413; id=6, #l=1635; id=7, #l=0; id=8, #l=141; id=9, #l=169; id=10, #l=61; id=11, #l=907; id=12, #l=1605; id=13, #l=885; id=14, #l=0; id=15, #l=62; 
    n.a.     n.a.            1            1.0  unknown 2.7591e-05,0.272224        6
-0.169466 -0.169466            2            2.0 {2.7591e-05,-0.146688,0.272224} 0.177655,0.272224        6
-0.253015 -0.336563            4            4.0 {0.133918,-0.513218,0.272224} 2.59967,0.272224        6
-0.126507 0.000000            8            8.0 {10.35,-0.763867,0.00625} 22.5925,0.00625        6
-0.226650 -0.326792           16           16.0 {14.1739,-0.936422,0.139583} 14.765,0.139583        6
-0.280405 -0.334160           32           32.0 {1.17787,-0.547426,0.139583} 4.52545,0.139583        6
-0.375493 -0.470582           64           64.0 {20.0033,-0.918589,0.139583} 17.5648,0.139583        6
-0.449559 -0.523624          128          128.0 {1.80081,-0.204226,0.139583} 3.96883,0.139583        6
-0.679785 -0.910012          256          256.0 {19.6038,-0.910619,0.139583} 18.2603,0.139583        6
-0.675038 -0.670290          512          512.0 {19.4669,-0.882105,0.139583} 19.5197,0.139583        6
-0.652252 -0.629467         1024         1024.0 {21.7379,-0.876886,0.139583} 21.8505,0.139583        6
-0.757584 -0.862915         2048         2048.0 {21.4701,-0.811077,0.139583} 23.8081,0.139583        6
-0.785273 -0.812962         4096         4096.0 {19.4274,-0.932004,0.139583} 21.392,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.801127 -0.816981         8192         8192.0 {22.3141,-0.912184,0.139583} 23.6372,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.813246
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3744; id=1, #l=826; id=2, #l=2816; id=3, #l=221; id=4, #l=0; id=5, #l=1466; id=6, #l=1887; id=7, #l=74; id=8, #l=0; id=9, #l=153; id=10, #l=683; id=11, #l=1642; id=12, #l=1194; id=13, #l=1482; id=14, #l=175; id=15, #l=37; 
    n.a.     n.a.            1            1.0  unknown 0.000196416,0.03824        6
-0.499355 -0.499355            2            2.0 {0.000196416,-0.501402,0.03824} 1.26469,0.03824        6
-0.471462 -0.443570            4            4.0 {0.953339,-0.542788,0.03824} 18.5066,0.03824        6
-0.547819 -0.624176            8            8.0 {22.6121,-0.81019,0.03824} 24.613,0.03824        6
-1.015336 -1.482854           16           16.0 {20.3295,-0.916579,0.03824} 22.4872,0.03824        6
-0.801602 -0.587868           32           32.0 {0.78546,-0.206747,0.03824} 13.0048,0.03824        6
-0.776927 -0.752252           64           64.0 {19.4437,-0.949661,0.0338288} 9.38184,0.0338288        6
-0.768045 -0.759163          128          128.0 {3.74364,-0.583663,0.03125} 13.4274,0.03125        6
-0.754110 -0.740174          256          256.0 {20.3305,-0.907503,0.03125} 14.3292,0.03125        6
-0.754533 -0.754956          512          512.0 {4.25219,-0.620546,0.03125} 4.48797,0.03125        6
-0.743011 -0.731490         1024         1024.0 {24.6628,-0.728691,0.03125} 25.1656,0.03125        6
-0.745027 -0.747042         2048         2048.0 {6.26651,-0.680774,0.03125} 16.7096,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 3

Starting simulation for: --cats 2048 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.737830 -0.730633         4096         4096.0 {11.2093,-0.798089,0.03125} 19.9844,0.03125        6
-0.737040 -0.736250         8192         8192.0 {20.6363,-0.897276,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.737235
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 25

Plotting...
</pre></div>
</div>
<img alt="../_images/python_cats_35_94.png" src="../_images/python_cats_35_94.png" />
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "VowpalWabbit/vowpal_wabbit",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="off_policy_evaluation.html" title="previous page">Offline policy evaluation using the VW command line</a>
    <a class='right-next' id="next-link" href="python_classification.html" title="next page">Classification with Vowpal Wabbit</a>

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, John langford et al.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.4.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>