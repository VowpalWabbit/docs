
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Simulating a smart thermostat using CATS: a Contextual Bandit algorithm with a continuous action space &#8212; VowpalWabbit latest documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nav.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".cell"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Classification with Vowpal Wabbit" href="python_classification.html" />
    <link rel="prev" title="Offline policy evaluation using the VW command line" href="off_policy_evaluation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <div class="navbar_container main_nav_container">
  <div class="container nav_wrapper">
    <div class="logo">
      <a href="https://vowpalwabbit.org/index.html">
        <?xml version="1.0" encoding="UTF-8"?>
<svg width="172px" height="30px" viewBox="0 0 172 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 57.1 (83088) - https://sketch.com -->
    <title>logo_vw_horiz_gray</title>
    <desc>Created with Sketch.</desc>
    <g id="Styles" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Desktop-Copy" transform="translate(-944.000000, -314.000000)">
            <g id="logo_vw_horiz_gray" transform="translate(941.000000, 314.000000)">
                <rect id="framework" x="0" y="0" width="175" height="30"></rect>
                <path d="M49.488,22 L46.59,22 L42.252,10.12 L44.88,10.12 L47.382,17.68 L48.066,20.02 L48.732,17.698 L51.252,10.12 L53.808,10.12 L49.488,22 Z M58.524,12.82 C59.9760073,12.82 61.106996,13.2339959 61.917,14.062 C62.7270041,14.8900041 63.132,16.0359927 63.132,17.5 C63.132,18.9640073 62.7270041,20.1099959 61.917,20.938 C61.106996,21.7660041 59.9760073,22.18 58.524,22.18 C57.0719927,22.18 55.9410041,21.7660041 55.131,20.938 C54.320996,20.1099959 53.916,18.9640073 53.916,17.5 C53.916,16.0359927 54.320996,14.8900041 55.131,14.062 C55.9410041,13.2339959 57.0719927,12.82 58.524,12.82 Z M58.524,14.656 C57.8279965,14.656 57.2970018,14.8929976 56.931,15.367 C56.5649982,15.8410024 56.382,16.5519953 56.382,17.5 C56.382,18.4480047 56.5649982,19.1589976 56.931,19.633 C57.2970018,20.1070024 57.8279965,20.344 58.524,20.344 C59.2200035,20.344 59.7509982,20.1070024 60.117,19.633 C60.4830018,19.1589976 60.666,18.4480047 60.666,17.5 C60.666,16.5519953 60.4830018,15.8410024 60.117,15.367 C59.7509982,14.8929976 59.2200035,14.656 58.524,14.656 Z M79.368,13 L76.506,22 L73.644,22 L71.682,15.646 L69.792,22 L66.948,22 L64.086,13 L66.696,13 L68.496,20.02 L70.512,13 L72.942,13 L74.958,20.02 L76.758,13 L79.368,13 Z M86.316,12.82 C87.516006,12.82 88.4579966,13.2309959 89.142,14.053 C89.8260034,14.8750041 90.168,16.0179927 90.168,17.482 C90.168,18.9580074 89.8260034,20.1099959 89.142,20.938 C88.4579966,21.7660041 87.516006,22.18 86.316,22.18 C85.6679968,22.18 85.1040024,22.0330015 84.624,21.739 C84.1439976,21.4449985 83.7660014,21.0400026 83.49,20.524 L83.49,25.78 L81.024,25.78 L81.024,13 L83.202,13 L83.292,14.782 C83.5560013,14.181997 83.9489974,13.7050018 84.471,13.351 C84.9930026,12.9969982 85.6079965,12.82 86.316,12.82 Z M85.578,20.29 C86.2500034,20.29 86.7719981,20.0500024 87.144,19.57 C87.5160019,19.0899976 87.702,18.4000045 87.702,17.5 C87.702,16.5999955 87.5160019,15.9100024 87.144,15.43 C86.7719981,14.9499976 86.2500034,14.71 85.578,14.71 C84.977997,14.71 84.4920019,14.9169979 84.12,15.331 C83.7479981,15.7450021 83.5380002,16.3359962 83.49,17.104 L83.49,17.896 C83.5380002,18.6520038 83.7479981,19.2399979 84.12,19.66 C84.4920019,20.0800021 84.977997,20.29 85.578,20.29 Z M100.518,20.506 C100.770001,20.506 100.973999,20.4820002 101.13,20.434 L100.95,21.928 C100.613998,22.0960008 100.224002,22.18 99.78,22.18 C98.6279942,22.18 97.9380011,21.7300045 97.71,20.83 C97.4459987,21.2740022 97.0380028,21.6099989 96.486,21.838 C95.9339972,22.0660011 95.2800038,22.18 94.524,22.18 C93.6479956,22.18 92.9640025,21.982002 92.472,21.586 C91.9799975,21.189998 91.734,20.6200037 91.734,19.876 C91.734,18.4119927 92.9039883,17.4640022 95.244,17.032 L97.404,16.618 L97.404,16.186 C97.404,15.7059976 97.2690014,15.3250014 96.999,15.043 C96.7289987,14.7609986 96.3540024,14.62 95.874,14.62 C95.3219972,14.62 94.8720017,14.7399988 94.524,14.98 C94.1759983,15.2200012 93.9360007,15.6099973 93.804,16.15 L91.842,15.322 C92.034001,14.5419961 92.4659966,13.9300022 93.138,13.486 C93.8100034,13.0419978 94.6859946,12.82 95.766,12.82 C97.0500064,12.82 98.0519964,13.0989972 98.772,13.657 C99.4920036,14.2150028 99.852,15.0399945 99.852,16.132 L99.852,19.822 C99.852,20.0620012 99.9059995,20.2359995 100.014,20.344 C100.122001,20.4520005 100.289999,20.506 100.518,20.506 Z M95.298,20.506 C95.8260026,20.506 96.3089978,20.3770013 96.747,20.119 C97.1850022,19.8609987 97.404,19.5100022 97.404,19.066 L97.404,18.13 L95.478,18.562 C95.069998,18.6580005 94.767001,18.7869992 94.569,18.949 C94.370999,19.1110008 94.272,19.3359986 94.272,19.624 C94.272,19.9120014 94.3619991,20.1309992 94.542,20.281 C94.7220009,20.4310007 94.9739984,20.506 95.298,20.506 Z M105.054,19.138 C105.054,19.5700022 105.116999,19.8699992 105.243,20.038 C105.369001,20.2060008 105.599998,20.29 105.936,20.29 C106.140001,20.29 106.316999,20.2750001 106.467,20.245 C106.617001,20.2149998 106.793999,20.1640004 106.998,20.092 L106.782,21.802 C106.589999,21.9220006 106.338002,22.0149997 106.026,22.081 C105.713998,22.1470003 105.408002,22.18 105.108,22.18 C104.231996,22.18 103.593002,21.9670021 103.191,21.541 C102.788998,21.1149979 102.588,20.4340047 102.588,19.498 L102.588,9.058 L105.054,9.058 L105.054,19.138 Z M118.482,22 L115.62,22 L112.164,10.12 L114.846,10.12 L117.15,20.038 L119.526,10.12 L121.902,10.12 L124.314,20.038 L126.618,10.12 L129.174,10.12 L125.718,22 L122.928,22 L121.272,15.52 L120.714,12.712 L120.678,12.712 L120.12,15.52 L118.482,22 Z M138.336,20.506 C138.588001,20.506 138.791999,20.4820002 138.948,20.434 L138.768,21.928 C138.431998,22.0960008 138.042002,22.18 137.598,22.18 C136.445994,22.18 135.756001,21.7300045 135.528,20.83 C135.263999,21.2740022 134.856003,21.6099989 134.304,21.838 C133.751997,22.0660011 133.098004,22.18 132.342,22.18 C131.465996,22.18 130.782002,21.982002 130.29,21.586 C129.797998,21.189998 129.552,20.6200037 129.552,19.876 C129.552,18.4119927 130.721988,17.4640022 133.062,17.032 L135.222,16.618 L135.222,16.186 C135.222,15.7059976 135.087001,15.3250014 134.817,15.043 C134.546999,14.7609986 134.172002,14.62 133.692,14.62 C133.139997,14.62 132.690002,14.7399988 132.342,14.98 C131.993998,15.2200012 131.754001,15.6099973 131.622,16.15 L129.66,15.322 C129.852001,14.5419961 130.283997,13.9300022 130.956,13.486 C131.628003,13.0419978 132.503995,12.82 133.584,12.82 C134.868006,12.82 135.869996,13.0989972 136.59,13.657 C137.310004,14.2150028 137.67,15.0399945 137.67,16.132 L137.67,19.822 C137.67,20.0620012 137.723999,20.2359995 137.832,20.344 C137.940001,20.4520005 138.107999,20.506 138.336,20.506 Z M133.116,20.506 C133.644003,20.506 134.126998,20.3770013 134.565,20.119 C135.003002,19.8609987 135.222,19.5100022 135.222,19.066 L135.222,18.13 L133.296,18.562 C132.887998,18.6580005 132.585001,18.7869992 132.387,18.949 C132.188999,19.1110008 132.09,19.3359986 132.09,19.624 C132.09,19.9120014 132.179999,20.1309992 132.36,20.281 C132.540001,20.4310007 132.791998,20.506 133.116,20.506 Z M145.734,12.82 C146.934006,12.82 147.875997,13.2339959 148.56,14.062 C149.244003,14.8900041 149.586,16.0419926 149.586,17.518 C149.586,18.9820073 149.244003,20.1249959 148.56,20.947 C147.875997,21.7690041 146.934006,22.18 145.734,22.18 C145.025996,22.18 144.411003,22.0030018 143.889,21.649 C143.366997,21.2949982 142.974001,20.818003 142.71,20.218 L142.62,22 L140.442,22 L140.442,9.058 L142.908,9.058 L142.908,14.476 C143.184001,13.9599974 143.561998,13.5550015 144.042,13.261 C144.522002,12.9669985 145.085997,12.82 145.734,12.82 Z M144.996,20.29 C145.668003,20.29 146.189998,20.0500024 146.562,19.57 C146.934002,19.0899976 147.12,18.4000045 147.12,17.5 C147.12,16.5999955 146.934002,15.9100024 146.562,15.43 C146.189998,14.9499976 145.668003,14.71 144.996,14.71 C144.395997,14.71 143.910002,14.9199979 143.538,15.34 C143.165998,15.7600021 142.956,16.3479962 142.908,17.104 L142.908,17.896 C142.956,18.6640038 143.165998,19.2549979 143.538,19.669 C143.910002,20.0830021 144.395997,20.29 144.996,20.29 Z M157.056,12.82 C158.256006,12.82 159.197997,13.2339959 159.882,14.062 C160.566003,14.8900041 160.908,16.0419926 160.908,17.518 C160.908,18.9820073 160.566003,20.1249959 159.882,20.947 C159.197997,21.7690041 158.256006,22.18 157.056,22.18 C156.347996,22.18 155.733003,22.0030018 155.211,21.649 C154.688997,21.2949982 154.296001,20.818003 154.032,20.218 L153.942,22 L151.764,22 L151.764,9.058 L154.23,9.058 L154.23,14.476 C154.506001,13.9599974 154.883998,13.5550015 155.364,13.261 C155.844002,12.9669985 156.407997,12.82 157.056,12.82 Z M156.318,20.29 C156.990003,20.29 157.511998,20.0500024 157.884,19.57 C158.256002,19.0899976 158.442,18.4000045 158.442,17.5 C158.442,16.5999955 158.256002,15.9100024 157.884,15.43 C157.511998,14.9499976 156.990003,14.71 156.318,14.71 C155.717997,14.71 155.232002,14.9199979 154.86,15.34 C154.487998,15.7600021 154.278,16.3479962 154.23,17.104 L154.23,17.896 C154.278,18.6640038 154.487998,19.2549979 154.86,19.669 C155.232002,20.0830021 155.717997,20.29 156.318,20.29 Z M164.328,11.704 C163.307995,11.704 162.798,11.2660044 162.798,10.39 C162.798,9.50199556 163.307995,9.058 164.328,9.058 C165.348005,9.058 165.858,9.50199556 165.858,10.39 C165.858,11.2660044 165.348005,11.704 164.328,11.704 Z M165.552,22 L163.086,22 L163.086,13 L165.552,13 L165.552,22 Z M174.336,21.442 C174.047999,21.6700011 173.685002,21.8499993 173.247,21.982 C172.808998,22.1140007 172.350002,22.18 171.87,22.18 C169.86599,22.18 168.864,21.2740091 168.864,19.462 L168.864,14.836 L167.226,14.836 L167.226,13 L168.864,13 L168.864,10.93 L171.33,10.246 L171.33,13 L174.246,13 L174.246,14.836 L171.33,14.836 L171.33,19.066 C171.33,19.8940041 171.743996,20.308 172.572,20.308 C173.100003,20.308 173.561998,20.1400017 173.958,19.804 L174.336,21.442 Z" id="VowpalWabbit" fill="#333333" fill-rule="nonzero"></path>
                <g id="logo_vw_color" transform="translate(3.000000, 0.000000)" fill="#2A3B93">
                    <path d="M27.9875518,16.6117194 C27.9875518,9.21947752 21.9666728,9.36035971 21.9666728,9.36035971 C21.3736977,6.15536974 20.3362508,3.5963294 19.3414955,1.96947553 C18.1790857,0.436543115 17.3241355,0 17.3241355,0 C16.2887633,0.700737156 15.7766231,3.93943024 15.7766231,3.93943024 C14.1726939,1.18184505 12.329851,1.05294263 12.329851,1.05294263 C9.93824094,8.37466357 17.0427696,11.1203489 17.0427696,11.1203489 C9.97542657,11.1203489 6.33307087,15.0400524 4.59284756,17.9877167 C4.0042614,19.0524794 3.60319929,20.0302689 3.35048069,20.7371557 L2.99801525,21.8605394 C1.89952322,21.2108361 0.011355398,21.1878349 0.011355398,21.1878349 C-0.278708419,29.2136474 5.0845596,28.0167877 5.0845596,28.0167877 C5.0845596,29.1432063 6.56177043,30 6.56177043,30 L18.0978518,30 C18.0978518,30 17.9248509,28.5478912 16.7183131,27.7616983 C16.5196972,27.4693917 16.4533057,27.212705 16.6897456,26.9422016 C17.354698,26.1816454 17.8296525,27.1798804 17.8296525,27.1798804 L18.3302221,27.8553801 C19.7539686,29.627988 20.7440159,29.9516816 21.1646284,30 L21.391732,30 C20.5763614,27.5009384 20.6054875,25.3190215 20.6054875,25.3190215 C20.4822802,22.1365535 22.8107704,19.2166024 22.8107704,19.2166024 C28.5084697,19.2166024 27.9875518,16.6117194 27.9875518,16.6117194" id="logo_rabbit"></path>
                </g>
            </g>
        </g>
    </g>
</svg>
      </a>
    </div>

    <div class="nav">
      <a href="https://vowpalwabbit.org/start.html">
        Get started
      </a>
      <a href="https://vowpalwabbit.org/features.html">
        Features
      </a>
      <a href="https://vowpalwabbit.org/tutorials.html">
        Tutorials
      </a>
      <a href="https://vowpalwabbit.org/blog.html">
        Blog
      </a>
      <a href="https://vowpalwabbit.org/research.html">
        Research
      </a>
      <div class="external_links">
        <a class="active" href="index.html">
          Doc
        </a>

        <a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki" target="_blank">
          Wiki
        </a>

        <a href="https://github.com/VowpalWabbit/vowpal_wabbit" target="_blank" class="github_link">
          <?xml version="1.0" encoding="UTF-8"?>
<svg width="30px" height="30px" viewBox="0 0 30 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 53 (72520) - https://sketchapp.com -->
    <title>GitHub</title>
    <desc>Created with Sketch.</desc>
    <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="HD_Desktop_header_Home" transform="translate(-1538.000000, -58.000000)" fill="#FFFFFF">
            <g id="Header">
                <path d="M1568,73.7951128 C1567.94603,74.2583723 1567.89891,74.7224863 1567.83682,75.1847206 C1567.56271,77.2238487 1566.86543,79.1138828 1565.7732,80.8526868 C1564.55268,82.7956941 1562.9969,84.4188114 1561.05088,85.6538569 C1560.03339,86.2996179 1558.94817,86.8066231 1557.80753,87.1895684 C1557.17559,87.4016322 1556.73848,87.0743943 1556.73531,86.4093237 C1556.72907,85.1020808 1556.73745,83.7947524 1556.73164,82.487424 C1556.72804,81.6908602 1556.64825,80.9063436 1556.21259,80.2087201 C1556.0855,80.0052003 1555.92463,79.8226135 1555.77393,79.6234512 C1556.35935,79.5140871 1556.9463,79.4362506 1557.51632,79.2916849 C1559.04696,78.9034423 1560.41543,78.2275208 1561.34791,76.8924242 C1562.03287,75.9115647 1562.34632,74.7851144 1562.48436,73.6108172 C1562.59169,72.6982249 1562.62222,71.7826422 1562.42971,70.8740656 C1562.23608,69.9599354 1561.84044,69.1418405 1561.22834,68.4359293 C1561.07756,68.2620575 1561.04763,68.1215929 1561.12221,67.896713 C1561.52468,66.6818314 1561.3562,65.491984 1560.9042,64.3262309 C1560.87829,64.2595017 1560.76574,64.1973008 1560.68569,64.1853391 C1560.15364,64.1058793 1559.65196,64.2559986 1559.18533,64.4761793 C1558.42904,64.8332361 1557.69764,65.242668 1556.9487,65.6159585 C1556.82229,65.6790137 1556.64782,65.7219904 1556.51706,65.6889249 C1554.16941,65.0964789 1551.82595,65.097077 1549.47805,65.6883268 C1549.34078,65.7228448 1549.14638,65.677134 1549.02331,65.5987849 C1548.07109,64.9919849 1547.06446,64.5120644 1545.97001,64.2236166 C1545.9511,64.218661 1545.93272,64.2115694 1545.91364,64.2077246 C1545.22551,64.0670892 1545.09971,64.1456947 1544.9036,64.8108506 C1544.58682,65.884755 1544.5296,66.9550708 1544.90668,68.0296587 C1544.93627,68.1139033 1544.90129,68.2616303 1544.8404,68.3306664 C1543.60397,69.7341156 1543.31096,71.3989279 1543.46559,73.1936101 C1543.55933,74.2817831 1543.81162,75.3262104 1544.29869,76.3083514 C1544.97176,77.6654063 1546.11181,78.4952066 1547.4926,78.982475 C1548.35956,79.2884382 1549.27852,79.4473579 1550.18824,79.6758264 C1550.19526,79.6319098 1550.20056,79.6666842 1550.18568,79.6820635 C1549.71726,80.1697591 1549.45556,80.755028 1549.34531,81.4170227 C1549.33137,81.5007546 1549.27365,81.6203716 1549.20685,81.6454912 C1548.16482,82.0372369 1547.11706,82.2433199 1546.08683,81.6149888 C1545.61867,81.3295314 1545.27683,80.9169382 1545.00101,80.4479541 C1544.56852,79.712395 1543.95864,79.179074 1543.13923,78.9361661 C1542.84434,78.8487602 1542.50823,78.8709748 1542.19359,78.8892591 C1541.97909,78.9018189 1541.90862,79.062362 1542.05256,79.2422147 C1542.18529,79.4077988 1542.32025,79.5950849 1542.4978,79.6971865 C1543.28625,80.1507913 1543.72798,80.8753286 1544.08881,81.6641173 C1544.30382,82.1341266 1544.48812,82.6140471 1544.88675,82.9753759 C1545.52169,83.5510755 1546.29115,83.7682658 1547.11612,83.8044072 C1547.81434,83.834995 1548.51496,83.8107298 1549.24722,83.8107298 C1549.24611,83.8009041 1549.26073,83.8742123 1549.26167,83.9476058 C1549.27211,84.7377616 1549.2828,85.5279173 1549.28844,86.3180731 C1549.294,87.0913115 1548.82935,87.4109452 1548.0952,87.1563319 C1544.28705,85.8355039 1541.4928,83.3342269 1539.62819,79.7992882 C1538.22405,77.1372118 1537.78027,74.2780237 1538.09739,71.2935795 C1538.4294,68.1688416 1539.66702,65.4337134 1541.73193,63.0872551 C1543.89022,60.6347648 1546.57714,59.0045559 1549.78825,58.3523869 C1554.45335,57.4048494 1558.71409,58.3562318 1562.44442,61.3515269 C1565.27245,63.6222848 1567.02271,66.5767393 1567.72914,70.1361141 C1567.83314,70.6605492 1567.87265,71.197715 1567.94398,71.7286436 C1567.95792,71.832625 1567.9811,71.9354102 1568,72.0387934 L1568,73.7951128 Z" id="GitHub"></path>
            </g>
        </g>
    </g>
</svg>
          <div>
            GitHub
          </div>
        </a>
      </div>
    </div>
  </div>
</div>
    <div class="navbar_container mobile_nav_container">
  <div class="container nav_wrapper">
    <div class="hamburger_icon">
      <?xml version="1.0" encoding="UTF-8"?>
<svg width="18px" height="16px" viewBox="0 0 18 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: sketchtool 57.1 (101010) - https://sketch.com -->
    <title>8049A6A1-2687-43E9-9B5D-E205E8F9E871</title>
    <desc>Created with sketchtool.</desc>
    <g id="Pages" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd" stroke-linecap="round">
        <g id="Mobile_home" transform="translate(-12.000000, -56.000000)" stroke="#FFFFFF" stroke-width="2">
            <g id="header">
                <g id="ui_header_mobile_dk" transform="translate(12.000000, 44.000000)">
                    <g id="icon_menu" transform="translate(1.000000, 12.500000)">
                        <g id="Line">
                            <path d="M16,0.5 L0,0.5"></path>
                            <path d="M16,7.5 L0,7.5"></path>
                            <path d="M16,14.5 L0,14.5"></path>
                        </g>
                    </g>
                </g>
            </g>
        </g>
    </g>
</svg>
    </div>
    <div class="logo">
      <a href="https://vowpalwabbit.org/index.html">
        <?xml version="1.0" encoding="UTF-8"?>
<svg width="172px" height="30px" viewBox="0 0 172 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 57.1 (83088) - https://sketch.com -->
    <title>logo_vw_horiz_gray</title>
    <desc>Created with Sketch.</desc>
    <g id="Styles" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Desktop-Copy" transform="translate(-944.000000, -314.000000)">
            <g id="logo_vw_horiz_gray" transform="translate(941.000000, 314.000000)">
                <rect id="framework" x="0" y="0" width="175" height="30"></rect>
                <path d="M49.488,22 L46.59,22 L42.252,10.12 L44.88,10.12 L47.382,17.68 L48.066,20.02 L48.732,17.698 L51.252,10.12 L53.808,10.12 L49.488,22 Z M58.524,12.82 C59.9760073,12.82 61.106996,13.2339959 61.917,14.062 C62.7270041,14.8900041 63.132,16.0359927 63.132,17.5 C63.132,18.9640073 62.7270041,20.1099959 61.917,20.938 C61.106996,21.7660041 59.9760073,22.18 58.524,22.18 C57.0719927,22.18 55.9410041,21.7660041 55.131,20.938 C54.320996,20.1099959 53.916,18.9640073 53.916,17.5 C53.916,16.0359927 54.320996,14.8900041 55.131,14.062 C55.9410041,13.2339959 57.0719927,12.82 58.524,12.82 Z M58.524,14.656 C57.8279965,14.656 57.2970018,14.8929976 56.931,15.367 C56.5649982,15.8410024 56.382,16.5519953 56.382,17.5 C56.382,18.4480047 56.5649982,19.1589976 56.931,19.633 C57.2970018,20.1070024 57.8279965,20.344 58.524,20.344 C59.2200035,20.344 59.7509982,20.1070024 60.117,19.633 C60.4830018,19.1589976 60.666,18.4480047 60.666,17.5 C60.666,16.5519953 60.4830018,15.8410024 60.117,15.367 C59.7509982,14.8929976 59.2200035,14.656 58.524,14.656 Z M79.368,13 L76.506,22 L73.644,22 L71.682,15.646 L69.792,22 L66.948,22 L64.086,13 L66.696,13 L68.496,20.02 L70.512,13 L72.942,13 L74.958,20.02 L76.758,13 L79.368,13 Z M86.316,12.82 C87.516006,12.82 88.4579966,13.2309959 89.142,14.053 C89.8260034,14.8750041 90.168,16.0179927 90.168,17.482 C90.168,18.9580074 89.8260034,20.1099959 89.142,20.938 C88.4579966,21.7660041 87.516006,22.18 86.316,22.18 C85.6679968,22.18 85.1040024,22.0330015 84.624,21.739 C84.1439976,21.4449985 83.7660014,21.0400026 83.49,20.524 L83.49,25.78 L81.024,25.78 L81.024,13 L83.202,13 L83.292,14.782 C83.5560013,14.181997 83.9489974,13.7050018 84.471,13.351 C84.9930026,12.9969982 85.6079965,12.82 86.316,12.82 Z M85.578,20.29 C86.2500034,20.29 86.7719981,20.0500024 87.144,19.57 C87.5160019,19.0899976 87.702,18.4000045 87.702,17.5 C87.702,16.5999955 87.5160019,15.9100024 87.144,15.43 C86.7719981,14.9499976 86.2500034,14.71 85.578,14.71 C84.977997,14.71 84.4920019,14.9169979 84.12,15.331 C83.7479981,15.7450021 83.5380002,16.3359962 83.49,17.104 L83.49,17.896 C83.5380002,18.6520038 83.7479981,19.2399979 84.12,19.66 C84.4920019,20.0800021 84.977997,20.29 85.578,20.29 Z M100.518,20.506 C100.770001,20.506 100.973999,20.4820002 101.13,20.434 L100.95,21.928 C100.613998,22.0960008 100.224002,22.18 99.78,22.18 C98.6279942,22.18 97.9380011,21.7300045 97.71,20.83 C97.4459987,21.2740022 97.0380028,21.6099989 96.486,21.838 C95.9339972,22.0660011 95.2800038,22.18 94.524,22.18 C93.6479956,22.18 92.9640025,21.982002 92.472,21.586 C91.9799975,21.189998 91.734,20.6200037 91.734,19.876 C91.734,18.4119927 92.9039883,17.4640022 95.244,17.032 L97.404,16.618 L97.404,16.186 C97.404,15.7059976 97.2690014,15.3250014 96.999,15.043 C96.7289987,14.7609986 96.3540024,14.62 95.874,14.62 C95.3219972,14.62 94.8720017,14.7399988 94.524,14.98 C94.1759983,15.2200012 93.9360007,15.6099973 93.804,16.15 L91.842,15.322 C92.034001,14.5419961 92.4659966,13.9300022 93.138,13.486 C93.8100034,13.0419978 94.6859946,12.82 95.766,12.82 C97.0500064,12.82 98.0519964,13.0989972 98.772,13.657 C99.4920036,14.2150028 99.852,15.0399945 99.852,16.132 L99.852,19.822 C99.852,20.0620012 99.9059995,20.2359995 100.014,20.344 C100.122001,20.4520005 100.289999,20.506 100.518,20.506 Z M95.298,20.506 C95.8260026,20.506 96.3089978,20.3770013 96.747,20.119 C97.1850022,19.8609987 97.404,19.5100022 97.404,19.066 L97.404,18.13 L95.478,18.562 C95.069998,18.6580005 94.767001,18.7869992 94.569,18.949 C94.370999,19.1110008 94.272,19.3359986 94.272,19.624 C94.272,19.9120014 94.3619991,20.1309992 94.542,20.281 C94.7220009,20.4310007 94.9739984,20.506 95.298,20.506 Z M105.054,19.138 C105.054,19.5700022 105.116999,19.8699992 105.243,20.038 C105.369001,20.2060008 105.599998,20.29 105.936,20.29 C106.140001,20.29 106.316999,20.2750001 106.467,20.245 C106.617001,20.2149998 106.793999,20.1640004 106.998,20.092 L106.782,21.802 C106.589999,21.9220006 106.338002,22.0149997 106.026,22.081 C105.713998,22.1470003 105.408002,22.18 105.108,22.18 C104.231996,22.18 103.593002,21.9670021 103.191,21.541 C102.788998,21.1149979 102.588,20.4340047 102.588,19.498 L102.588,9.058 L105.054,9.058 L105.054,19.138 Z M118.482,22 L115.62,22 L112.164,10.12 L114.846,10.12 L117.15,20.038 L119.526,10.12 L121.902,10.12 L124.314,20.038 L126.618,10.12 L129.174,10.12 L125.718,22 L122.928,22 L121.272,15.52 L120.714,12.712 L120.678,12.712 L120.12,15.52 L118.482,22 Z M138.336,20.506 C138.588001,20.506 138.791999,20.4820002 138.948,20.434 L138.768,21.928 C138.431998,22.0960008 138.042002,22.18 137.598,22.18 C136.445994,22.18 135.756001,21.7300045 135.528,20.83 C135.263999,21.2740022 134.856003,21.6099989 134.304,21.838 C133.751997,22.0660011 133.098004,22.18 132.342,22.18 C131.465996,22.18 130.782002,21.982002 130.29,21.586 C129.797998,21.189998 129.552,20.6200037 129.552,19.876 C129.552,18.4119927 130.721988,17.4640022 133.062,17.032 L135.222,16.618 L135.222,16.186 C135.222,15.7059976 135.087001,15.3250014 134.817,15.043 C134.546999,14.7609986 134.172002,14.62 133.692,14.62 C133.139997,14.62 132.690002,14.7399988 132.342,14.98 C131.993998,15.2200012 131.754001,15.6099973 131.622,16.15 L129.66,15.322 C129.852001,14.5419961 130.283997,13.9300022 130.956,13.486 C131.628003,13.0419978 132.503995,12.82 133.584,12.82 C134.868006,12.82 135.869996,13.0989972 136.59,13.657 C137.310004,14.2150028 137.67,15.0399945 137.67,16.132 L137.67,19.822 C137.67,20.0620012 137.723999,20.2359995 137.832,20.344 C137.940001,20.4520005 138.107999,20.506 138.336,20.506 Z M133.116,20.506 C133.644003,20.506 134.126998,20.3770013 134.565,20.119 C135.003002,19.8609987 135.222,19.5100022 135.222,19.066 L135.222,18.13 L133.296,18.562 C132.887998,18.6580005 132.585001,18.7869992 132.387,18.949 C132.188999,19.1110008 132.09,19.3359986 132.09,19.624 C132.09,19.9120014 132.179999,20.1309992 132.36,20.281 C132.540001,20.4310007 132.791998,20.506 133.116,20.506 Z M145.734,12.82 C146.934006,12.82 147.875997,13.2339959 148.56,14.062 C149.244003,14.8900041 149.586,16.0419926 149.586,17.518 C149.586,18.9820073 149.244003,20.1249959 148.56,20.947 C147.875997,21.7690041 146.934006,22.18 145.734,22.18 C145.025996,22.18 144.411003,22.0030018 143.889,21.649 C143.366997,21.2949982 142.974001,20.818003 142.71,20.218 L142.62,22 L140.442,22 L140.442,9.058 L142.908,9.058 L142.908,14.476 C143.184001,13.9599974 143.561998,13.5550015 144.042,13.261 C144.522002,12.9669985 145.085997,12.82 145.734,12.82 Z M144.996,20.29 C145.668003,20.29 146.189998,20.0500024 146.562,19.57 C146.934002,19.0899976 147.12,18.4000045 147.12,17.5 C147.12,16.5999955 146.934002,15.9100024 146.562,15.43 C146.189998,14.9499976 145.668003,14.71 144.996,14.71 C144.395997,14.71 143.910002,14.9199979 143.538,15.34 C143.165998,15.7600021 142.956,16.3479962 142.908,17.104 L142.908,17.896 C142.956,18.6640038 143.165998,19.2549979 143.538,19.669 C143.910002,20.0830021 144.395997,20.29 144.996,20.29 Z M157.056,12.82 C158.256006,12.82 159.197997,13.2339959 159.882,14.062 C160.566003,14.8900041 160.908,16.0419926 160.908,17.518 C160.908,18.9820073 160.566003,20.1249959 159.882,20.947 C159.197997,21.7690041 158.256006,22.18 157.056,22.18 C156.347996,22.18 155.733003,22.0030018 155.211,21.649 C154.688997,21.2949982 154.296001,20.818003 154.032,20.218 L153.942,22 L151.764,22 L151.764,9.058 L154.23,9.058 L154.23,14.476 C154.506001,13.9599974 154.883998,13.5550015 155.364,13.261 C155.844002,12.9669985 156.407997,12.82 157.056,12.82 Z M156.318,20.29 C156.990003,20.29 157.511998,20.0500024 157.884,19.57 C158.256002,19.0899976 158.442,18.4000045 158.442,17.5 C158.442,16.5999955 158.256002,15.9100024 157.884,15.43 C157.511998,14.9499976 156.990003,14.71 156.318,14.71 C155.717997,14.71 155.232002,14.9199979 154.86,15.34 C154.487998,15.7600021 154.278,16.3479962 154.23,17.104 L154.23,17.896 C154.278,18.6640038 154.487998,19.2549979 154.86,19.669 C155.232002,20.0830021 155.717997,20.29 156.318,20.29 Z M164.328,11.704 C163.307995,11.704 162.798,11.2660044 162.798,10.39 C162.798,9.50199556 163.307995,9.058 164.328,9.058 C165.348005,9.058 165.858,9.50199556 165.858,10.39 C165.858,11.2660044 165.348005,11.704 164.328,11.704 Z M165.552,22 L163.086,22 L163.086,13 L165.552,13 L165.552,22 Z M174.336,21.442 C174.047999,21.6700011 173.685002,21.8499993 173.247,21.982 C172.808998,22.1140007 172.350002,22.18 171.87,22.18 C169.86599,22.18 168.864,21.2740091 168.864,19.462 L168.864,14.836 L167.226,14.836 L167.226,13 L168.864,13 L168.864,10.93 L171.33,10.246 L171.33,13 L174.246,13 L174.246,14.836 L171.33,14.836 L171.33,19.066 C171.33,19.8940041 171.743996,20.308 172.572,20.308 C173.100003,20.308 173.561998,20.1400017 173.958,19.804 L174.336,21.442 Z" id="VowpalWabbit" fill="#333333" fill-rule="nonzero"></path>
                <g id="logo_vw_color" transform="translate(3.000000, 0.000000)" fill="#2A3B93">
                    <path d="M27.9875518,16.6117194 C27.9875518,9.21947752 21.9666728,9.36035971 21.9666728,9.36035971 C21.3736977,6.15536974 20.3362508,3.5963294 19.3414955,1.96947553 C18.1790857,0.436543115 17.3241355,0 17.3241355,0 C16.2887633,0.700737156 15.7766231,3.93943024 15.7766231,3.93943024 C14.1726939,1.18184505 12.329851,1.05294263 12.329851,1.05294263 C9.93824094,8.37466357 17.0427696,11.1203489 17.0427696,11.1203489 C9.97542657,11.1203489 6.33307087,15.0400524 4.59284756,17.9877167 C4.0042614,19.0524794 3.60319929,20.0302689 3.35048069,20.7371557 L2.99801525,21.8605394 C1.89952322,21.2108361 0.011355398,21.1878349 0.011355398,21.1878349 C-0.278708419,29.2136474 5.0845596,28.0167877 5.0845596,28.0167877 C5.0845596,29.1432063 6.56177043,30 6.56177043,30 L18.0978518,30 C18.0978518,30 17.9248509,28.5478912 16.7183131,27.7616983 C16.5196972,27.4693917 16.4533057,27.212705 16.6897456,26.9422016 C17.354698,26.1816454 17.8296525,27.1798804 17.8296525,27.1798804 L18.3302221,27.8553801 C19.7539686,29.627988 20.7440159,29.9516816 21.1646284,30 L21.391732,30 C20.5763614,27.5009384 20.6054875,25.3190215 20.6054875,25.3190215 C20.4822802,22.1365535 22.8107704,19.2166024 22.8107704,19.2166024 C28.5084697,19.2166024 27.9875518,16.6117194 27.9875518,16.6117194" id="logo_rabbit"></path>
                </g>
            </g>
        </g>
    </g>
</svg>
      </a>
    </div>
  </div>
</div>

<div class="mobile_nav">
  <button type="button" class="go_back_button">
    <
  </button>

  <a href="https://vowpalwabbit.org/start.html">
    Get started
  </a>
  <a href="https://vowpalwabbit.org/features.html">
    Features
  </a>
  <a href="https://vowpalwabbit.org/tutorials.html">
    Tutorials
  </a>
  <a href="https://vowpalwabbit.org/blog.html">
    Blog
  </a>
  <a href="https://vowpalwabbit.org/research.html">
    Research
  </a>
  <div class="external_links">
    <a href="https://github.com/VowpalWabbit/vowpalwabbit.github.io/issues/new"
      target="_blank"
    >
      Feedback
    </a>

    <a class="active" href="index.html">
      Doc
    </a>

    <a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki" target="_blank">
      Wiki
    </a>

    <a href="https://github.com/VowpalWabbit/vowpal_wabbit" target="_blank" class="github_link">
      <?xml version="1.0" encoding="UTF-8"?>
<svg width="30px" height="30px" viewBox="0 0 30 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 53 (72520) - https://sketchapp.com -->
    <title>GitHub</title>
    <desc>Created with Sketch.</desc>
    <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="HD_Desktop_header_Home" transform="translate(-1538.000000, -58.000000)" fill="#FFFFFF">
            <g id="Header">
                <path d="M1568,73.7951128 C1567.94603,74.2583723 1567.89891,74.7224863 1567.83682,75.1847206 C1567.56271,77.2238487 1566.86543,79.1138828 1565.7732,80.8526868 C1564.55268,82.7956941 1562.9969,84.4188114 1561.05088,85.6538569 C1560.03339,86.2996179 1558.94817,86.8066231 1557.80753,87.1895684 C1557.17559,87.4016322 1556.73848,87.0743943 1556.73531,86.4093237 C1556.72907,85.1020808 1556.73745,83.7947524 1556.73164,82.487424 C1556.72804,81.6908602 1556.64825,80.9063436 1556.21259,80.2087201 C1556.0855,80.0052003 1555.92463,79.8226135 1555.77393,79.6234512 C1556.35935,79.5140871 1556.9463,79.4362506 1557.51632,79.2916849 C1559.04696,78.9034423 1560.41543,78.2275208 1561.34791,76.8924242 C1562.03287,75.9115647 1562.34632,74.7851144 1562.48436,73.6108172 C1562.59169,72.6982249 1562.62222,71.7826422 1562.42971,70.8740656 C1562.23608,69.9599354 1561.84044,69.1418405 1561.22834,68.4359293 C1561.07756,68.2620575 1561.04763,68.1215929 1561.12221,67.896713 C1561.52468,66.6818314 1561.3562,65.491984 1560.9042,64.3262309 C1560.87829,64.2595017 1560.76574,64.1973008 1560.68569,64.1853391 C1560.15364,64.1058793 1559.65196,64.2559986 1559.18533,64.4761793 C1558.42904,64.8332361 1557.69764,65.242668 1556.9487,65.6159585 C1556.82229,65.6790137 1556.64782,65.7219904 1556.51706,65.6889249 C1554.16941,65.0964789 1551.82595,65.097077 1549.47805,65.6883268 C1549.34078,65.7228448 1549.14638,65.677134 1549.02331,65.5987849 C1548.07109,64.9919849 1547.06446,64.5120644 1545.97001,64.2236166 C1545.9511,64.218661 1545.93272,64.2115694 1545.91364,64.2077246 C1545.22551,64.0670892 1545.09971,64.1456947 1544.9036,64.8108506 C1544.58682,65.884755 1544.5296,66.9550708 1544.90668,68.0296587 C1544.93627,68.1139033 1544.90129,68.2616303 1544.8404,68.3306664 C1543.60397,69.7341156 1543.31096,71.3989279 1543.46559,73.1936101 C1543.55933,74.2817831 1543.81162,75.3262104 1544.29869,76.3083514 C1544.97176,77.6654063 1546.11181,78.4952066 1547.4926,78.982475 C1548.35956,79.2884382 1549.27852,79.4473579 1550.18824,79.6758264 C1550.19526,79.6319098 1550.20056,79.6666842 1550.18568,79.6820635 C1549.71726,80.1697591 1549.45556,80.755028 1549.34531,81.4170227 C1549.33137,81.5007546 1549.27365,81.6203716 1549.20685,81.6454912 C1548.16482,82.0372369 1547.11706,82.2433199 1546.08683,81.6149888 C1545.61867,81.3295314 1545.27683,80.9169382 1545.00101,80.4479541 C1544.56852,79.712395 1543.95864,79.179074 1543.13923,78.9361661 C1542.84434,78.8487602 1542.50823,78.8709748 1542.19359,78.8892591 C1541.97909,78.9018189 1541.90862,79.062362 1542.05256,79.2422147 C1542.18529,79.4077988 1542.32025,79.5950849 1542.4978,79.6971865 C1543.28625,80.1507913 1543.72798,80.8753286 1544.08881,81.6641173 C1544.30382,82.1341266 1544.48812,82.6140471 1544.88675,82.9753759 C1545.52169,83.5510755 1546.29115,83.7682658 1547.11612,83.8044072 C1547.81434,83.834995 1548.51496,83.8107298 1549.24722,83.8107298 C1549.24611,83.8009041 1549.26073,83.8742123 1549.26167,83.9476058 C1549.27211,84.7377616 1549.2828,85.5279173 1549.28844,86.3180731 C1549.294,87.0913115 1548.82935,87.4109452 1548.0952,87.1563319 C1544.28705,85.8355039 1541.4928,83.3342269 1539.62819,79.7992882 C1538.22405,77.1372118 1537.78027,74.2780237 1538.09739,71.2935795 C1538.4294,68.1688416 1539.66702,65.4337134 1541.73193,63.0872551 C1543.89022,60.6347648 1546.57714,59.0045559 1549.78825,58.3523869 C1554.45335,57.4048494 1558.71409,58.3562318 1562.44442,61.3515269 C1565.27245,63.6222848 1567.02271,66.5767393 1567.72914,70.1361141 C1567.83314,70.6605492 1567.87265,71.197715 1567.94398,71.7286436 C1567.95792,71.832625 1567.9811,71.9354102 1568,72.0387934 L1568,73.7951128 Z" id="GitHub"></path>
            </g>
        </g>
    </g>
</svg>

      <div>
        GitHub
      </div>
    </a>
  </div>
</div>

<script script type="text/javascript">
  $(".mobile_nav_container").on("click", ".hamburger_icon", (e) => {
    e.stopPropagation();
    $(".mobile_nav").addClass("open");
  });

  $('body').on("click", ".mobile_nav .go_back_button", () => {
    $(".mobile_nav").removeClass("open");
  });
</script>


    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><a href="https://vowpalwabbit.org/docs/">
  latest
</a>

<i class="fas fa-angle-down"></i>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Tutorials
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="cmd_first_steps.html">
     Command line tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cmd_linear_regression.html">
     Linear Regression Tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="off_policy_evaluation.html">
     Offline policy evaluation using the VW command line
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Simulating a smart thermostat using CATS: a Contextual Bandit algorithm with a continuous action space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_classification.html">
     Classification with Vowpal Wabbit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_Contextual_bandits_and_Vowpal_Wabbit.html">
     Contextual bandits and Vowpal Wabbit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_Simulating_a_news_personalization_scenario_using_Contextual_Bandits.html">
     Simulating a news personalization scenario using Contextual Bandits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_first_steps.html">
     Basics with Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_slates.html">
     Slates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DFtoVW_tutorial.html">
     Using DFtoVW and exploring VW output
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../examples/index.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/basics.html">
     Python Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/contextual_bandit.html">
     Contextual Bandits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/mini_vw.html">
     Mini VW
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/poisson_regression.html">
     Poisson Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/predict.html">
     Predict comparison
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/search_covington.html">
     Search - Covington
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/search_sequence_ldf.html">
     Search - Sequence LDF
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/search_sequence.html">
     Search - Sequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/search_speech_tagger.html">
     Search - Speech Tagger
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../reference/index.html">
   API Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/vowpalwabbit.pyvw.html">
     vowpalwabbit.pyvw
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/vowpalwabbit.sklearn.html">
     vowpalwabbit.sklearn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/vowpalwabbit.DFtoVW.html">
     vowpalwabbit.DFtoVW
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/vowpalwabbit.pyvw.pylibvw.html">
     vowpalwabbit.pyvw.pylibvw
    </a>
   </li>
  </ul>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-reward">
   Simulate reward
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#getting-a-decision">
   Getting a decision
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulation-set-up">
   Simulation set up
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scenario-1">
   Scenario 1
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#with-learning">
     With Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#without-learning">
     Without Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameter-sweep">
   Parameter sweep
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     With Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Without Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scenario-2">
   Scenario 2
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#living-room">
     Living Room
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bedroom">
     Bedroom
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     With Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Without Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scenario-3">
   Scenario 3
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#better-cost-function">
     Better cost function
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                

<div class="tocsection editthispage">
    <a href="https://github.com/VowpalWabbit/vowpal_wabbit/edit/master/python/docs/source/tutorials/python_cats.ipynb">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
    
    
    <button title="Activate interactive cells" class="thebelab-button thebe-launch-button" onclick="initThebe()">
        Make live
    </button>
    <a class="binder-button" href="https://mybinder.org/v2/gh/VowpalWabbit/vowpal_wabbit/master?filepath=python/docs/source/tutorials/python_cats.ipynb">
        <img class="binder-button-logo" src="https://mybinder.org/badge_logo.svg" alt="Binder">
    </a>
    

              <div>
                
  <div class="section" id="simulating-a-smart-thermostat-using-cats-a-contextual-bandit-algorithm-with-a-continuous-action-space">
<h1>Simulating a smart thermostat using CATS: a Contextual Bandit algorithm with a continuous action space<a class="headerlink" href="#simulating-a-smart-thermostat-using-cats-a-contextual-bandit-algorithm-with-a-continuous-action-space" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial we will simulate the scenario of personalizing a thermostat for a household with two rooms using Contextual Bandits in a continuous action space. The goal is to maximize user satisfaction with the thermostat quantified by measuring thermostat accuracy or reward (TR). The thermostat proposes a temperature and the user will either accept the temperature or adjust it to fit their needs.</p>
<p>Let’s recall that in a CB setting, a data point has four components,</p>
<ul class="simple">
<li><p>Context</p></li>
<li><p>Chosen Action</p></li>
<li><p>Probability of chosen action</p></li>
<li><p>Reward/cost for chosen action</p></li>
</ul>
<p>In our simulator we will need to generate a context, get an action/decision for the given context, and also simulate generating a reward.</p>
<p>The goal of the learning agent is to maximize the reward or to minimize the loss.</p>
<p>The thermostat tracks two rooms: ‘Living Room’ and ‘Bedroom’.
Each room will need temperature adjustment either in the morning or in the afternoon.
The context is therefore (room, time_of_day).</p>
<p>In a continuous range we can’t specify actions since there are infinite actions we can take across the continuous range. We do however provide the minimum value and the maximum value of the range. Here we will range between 0 degrees Celsius and 32 degrees Celsius using 1 degree increments which gives us a continuous range of 33 degrees.</p>
<p>The reward is measured using the absolute difference between the proposed temperature and the one that was actually set by the people living in the house.</p>
<p>Let’s first start with importing the necessary packages:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">vowpalwabbit</span> <span class="kn">import</span> <span class="n">pyvw</span>
<span class="kn">import</span> <span class="nn">pylibvw</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">json</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># VW minimizes loss/cost, therefore we will pass cost as -reward</span>
<span class="n">USER_LIKED_TEMPERATURE</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
<span class="n">USER_DISLIKED_TEMPERATURE</span> <span class="o">=</span> <span class="mf">0.0</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="simulate-reward">
<h2>Simulate reward<a class="headerlink" href="#simulate-reward" title="Permalink to this headline">¶</a></h2>
<p>In the real world we will have to learn the room temperature preferences as we observe the interactions between the proposed temperature for each room and the one selected by the people living in the house. Since this is a simulation we will have to define the preference profile for each room. The reward that we provide to the learner will follow this preference profile. Our hope is to see if the learner can take better and better decisions as we see more samples which in turn means we are maximizing the reward.</p>
<p>We will also modify the reward function in a few different ways and see if the CB learner picks up the changes. We will compare the TR with and without learning.</p>
<p>VW minimizes the cost, which is defined as -reward. Therefore, we will pass the cost associated to each chosen action to VW.</p>
<p>The reward function below specifies that we want the living room to be cold in the morning but warm in the afternoon. In reverse, we prefer the bedroom to be warm in the morning and cold in the afternoon. It looks dense but we are just simulating our hypothetical world in the format of the feedback the learner understands: cost. If the learner recommends a temperature that aligns with the reward function, we give a positive reward. Max reward is -1.0, min reward is 0 since VW learns in terms of cost, so we return a negative reward. In our simulated world this is the difference between the temperature recommended and the temperature chosen. If the difference is smaller than 5 degrees then we give a reward to the thermostat. This is a steep cost function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_cost</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">):</span>
    <span class="nb">range</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">max_value</span> <span class="o">-</span> <span class="n">min_value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Living Room&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">29</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Bedroom&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">29</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This function modifies (context, temperature (i.e. action), cost, probability) to VW friendly json format</span>
<span class="k">def</span> <span class="nf">to_vw_example_format</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cats_label</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">example_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">cats_label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">chosen_temp</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">pdf_value</span> <span class="o">=</span> <span class="n">cats_label</span>
        <span class="n">example_dict</span><span class="p">[</span><span class="s1">&#39;_label_ca&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;action&#39;</span> <span class="p">:</span> <span class="n">chosen_temp</span><span class="p">,</span> <span class="s1">&#39;cost&#39;</span><span class="p">:</span> <span class="n">cost</span><span class="p">,</span> <span class="s1">&#39;pdf_value&#39;</span><span class="p">:</span> <span class="n">pdf_value</span><span class="p">}</span>
    <span class="n">example_dict</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;room=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]):</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;time_of_day=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">])</span> <span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">example_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="getting-a-decision">
<h2>Getting a decision<a class="headerlink" href="#getting-a-decision" title="Permalink to this headline">¶</a></h2>
<p>We call VW and get a predicted temperature and the value of the probability density function at that temperature. Since we are predicting over a continuous range VW will sample a pdf before returning the predicted value and the density of the pdf at that point. We are incorporating exploration into our strategy so the pdf will be more dense around the value that VW chooses to predict, and less dense in the rest of the continuous range. So it is more likely that VW will choose an action around the predicted value.</p>
<p>We have all of the information we need to choose a temperature for a specific room and time of day. To use VW to achieve this, we will do the following:</p>
<p>We convert our context into the json format we need.
We pass this example to VW and get the chosen action and the probability of chosing that action.
Finally we return the chosen temperature and the probability of choosing it (we are going to need the probability when we learn form this example)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_temperature</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="n">vw_text_example</span> <span class="o">=</span> <span class="n">to_vw_example_format</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">vw</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">vw_text_example</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="simulation-set-up">
<h2>Simulation set up<a class="headerlink" href="#simulation-set-up" title="Permalink to this headline">¶</a></h2>
<p>Now that we have done all of the setup work and know how to interact with VW, let’s simulate the world of our two rooms. The scenario is that the thermostat it turned on in each room and it has to propose a temperature. Remember that the reward function allows us to define the worlds reaction to what VW recommends.</p>
<p>We will choose between ‘Living Room’ and ‘Bedroom’ uniformly at random and also choose the time of day uniformly at random. We can think of this as tossing a coin to choose between the rooms (‘Living Room’ if heads and ‘Bedroom’ if tails) and another coin toss for choosing time of day.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rooms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Living Room&#39;</span><span class="p">,</span> <span class="s1">&#39;Bedroom&#39;</span><span class="p">]</span>
<span class="n">times_of_day</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;morning&#39;</span><span class="p">,</span> <span class="s1">&#39;afternoon&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">choose_room</span><span class="p">(</span><span class="n">rooms</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">rooms</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">choose_time_of_day</span><span class="p">(</span><span class="n">times_of_day</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">times_of_day</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will instantiate a CB learner in VW and then simulate the thermostat interaction num_iterations number of times. In each interaction, we:</p>
<ol class="simple">
<li><p>Decide between ‘Living Room’ and ‘Bedroom’</p></li>
<li><p>Decide time of day</p></li>
<li><p>Pass context i.e. (room, time of day) to learner to get a temperature i.e. a value between min (0 degrees) and max (32 degrees) and probability of choosing that temperature</p></li>
<li><p>Receive reward i.e. see if the proposed temperature was adjusted or not, and by how much. Remember that cost is just negative reward.</p></li>
<li><p>Format context, action (temperature), probability, and reward into VW format</p></li>
<li><p>Learn from the example</p></li>
</ol>
<p>The above steps are repeatedly executed during our simulations, so we define the process in the run_simulation function. The cost function must be supplied as this is essentially us simulating how the world works.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">cost_function</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="n">reward_rate</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">hits</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">cost_sum</span> <span class="o">=</span> <span class="mf">0.</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># 1. In each simulation choose a room</span>
        <span class="n">room</span> <span class="o">=</span> <span class="n">choose_room</span><span class="p">(</span><span class="n">rooms</span><span class="p">)</span>
        <span class="c1"># 2. Choose time of day for a given room</span>
        <span class="n">time_of_day</span> <span class="o">=</span> <span class="n">choose_time_of_day</span><span class="p">(</span><span class="n">times_of_day</span><span class="p">)</span>
        <span class="c1"># 3. Pass context to vw to get a temperature</span>
        <span class="n">context</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;room&#39;</span><span class="p">:</span> <span class="n">room</span><span class="p">,</span> <span class="s1">&#39;time_of_day&#39;</span><span class="p">:</span> <span class="n">time_of_day</span><span class="p">}</span>
        <span class="n">temperature</span><span class="p">,</span> <span class="n">pdf_value</span> <span class="o">=</span> <span class="n">predict_temperature</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        
        <span class="c1"># 4. Get cost of the action we chose</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">cost_function</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cost</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="mf">0.75</span><span class="p">:</span> <span class="c1"># count something as a hit only if it has a high reward</span>
            <span class="n">hits</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">cost_sum</span> <span class="o">+=</span> <span class="n">cost</span>

        <span class="k">if</span> <span class="n">do_learn</span><span class="p">:</span>
            <span class="c1"># 5. Inform VW of what happened so we can learn from it</span>
            <span class="n">txt_ex</span> <span class="o">=</span> <span class="n">to_vw_example_format</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cats_label</span><span class="o">=</span><span class="p">(</span><span class="n">temperature</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">pdf_value</span><span class="p">))</span>
            <span class="n">vw_format</span> <span class="o">=</span> <span class="n">vw</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">txt_ex</span><span class="p">,</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="o">.</span><span class="n">lContinuous</span><span class="p">)</span>
            <span class="c1"># 6. Learn</span>
            <span class="n">vw</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">vw_format</span><span class="p">)</span>
            <span class="c1"># 7. Let VW know you&#39;re done with these objects</span>
            <span class="n">vw</span><span class="o">.</span><span class="n">finish_example</span><span class="p">(</span><span class="n">vw_format</span><span class="p">)</span>

        <span class="c1"># We negate this so that on the plot instead of minimizing cost, we are maximizing reward</span>
        <span class="n">reward_rate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">cost_sum</span><span class="o">/</span><span class="n">i</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">reward_rate</span><span class="p">,</span> <span class="n">hits</span>
</pre></div>
</div>
</div>
</div>
<p>We want to be able to visualize what is occurring, so we are going to plot the reward rate over each iteration of the simulation. If VW is showing temperatures the that are close to what the simulated world wants, the reward will be higher. Below is a little utility function to make showing the plot easier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_reward_rate</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">reward_rate</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">reward_rate</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;num_iterations&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;reward rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="scenario-1">
<h2>Scenario 1<a class="headerlink" href="#scenario-1" title="Permalink to this headline">¶</a></h2>
<p>We will use the first reward function get_cost and assume that the preferences for room temperatures do not change over time and see what happens to the smart thermostat as we learn. We will also see what happens when there is no learning. We will use the “no learning” case as our baseline to compare to.</p>
<p>We will be using the CATS algorithm which does tree based learning with smoothing. That means that we need to provide the number of actions (buckets/tree leaves) that the continuous range will be discretized into, and then we need to define the bandwidth which is the radius around the chosen discreet action that the algorithm will sample a temperature from with higher probability.</p>
<p>For example, in our current range of 32 degrees celsius if we select the number of actions to be 8 that means that the algorithm will initially predict an action from the centre of one of 8 buckets:</p>
<p><code class="docutils literal notranslate"><span class="pre">(0</span> <span class="pre">-</span> <span class="pre">2</span> <span class="pre">-</span> <span class="pre">4),</span> <span class="pre">(4</span> <span class="pre">-</span> <span class="pre">6</span> <span class="pre">-</span> <span class="pre">8),</span> <span class="pre">(8</span> <span class="pre">-</span> <span class="pre">10</span> <span class="pre">-</span> <span class="pre">12),</span> <span class="pre">(12</span> <span class="pre">-</span> <span class="pre">14</span> <span class="pre">-</span> <span class="pre">16),</span> <span class="pre">(16</span> <span class="pre">-</span> <span class="pre">18</span> <span class="pre">-</span> <span class="pre">20),</span> <span class="pre">(20</span> <span class="pre">-</span> <span class="pre">22</span> <span class="pre">-</span> <span class="pre">24),</span> <span class="pre">(24</span> <span class="pre">-</span> <span class="pre">26</span> <span class="pre">-</span> <span class="pre">28),</span> <span class="pre">(28</span> <span class="pre">-</span> <span class="pre">30</span> <span class="pre">-</span> <span class="pre">32)</span></code></p>
<p>Let’s say that for a given context, it selects the third bucket that starts from 8 degrees celsius, goes until 12 degrees celsius, and has a center of 10 degrees celsius. For a smoothing radius (bandwidth) of 1 the resulting probability density function (pdf) that VW will have to sample from will have a higher density around</p>
<p><code class="docutils literal notranslate"><span class="pre">[bucket_centre</span> <span class="pre">-</span> <span class="pre">bandwidth,</span> <span class="pre">bucket_centre</span> <span class="pre">+</span> <span class="pre">bandwidth]</span></code></p>
<p>i.e. [9, 11]. If bandwidth was bigger, for example 5 then we would have higher density (and therefore higher probability of selecting an action) in the range [5, 15], providing a smoothing range that spans the discretized buckets. The bandwidth is defined in terms of the continuous range (max_value - min_value)</p>
<div class="section" id="with-learning">
<h3>With Learning<a class="headerlink" href="#with-learning" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="n">num_actions</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Instantiate VW learner</span>
<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidth</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
<span class="n">ctr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
<span class="n">plot_reward_rate</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">ctr</span><span class="p">,</span> <span class="s1">&#39;reward rate with num_actions = 32 and bandwidth = 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.611352,0.40625        6
0.000000 0.000000            4            4.0 {0.582045,0,0.40625} 2.23432,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,-1,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.40591,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.566242,0,0.40625} 1.71644,0.40625        6
0.000000 0.000000           64           64.0 {2.1114,0,0.40625} 1.27354,0.40625        6
-0.019231 -0.038462          128          128.0 {18.7182,-1,0.00625} 20.2329,0.40625        6
-0.221154 -0.423077          256          256.0 {24.7023,-1,0.40625} 24.2407,0.40625        6
-0.341346 -0.461538          512          512.0 {19.5271,0,0.40625} 19.5452,0.40625        6
-0.557692 -0.774038         1024         1024.0 {25.0356,-1,0.40625} 25.0743,0.40625        6
-0.641827 -0.725962         2048         2048.0 {12.7897,0,0.40625} 13.593,0.40625        6
-0.744591 -0.847356         4096         4096.0 {24.0007,-1,0.40625} 24.6757,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.731971 -0.719351         8192         8192.0 {19.8028,-1,0.40625} 20.2574,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.706708
total feature number = 60000
</pre></div>
</div>
<img alt="../_images/python_cats_15_2.png" src="../_images/python_cats_15_2.png" />
</div>
</div>
</div>
<div class="section" id="without-learning">
<h3>Without Learning<a class="headerlink" href="#without-learning" title="Permalink to this headline">¶</a></h3>
<p>Let’s do the same but without learning. The reward rate never improves and just hovers around 0.5</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="n">num_actions</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Instantiate VW learner</span>
<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidth</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
<span class="n">ctr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
<span class="n">plot_reward_rate</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">ctr</span><span class="p">,</span> <span class="s1">&#39;click through rate with num_actions = 32 and bandwidth = 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Learn() count per node: id=0, #l=3657; id=1, #l=970; id=2, #l=2140; id=3, #l=0; id=4, #l=808; id=5, #l=1637; id=6, #l=1115; id=7, #l=0; id=8, #l=0; id=9, #l=226; id=10, #l=318; id=11, #l=1009; id=12, #l=1700; id=13, #l=887; id=14, #l=33; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.611352,0.40625        6
    n.a.     n.a.            4            4.0  unknown 2.23432,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.71644,0.40625        6
    n.a.     n.a.           64           64.0  unknown 1.27354,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.52519,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.59455,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.837536,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.42812,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.77766,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 2.02957,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
</pre></div>
</div>
<img alt="../_images/python_cats_17_2.png" src="../_images/python_cats_17_2.png" />
</div>
</div>
</div>
</div>
<div class="section" id="parameter-sweep">
<h2>Parameter sweep<a class="headerlink" href="#parameter-sweep" title="Permalink to this headline">¶</a></h2>
<p>Next let’s do a parameter sweep for different values of <code class="docutils literal notranslate"><span class="pre">num_actions</span></code> and <code class="docutils literal notranslate"><span class="pre">bandwidth</span></code>. We will use the below function to help us plot the reward rates for different combinations of <code class="docutils literal notranslate"><span class="pre">num_actions</span></code> and <code class="docutils literal notranslate"><span class="pre">bandwidths</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_reward_sweep</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">bandwidths</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">n_actions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
    <span class="n">n_bandwidths</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">bandwidths</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">n_bandwidths</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bandwidths</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">bandwidths</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;NA&#39;</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="n">reward_rate</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="p">])][</span><span class="nb">str</span><span class="p">(</span><span class="n">bandwidths</span><span class="p">[</span><span class="n">j</span><span class="p">])]</span>
            <span class="n">hits_percentage</span> <span class="o">=</span> <span class="p">(</span><span class="n">hits</span><span class="o">/</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">))</span><span class="o">*</span><span class="mi">100</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">reward_rate</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;hits </span><span class="si">{:.2f}</span><span class="s1">% TR </span><span class="si">{:.2f}</span><span class="s1">%&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">hits_percentage</span><span class="p">,</span> <span class="n">reward_rate</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;b: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidths</span><span class="p">[</span><span class="n">j</span><span class="o">%</span><span class="k">len</span>(bandwidths)]), fontsize=14)
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;k: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="o">%</span><span class="k">len</span>(actions)]), fontsize=14)

    <span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="s1">&#39;num_iterations&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;reward_rate&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_figheight</span><span class="p">(</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_figwidth</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;#examples </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">))</span>

    <span class="c1"># Hide x labels and tick labels for top plots and y ticks for right plots.</span>
    <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axs</span><span class="o">.</span><span class="n">flat</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">label_outer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id1">
<h3>With Learning<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>We will try all the number of actions as powers of 2 from 8 until 2048. Since our continuous range stays the same (0-32) we are creating smaller range buckets as the number of actions grows. The number of actions needs to be a power of 2 as it represents the number of leaves that the internal binary tree will have. Small number of actions might result in coarser discretizaton leading to results similar to uniform random. On the other hand really large number of actions could mean that we need a lot more data in order to train all of the buckets.</p>
<p>We will also try all the combinaitons of the above action numbers with bandwidths ranging from 0 to 25. The smaller the bandwidth the smaller the smoothing range around the selected continuous value. Really large bandwidths will result in large smoothing ranges and could lead to results similar to uniform random.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># do parameter sweeping</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">]</span>
<span class="n">bandwidths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span>

<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="k">for</span> <span class="n">actions</span> <span class="ow">in</span> <span class="n">num_actions</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="n">bandwidths</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">bd</span> <span class="o">&gt;=</span> <span class="n">actions</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting simulation for: --cats </span><span class="si">{}</span><span class="s2"> --bandwidth </span><span class="si">{}</span><span class="s2"> --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
        <span class="n">rr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done with simulation for num_actions: </span><span class="si">{}</span><span class="s2"> and bandwidth: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)][</span><span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">rr</span><span class="p">,</span> <span class="n">hits</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Plotting...&quot;</span><span class="p">)</span>
<span class="n">plot_reward_sweep</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">bandwidths</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting simulation for: --cats 8 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
0.000000 0.000000            2            2.0 {3.64167e-05,0,0.20625} 0.234482,0.20625        6
0.000000 0.000000            4            4.0 {0.176755,0,0.20625} 3.43124,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.76921,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.145629,0,0.20625} 2.41116,0.20625        6
0.000000 0.000000           64           64.0 {22.5831,0,0.20625} 20.9327,0.20625        6
0.000000 0.000000          128          128.0 {18.7182,-1,0.00625} 21.4284,0.20625        6
0.000000 0.000000          256          256.0 {22.4743,0,0.20625} 21.565,0.20625        6
0.000000 0.000000          512          512.0 {12.2806,-1,0.20625} 12.3164,0.20625        6
0.000000 0.000000         1024         1024.0 {19.2519,-1,0.20625} 19.3281,0.20625        6
0.000000 0.000000         2048         2048.0 {20.3434,0,0.20625} 21.9257,0.20625        6
0.000000 0.000000         4096         4096.0 {24.9711,-1,0.20625} 26.3007,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {18.6419,-1,0.20625} 19.5373,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3899; id=1, #l=460; id=2, #l=3478; id=3, #l=0; id=4, #l=471; id=5, #l=2115; id=6, #l=1455; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 1.10366,0.40625        6
0.000000 0.000000            4            4.0 {1.07435,0,0.40625} 2.72663,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.89821,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {1.05855,0,0.40625} 2.20875,0.40625        6
0.000000 0.000000           64           64.0 {22.296,0,0.40625} 21.4582,0.40625        6
-0.250000 -0.500000          128          128.0 {18.7182,-1,0.00625} 21.7098,0.40625        6
-0.375000 -0.500000          256          256.0 {22.2408,-1,0.40625} 21.7792,0.40625        6
-0.524038 -0.673077          512          512.0 {13.1271,-1,0.40625} 13.1452,0.40625        6
-0.555288 -0.586538         1024         1024.0 {22.5741,0,0.40625} 22.6127,0.40625        6
-0.591346 -0.627404         2048         2048.0 {25.0974,-1,0.40625} 25.9007,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 0

Starting simulation for: --cats 8 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.688101 -0.784856         4096         4096.0 {21.5392,-1,0.40625} 22.2142,0.40625        6
-0.765926 -0.843750         8192         8192.0 {14.3874,-1,0.40625} 14.842,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.782523
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 1

Starting simulation for: --cats 8 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Learn() count per node: id=0, #l=3782; id=1, #l=1796; id=2, #l=2029; id=3, #l=0; id=4, #l=1807; id=5, #l=524; id=6, #l=1597; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
0.000000 0.000000            2            2.0 {3.64167e-05,0,0.20625} 0.234482,0.20625        6
0.000000 0.000000            4            4.0 {0.176755,0,0.20625} 3.43124,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.76921,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.145629,0,0.20625} 2.41116,0.20625        6
0.000000 0.000000           64           64.0 {3.18912,0,0.20625} 1.53879,0.20625        6
0.000000 0.000000          128          128.0 {0.567218,0,0.20625} 2.03446,0.20625        6
0.000000 0.000000          256          256.0 {3.08037,0,0.20625} 2.17109,0.20625        6
-0.184659 -0.369318          512          512.0 {21.261,0,0.00625} 22.4398,0.00625        6
-0.471117 -0.757576         1024         1024.0 {30.8883,0,0.20625} 30.9645,0.20625        6
-0.630919 -0.790720         2048         2048.0 {16.4646,-1,0.20625} 18.0469,0.20625        6
-0.705492 -0.780066         4096         4096.0 {17.2135,-1,0.20625} 18.5431,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.728279 -0.751065         8192         8192.0 {26.3994,-1,0.20625} 27.2949,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.756849
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3732; id=1, #l=565; id=2, #l=3210; id=3, #l=0; id=4, #l=569; id=5, #l=1830; id=6, #l=1451; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 3.21214,0.139583        6
0.000000 0.000000            4            4.0 {3.12685,0,0.139583} 7.93571,0.139583        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {8.4351,0,0.139583} 9.58582,0.00625        6
-0.074627 -0.149254           32           32.0 {4.80576,0,0.00625} 17.8911,0.139583        6
-0.149254 -0.223881           64           64.0 {19.0406,0,0.139583} 16.6021,0.139583        6
-0.261194 -0.373134          128          128.0 {15.1665,-1,0.139583} 17.3345,0.139583        6
-0.544154 -0.827114          256          256.0 {18.88,-1,0.139583} 17.5364,0.139583        6
-0.671953 -0.799751          512          512.0 {15.2803,-1,0.139583} 15.3331,0.139583        6
-0.631685 -0.591418         1024         1024.0 {19.8499,-1,0.139583} 19.9624,0.139583        6
-0.657960 -0.684235         2048         2048.0 {23.3731,-1,0.139583} 25.7111,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 2

Starting simulation for: --cats 8 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.701065 -0.744170         4096         4096.0 {24.4797,-1,0.139583} 26.4443,0.139583        6
-0.733637 -0.766208         8192         8192.0 {26.5902,-1,0.139583} 27.9133,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.749087
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2349; id=1, #l=1828; id=2, #l=2168; id=3, #l=0; id=4, #l=1460; id=5, #l=1739; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 9.31589e-06,0.80625        6
0.000000 0.000000            2            2.0 {9.31589e-06,0,0.80625} 0.0599837,0.80625        6
0.000000 0.000000            4            4.0 {0.0452164,0,0.80625} 0.877758,0.80625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.964217,0,0.80625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0372539,0,0.80625} 0.616809,0.80625        6
0.000000 0.000000           64           64.0 {20.6608,-1,0.80625} 20.2386,0.80625        6
0.000000 0.000000          128          128.0 {18.7182,0,0.00625} 20.3654,0.80625        6
0.000000 0.000000          256          256.0 {20.633,-1,0.80625} 20.4004,0.80625        6
0.000000 0.000000          512          512.0 {21.002,-1,0.80625} 21.0112,0.80625        6
0.000000 0.000000         1024         1024.0 {21.7931,0,0.80625} 21.8126,0.80625        6
0.000000 0.000000         2048         2048.0 {21.0801,0,0.80625} 21.4849,0.80625        6
0.000000 0.000000         4096         4096.0 {21.2717,0,0.80625} 21.6118,0.80625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {19.6526,-1,0.80625} 19.8816,0.80625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3448; id=1, #l=920; id=2, #l=2539; id=3, #l=0; id=4, #l=925; id=5, #l=1072; id=6, #l=1494; id=7, #l=0; id=8, #l=0; id=9, #l=5; id=10, #l=935; id=11, #l=503; id=12, #l=589; id=13, #l=1497; id=14, #l=14; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.611352,0.40625        6
0.000000 0.000000            4            4.0 {0.582045,0,0.40625} 2.23432,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.40591,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.566242,0,0.40625} 1.71644,0.40625        6
0.000000 0.000000           64           64.0 {2.1114,0,0.40625} 1.27354,0.40625        6
0.000000 0.000000          128          128.0 {0.78028,0,0.40625} 1.52519,0.40625        6
0.000000 0.000000          256          256.0 {2.05619,0,0.40625} 1.59455,0.40625        6
-0.360577 -0.721154          512          512.0 {11.6502,0,0.40625} 11.6683,0.40625        6
-0.478365 -0.596154         1024         1024.0 {25.0356,-1,0.40625} 25.0743,0.40625        6
-0.603365 -0.728365         2048         2048.0 {23.6205,-1,0.40625} 24.4238,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 0

Starting simulation for: --cats 32 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.690905 -0.778446         4096         4096.0 {24.9853,-1,0.40625} 25.6603,0.40625        6
-0.721655 -0.752404         8192         8192.0 {20.7874,-1,0.40625} 21.242,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 1

Starting simulation for: --cats 32 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>10000.000000
average loss = -0.727385
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3304; id=1, #l=168; id=2, #l=3167; id=3, #l=0; id=4, #l=83; id=5, #l=576; id=6, #l=1632; id=7, #l=0; id=8, #l=0; id=9, #l=115; id=10, #l=124; id=11, #l=1074; id=12, #l=1335; id=13, #l=337; id=14, #l=217; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.71933,0.20625        6
0.000000 0.000000            4            4.0 {0.661603,0,0.20625} 3.91608,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {4.25406,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.630478,0,0.20625} 2.89601,0.20625        6
0.000000 0.000000           64           64.0 {3.67397,0,0.20625} 2.02364,0.20625        6
0.000000 0.000000          128          128.0 {1.05207,0,0.20625} 2.51931,0.20625        6
0.000000 0.000000          256          256.0 {9.38341,0,0.20625} 8.47412,0.20625        6
-0.089421 -0.178842          512          512.0 {21.261,0,0.00625} 22.4398,0.00625        6
-0.424919 -0.760417         1024         1024.0 {13.9186,0,0.20625} 13.9948,0.20625        6
-0.525162 -0.625406         2048         2048.0 {17.9192,-1,0.20625} 19.5015,0.20625        6
-0.625592 -0.726021         4096         4096.0 {18.6681,-1,0.20625} 19.9976,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.686240 -0.746889         8192         8192.0 {29.7934,-1,0.20625} 30.6888,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.692239
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3432; id=1, #l=501; id=2, #l=2456; id=3, #l=0; id=4, #l=205; id=5, #l=933; id=6, #l=875; id=7, #l=0; id=8, #l=0; id=9, #l=279; id=10, #l=230; id=11, #l=867; id=12, #l=1064; id=13, #l=919; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.19857e-05,0.234821        6
0.000000 0.000000            2            2.0 {3.19857e-05,0,0.234821} 0.205952,0.234821        6
0.000000 0.000000            4            4.0 {0.155249,0,0.234821} 3.01375,0.234821        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.3106,0,0.234821} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.12791,0,0.234821} 2.11779,0.234821        6
0.000000 0.000000           64           64.0 {2.80109,0,0.234821} 1.35156,0.234821        6
-0.037313 -0.074627          128          128.0 {17.5545,0,0.139583} 19.7226,0.139583        6
-0.194926 -0.352539          256          256.0 {21.268,0,0.139583} 19.9244,0.139583        6
-0.338870 -0.482813          512          512.0 {12.8923,-1,0.139583} 12.9451,0.139583        6
-0.488689 -0.638508         1024         1024.0 {19.3723,-1,0.139583} 19.4848,0.139583        6
-0.612815 -0.736940         2048         2048.0 {13.3432,-1,0.139583} 15.6813,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 2

Starting simulation for: --cats 32 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.694508 -0.776202         4096         4096.0 {14.4498,-1,0.139583} 16.4144,0.139583        6
-0.731997 -0.769486         8192         8192.0 {28.9783,-1,0.139583} 30.3014,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.729530
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2654; id=1, #l=1678; id=2, #l=2518; id=3, #l=5; id=4, #l=0; id=5, #l=1837; id=6, #l=630; id=7, #l=0; id=8, #l=0; id=9, #l=448; id=10, #l=480; id=11, #l=594; id=12, #l=1024; id=13, #l=629; id=14, #l=494; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000199639,0.0376226        6
0.000000 0.000000            2            2.0 {0.000199639,0,0.0376226} 1.28545,0.0376226        6
0.000000 0.000000            4            4.0 {0.968985,0,0.0376226} 18.8103,0.0376226        6
-0.418606 -0.837211            8            8.0 {22.9832,-1,0.0376226} 25.017,0.0376226        6
-0.313130 -0.207655           16           16.0 {20.6631,0,0.0376226} 22.8563,0.0376226        6
-0.422509 -0.531887           32           32.0 {0.798351,0,0.0376226} 13.2182,0.0376226        6
-0.348067 -0.273625           64           64.0 {17.483,0,0.0376226} 8.4358,0.0376226        6
-0.253704 -0.159341          128          128.0 {3.10954,0,0.0376226} 11.1531,0.0376226        6
-0.323709 -0.393714          256          256.0 {16.8869,0,0.0376226} 11.9021,0.0376226        6
-0.289212 -0.254714          512          512.0 {3.98221,0,0.0333686} 4.20302,0.0333686        6
-0.326082 -0.362953         1024         1024.0 {24.6628,0,0.03125} 25.1656,0.03125        6
-0.350143 -0.374203         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.351391 -0.352640         4096         4096.0 {11.2093,-1,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.345123 -0.338855         8192         8192.0 {20.6363,-1,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.340857
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=2; id=2, #l=0; id=3, #l=169; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=144; id=8, #l=43; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=86; 
    n.a.     n.a.            1            1.0  unknown 4.67607e-06,1.60625        6
0.000000 0.000000            2            2.0 {4.67607e-06,0,1.60625} 0.0301085,1.60625        6
0.000000 0.000000            4            4.0 {0.0226962,0,1.60625} 0.440587,1.60625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.483984,0,1.60625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0186995,0,1.60625} 0.309605,1.60625        6
0.000000 0.000000           64           64.0 {0.409498,0,1.60625} 0.197588,1.60625        6
0.000000 0.000000          128          128.0 {0.0728334,0,1.60625} 0.261234,1.60625        6
0.000000 0.000000          256          256.0 {0.395535,0,1.60625} 0.278778,1.60625        6
0.000000 0.000000          512          512.0 {0.0827275,0,1.60625} 0.0873145,1.60625        6
0.000000 0.000000         1024         1024.0 {0.479821,0,1.60625} 0.489602,1.60625        6
0.000000 0.000000         2048         2048.0 {0.121917,0,1.60625} 0.32509,1.60625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 25

Starting simulation for: --cats 64 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {18.6461,0,1.60625} 18.8168,1.60625        6
0.000000 0.000000         8192         8192.0 {14.8451,-1,1.60625} 14.96,1.60625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 0

Starting simulation for: --cats 64 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2124; id=1, #l=758; id=2, #l=1373; id=3, #l=0; id=4, #l=760; id=5, #l=758; id=6, #l=627; id=7, #l=0; id=8, #l=0; id=9, #l=2; id=10, #l=768; id=11, #l=90; id=12, #l=678; id=13, #l=627; id=14, #l=9; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.365198,0.40625        6
0.000000 0.000000            4            4.0 {0.335891,0,0.40625} 1.98817,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.15975,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.320089,0,0.40625} 1.47028,0.40625        6
0.000000 0.000000           64           64.0 {1.86525,0,0.40625} 1.02739,0.40625        6
0.000000 0.000000          128          128.0 {0.534126,0,0.40625} 1.27903,0.40625        6
0.000000 0.000000          256          256.0 {1.81004,0,0.40625} 1.3484,0.40625        6
-0.317308 -0.634615          512          512.0 {12.8809,0,0.40625} 12.8991,0.40625        6
-0.302885 -0.288462         1024         1024.0 {24.2971,-1,0.40625} 24.3358,0.40625        6
-0.513221 -0.723558         2048         2048.0 {23.3743,-1,0.40625} 24.1777,0.40625        6
-0.604567 -0.695913         4096         4096.0 {20.8007,-1,0.40625} 21.4757,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.649639 -0.694712         8192         8192.0 {14.1413,-1,0.40625} 14.5958,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.721477
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3274; id=1, #l=1415; id=2, #l=1667; id=3, #l=0; id=4, #l=1287; id=5, #l=935; id=6, #l=1017; id=7, #l=0; id=8, #l=0; id=9, #l=164; id=10, #l=574; id=11, #l=416; id=12, #l=783; id=13, #l=560; id=14, #l=109; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.476906,0.20625        6
0.000000 0.000000            4            4.0 {0.419179,0,0.20625} 3.67366,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,-1,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {4.01163,0,0.20625} 9.58583,0.00625        6
0.000000 0.000000           32           32.0 {0.388053,0,0.20625} 2.65359,0.20625        6
0.000000 0.000000           64           64.0 {3.43155,0,0.20625} 1.78122,0.20625        6
0.000000 0.000000          128          128.0 {0.809642,0,0.20625} 2.27689,0.20625        6
-0.066288 -0.132576          256          256.0 {13.0198,-1,0.20625} 12.1105,0.20625        6
-0.265152 -0.464015          512          512.0 {11.0685,0,0.20625} 11.1042,0.20625        6
-0.352904 -0.440657         1024         1024.0 {14.161,-1,0.20625} 14.2372,0.20625        6
-0.564667 -0.776430         2048         2048.0 {17.1919,-1,0.20625} 18.7742,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 1

Starting simulation for: --cats 64 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.579669 -0.594670         4096         4096.0 {17.9408,-1,0.20625} 19.2704,0.20625        6
-0.699293 -0.818917         8192         8192.0 {17.4297,-1,0.20625} 18.3252,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 2

Starting simulation for: --cats 64 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.697342
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3184; id=1, #l=709; id=2, #l=3470; id=3, #l=0; id=4, #l=567; id=5, #l=821; id=6, #l=462; id=7, #l=0; id=8, #l=0; id=9, #l=143; id=10, #l=540; id=11, #l=667; id=12, #l=751; id=13, #l=964; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.97576e-05,0.252404        6
0.000000 0.000000            2            2.0 {2.97576e-05,0,0.252404} 0.191605,0.252404        6
0.000000 0.000000            4            4.0 {0.144434,0,0.252404} 2.80381,0.252404        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.07998,0,0.252404} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.119,0,0.252404} 1.97027,0.252404        6
-0.074627 -0.149254           64           64.0 {21.1899,0,0.139583} 18.7514,0.139583        6
-0.317164 -0.559702          128          128.0 {17.3157,0,0.139583} 19.4838,0.139583        6
-0.270522 -0.223881          256          256.0 {21.0292,-1,0.139583} 19.6856,0.139583        6
-0.486629 -0.702736          512          512.0 {19.34,0,0.139583} 19.3928,0.139583        6
-0.515187 -0.543745         1024         1024.0 {17.7006,0,0.139583} 17.8132,0.139583        6
-0.582702 -0.650217         2048         2048.0 {15.0149,-1,0.139583} 17.3529,0.139583        6
-0.580919 -0.579136         4096         4096.0 {16.5991,-1,0.139583} 18.5637,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.671327 -0.761736         8192         8192.0 {24.441,-1,0.139583} 25.764,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.673096
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2325; id=1, #l=1521; id=2, #l=2351; id=3, #l=5; id=4, #l=0; id=5, #l=2099; id=6, #l=849; id=7, #l=0; id=8, #l=0; id=9, #l=410; id=10, #l=455; id=11, #l=966; id=12, #l=1058; id=13, #l=625; id=14, #l=407; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000198004,0.0379332        6
0.000000 0.000000            2            2.0 {0.000198004,0,0.0379332} 1.27492,0.0379332        6
0.000000 0.000000            4            4.0 {0.961051,0,0.0379332} 18.6563,0.0379332        6
-0.205954 -0.411909            8            8.0 {22.795,0,0.0379332} 24.8121,0.0379332        6
-0.308931 -0.411909           16           16.0 {20.4939,-1,0.0379332} 22.6691,0.0379332        6
-0.308931 -0.308931           32           32.0 {0.791813,0,0.0379332} 13.11,0.0379332        6
-0.349471 -0.390010           64           64.0 {17.3399,-1,0.0379332} 8.36672,0.0379332        6
-0.388187 -0.426903          128          128.0 {3.08407,0,0.0379332} 11.0618,0.0379332        6
-0.387592 -0.386998          256          256.0 {20.3305,-1,0.03125} 14.3292,0.03125        6
-0.369910 -0.352228          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.329061 -0.288212         1024         1024.0 {24.6628,-1,0.03125} 25.1656,0.03125        6
-0.341477 -0.353892         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 3

Starting simulation for: --cats 64 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.319274 -0.297071         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
-0.322216 -0.325159         8192         8192.0 {20.6363,0,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.322478
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=129; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=121; id=8, #l=42; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=89; 
    n.a.     n.a.            1            1.0  unknown 2.34259e-06,3.20625        6
0.000000 0.000000            2            2.0 {2.34259e-06,0,3.20625} 0.0150836,3.20625        6
0.000000 0.000000            4            4.0 {0.0113702,0,3.20625} 0.220723,3.20625        6
0.000000 0.000000            8            8.0 {10.3501,-1,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.242464,0,3.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00936795,0,3.20625} 0.155104,3.20625        6
0.000000 0.000000           64           64.0 {0.205148,0,3.20625} 0.0989867,3.20625        6
0.000000 0.000000          128          128.0 {0.0364877,0,3.20625} 0.130872,3.20625        6
0.000000 0.000000          256          256.0 {0.198153,0,3.20625} 0.139661,3.20625        6
0.000000 0.000000          512          512.0 {0.0414444,0,3.20625} 0.0437424,3.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 25

Starting simulation for: --cats 128 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         1024         1024.0 {0.240378,0,3.20625} 0.245278,3.20625        6
0.000000 0.000000         2048         2048.0 {0.0610771,0,3.20625} 0.162862,3.20625        6
0.000000 0.000000         4096         4096.0 {0.109252,0,3.20625} 0.19478,3.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {28.1466,0,3.20625} 28.2042,3.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=669; id=1, #l=227; id=2, #l=447; id=3, #l=0; id=4, #l=229; id=5, #l=127; id=6, #l=329; id=7, #l=0; id=8, #l=0; id=9, #l=2; id=10, #l=233; id=11, #l=5; id=12, #l=129; id=13, #l=211; id=14, #l=125; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.242121,0.40625        6
0.000000 0.000000            4            4.0 {0.212814,0,0.40625} 1.86509,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.03668,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.197012,0,0.40625} 1.34721,0.40625        6
0.000000 0.000000           64           64.0 {1.74217,0,0.40625} 0.904311,0.40625        6
0.000000 0.000000          128          128.0 {0.411049,0,0.40625} 1.15596,0.40625        6
0.000000 0.000000          256          256.0 {1.68696,0,0.40625} 1.22532,0.40625        6
-0.312500 -0.625000          512          512.0 {0.450169,0,0.40625} 0.468305,0.40625        6
-0.399038 -0.485577         1024         1024.0 {16.7894,0,0.40625} 16.8281,0.40625        6
-0.539663 -0.680288         2048         2048.0 {21.282,-1,0.40625} 22.0854,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 0

Starting simulation for: --cats 128 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.573317 -0.606971         4096         4096.0 {24.6161,-1,0.40625} 25.2911,0.40625        6
-0.756611 -0.939904         8192         8192.0 {19.6797,-1,0.40625} 20.1343,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 1

Starting simulation for: --cats 128 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.736000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3481; id=1, #l=501; id=2, #l=3105; id=3, #l=0; id=4, #l=445; id=5, #l=966; id=6, #l=1613; id=7, #l=0; id=8, #l=0; id=9, #l=95; id=10, #l=318; id=11, #l=1096; id=12, #l=781; id=13, #l=782; id=14, #l=33; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.355694,0.20625        6
0.000000 0.000000            4            4.0 {0.297967,0,0.20625} 3.55245,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.89042,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.266841,0,0.20625} 2.53238,0.20625        6
0.000000 0.000000           64           64.0 {3.31033,0,0.20625} 1.66001,0.20625        6
0.000000 0.000000          128          128.0 {0.68843,0,0.20625} 2.15567,0.20625        6
0.000000 0.000000          256          256.0 {3.20159,0,0.20625} 2.2923,0.20625        6
-0.184659 -0.369318          512          512.0 {12.4018,0,0.20625} 12.4376,0.20625        6
-0.376420 -0.568182         1024         1024.0 {15.4944,0,0.20625} 15.5705,0.20625        6
-0.417850 -0.459280         2048         2048.0 {18.5252,-1,0.20625} 20.1075,0.20625        6
-0.664063 -0.910275         4096         4096.0 {15.8802,-1,0.20625} 17.2098,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.760606 -0.857150         8192         8192.0 {25.7934,-1,0.20625} 26.6888,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.770725
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3238; id=1, #l=545; id=2, #l=2513; id=3, #l=0; id=4, #l=438; id=5, #l=1952; id=6, #l=1342; id=7, #l=0; id=8, #l=0; id=9, #l=125; id=10, #l=255; id=11, #l=994; id=12, #l=1199; id=13, #l=480; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.86404e-05,0.26225        6
0.000000 0.000000            2            2.0 {2.86404e-05,0,0.26225} 0.184411,0.26225        6
0.000000 0.000000            4            4.0 {0.139011,0,0.26225} 2.69854,0.26225        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.96435,0,0.26225} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.114532,0,0.26225} 1.89629,0.26225        6
0.000000 0.000000           64           64.0 {2.50813,0,0.26225} 1.2102,0.26225        6
0.000000 0.000000          128          128.0 {0.446096,0,0.26225} 1.60003,0.26225        6
-0.321358 -0.642717          256          256.0 {26.6412,0,0.139583} 25.2976,0.139583        6
-0.410520 -0.499682          512          512.0 {21.261,-1,0.00625} 22.4398,0.00625        6
-0.457193 -0.503866         1024         1024.0 {29.5215,-1,0.139583} 29.6341,0.139583        6
-0.595275 -0.733356         2048         2048.0 {18,-1,0.139583} 20.338,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 2

Starting simulation for: --cats 128 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.583874 -0.572474         4096         4096.0 {21.9722,0,0.139583} 23.9368,0.139583        6
-0.686335 -0.788795         8192         8192.0 {24.5604,-1,0.139583} 25.8834,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.677191
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 3

Starting simulation for: --cats 128 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Learn() count per node: id=0, #l=2536; id=1, #l=1479; id=2, #l=1841; id=3, #l=4; id=4, #l=0; id=5, #l=2049; id=6, #l=979; id=7, #l=0; id=8, #l=0; id=9, #l=526; id=10, #l=319; id=11, #l=1122; id=12, #l=813; id=13, #l=732; id=14, #l=572; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000197185,0.0380908        6
0.000000 0.000000            2            2.0 {0.000197185,0,0.0380908} 1.26965,0.0380908        6
0.000000 0.000000            4            4.0 {0.957074,0,0.0380908} 18.5791,0.0380908        6
-0.205102 -0.410204            8            8.0 {22.7007,0,0.0380908} 24.7095,0.0380908        6
-0.102551 0.000000           16           16.0 {20.4091,0,0.0380908} 22.5753,0.0380908        6
-0.153827 -0.205102           32           32.0 {0.788537,0,0.0380908} 13.0557,0.0380908        6
-0.336225 -0.518623           64           64.0 {17.2681,-1,0.0380908} 8.3321,0.0380908        6
-0.302566 -0.268906          128          128.0 {3.07131,0,0.0380908} 11.016,0.0380908        6
-0.358158 -0.413750          256          256.0 {18.8425,-1,0.0337178} 13.2804,0.0337178        6
-0.363704 -0.369250          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.342842 -0.321980         1024         1024.0 {24.6628,-1,0.03125} 25.1656,0.03125        6
-0.345697 -0.348553         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.335296 -0.324895         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.327440 -0.319585         8192         8192.0 {20.6363,0,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.327616
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=137; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=149; id=8, #l=24; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=81; 
    n.a.     n.a.            1            1.0  unknown 1.17244e-06,6.40625        6
0.000000 0.000000            2            2.0 {1.17244e-06,0,6.40625} 0.00754917,6.40625        6
0.000000 0.000000            4            4.0 {0.00569065,0,6.40625} 0.110469,6.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.12135,0,6.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00468855,0,6.40625} 0.0776277,6.40625        6
0.000000 0.000000           64           64.0 {0.102674,0,6.40625} 0.0495416,6.40625        6
0.000000 0.000000          128          128.0 {0.0182616,0,6.40625} 0.0654997,6.40625        6
0.000000 0.000000          256          256.0 {0.099173,0,6.40625} 0.0698985,6.40625        6
0.000000 0.000000          512          512.0 {0.0207424,0,6.40625} 0.0218925,6.40625        6
0.000000 0.000000         1024         1024.0 {0.120306,0,6.40625} 0.122759,6.40625        6
0.000000 0.000000         2048         2048.0 {0.0305684,0,6.40625} 0.0815103,6.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 25

Starting simulation for: --cats 256 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {25.4049,0,6.40625} 25.4477,6.40625        6
0.000000 0.000000         8192         8192.0 {25.4509,0,6.40625} 25.4797,6.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 0

Starting simulation for: --cats 256 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1524; id=1, #l=1; id=2, #l=1526; id=3, #l=0; id=4, #l=2; id=5, #l=3; id=6, #l=1525; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=6; id=11, #l=3; id=12, #l=4; id=13, #l=1527; id=14, #l=5; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.180583,0.40625        6
0.000000 0.000000            4            4.0 {0.151276,0,0.40625} 1.80355,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {1.97514,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.135473,0,0.40625} 1.28567,0.40625        6
0.000000 0.000000           64           64.0 {1.68063,0,0.40625} 0.842772,0.40625        6
0.000000 0.000000          128          128.0 {0.349511,0,0.40625} 1.09442,0.40625        6
-0.096154 -0.192308          256          256.0 {21.3177,0,0.40625} 20.8561,0.40625        6
-0.850962 -1.605769          512          512.0 {21.261,0,0.00625} 22.4398,0.00625        6
-0.644231 -0.437500         1024         1024.0 {28.5433,-1,0.40625} 28.582,0.40625        6
-0.868990 -1.093750         2048         2048.0 {12.359,-1,0.40625} 13.1623,0.40625        6
-0.962740 -1.056490         4096         4096.0 {13.6007,-1,0.40625} 14.2757,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.842548 -0.722356         8192         8192.0 {27.8643,0,0.40625} 28.3189,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.801477
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3783; id=1, #l=1574; id=2, #l=2227; id=3, #l=0; id=4, #l=1414; id=5, #l=365; id=6, #l=1687; id=7, #l=0; id=8, #l=0; id=9, #l=208; id=10, #l=817; id=11, #l=227; id=12, #l=443; id=13, #l=1541; id=14, #l=1030; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.295088,0.20625        6
0.000000 0.000000            4            4.0 {0.237361,0,0.20625} 3.49184,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.82982,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.206235,0,0.20625} 2.47177,0.20625        6
-0.037879 -0.075758           64           64.0 {20.7043,0,0.20625} 19.0539,0.20625        6
-0.284091 -0.530303          128          128.0 {18.0824,0,0.20625} 19.5496,0.20625        6
-0.568182 -0.852273          256          256.0 {22.5349,-1,0.20625} 21.6256,0.20625        6
-0.686553 -0.804924          512          512.0 {18.1594,-1,0.20625} 18.1951,0.20625        6
-0.620265 -0.553977         1024         1024.0 {25.1307,-1,0.20625} 25.2069,0.20625        6
-0.687737 -0.755208         2048         2048.0 {13.8586,-1,0.20625} 15.4408,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 1

Starting simulation for: --cats 256 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.661103 -0.634470         4096         4096.0 {14.8499,-1,0.20625} 16.1795,0.20625        6
-0.713809 -0.766514         8192         8192.0 {14.3388,-1,0.20625} 15.2342,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.715867
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3302; id=1, #l=1361; id=2, #l=1936; id=3, #l=0; id=4, #l=1166; id=5, #l=2235; id=6, #l=1362; id=7, #l=0; id=8, #l=0; id=9, #l=231; id=10, #l=559; id=11, #l=1200; id=12, #l=1259; id=13, #l=546; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.80809e-05,0.267474        6
0.000000 0.000000            2            2.0 {2.80809e-05,0,0.267474} 0.180809,0.267474        6
0.000000 0.000000            4            4.0 {0.136296,0,0.267474} 2.64583,0.267474        6
0.000000 0.000000            8            8.0 {10.35,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.90644,0,0.267474} 9.58581,0.00625        6
0.000000 0.000000           32           32.0 {0.112295,0,0.267474} 1.85925,0.267474        6
-0.037313 -0.074627           64           64.0 {21.0108,0,0.139583} 18.5722,0.139583        6
-0.223881 -0.410448          128          128.0 {17.1366,0,0.139583} 19.3047,0.139583        6
-0.497512 -0.771144          256          256.0 {16.074,-1,0.139583} 14.7304,0.139583        6
-0.706147 -0.914781          512          512.0 {21.261,-1,0.00625} 22.4398,0.00625        6
-0.632517 -0.558888         1024         1024.0 {29.4618,-1,0.139583} 29.5744,0.139583        6
-0.661558 -0.690599         2048         2048.0 {11.8507,-1,0.139583} 14.1887,0.139583        6
-0.704780 -0.748003         4096         4096.0 {14.7483,-1,0.139583} 16.7129,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 2

Starting simulation for: --cats 256 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.727058 -0.749336         8192         8192.0 {16.9783,-1,0.139583} 18.3014,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.733885
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2644; id=1, #l=2029; id=2, #l=2674; id=3, #l=0; id=4, #l=0; id=5, #l=1456; id=6, #l=634; id=7, #l=0; id=8, #l=0; id=9, #l=672; id=10, #l=583; id=11, #l=699; id=12, #l=872; id=13, #l=345; id=14, #l=456; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196775,0.0381702        6
0.000000 0.000000            2            2.0 {0.000196775,0,0.0381702} 1.26701,0.0381702        6
0.000000 0.000000            4            4.0 {0.955083,0,0.0381702} 18.5404,0.0381702        6
-0.409351 -0.818701            8            8.0 {22.6535,-1,0.0381702} 24.6581,0.0381702        6
-1.136688 -1.864026           16           16.0 {20.3667,-1,0.0381702} 22.5283,0.0381702        6
-0.670682 -0.204675           32           32.0 {0.786897,0,0.0381702} 13.0286,0.0381702        6
-0.413188 -0.155695           64           64.0 {17.2322,-1,0.0381702} 8.31476,0.0381702        6
-0.422433 -0.431678          128          128.0 {3.74364,0,0.03125} 13.4274,0.03125        6
-0.370135 -0.317836          256          256.0 {20.3305,-1,0.03125} 14.3292,0.03125        6
-0.368853 -0.367572          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.344662 -0.320470         1024         1024.0 {24.6628,-1,0.03125} 25.1656,0.03125        6
-0.328696 -0.312730         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 3

Starting simulation for: --cats 256 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.313712 -0.298729         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
-0.313264 -0.312816         8192         8192.0 {20.6363,-1,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.315352
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 25

Starting simulation for: --cats 512 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=152; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=136; id=8, #l=36; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=86; 
    n.a.     n.a.            1            1.0  unknown 5.86506e-07,12.8063        6
0.000000 0.000000            2            2.0 {5.86506e-07,0,12.8063} 0.00377643,12.8063        6
0.000000 0.000000            4            4.0 {0.00284671,0,12.8063} 0.0552615,12.8063        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0607047,0,12.8063} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00234542,0,12.8063} 0.0388328,12.8063        6
0.000000 0.000000           64           64.0 {0.0513621,0,12.8063} 0.0247829,12.8063        6
0.000000 0.000000          128          128.0 {0.00913528,0,12.8063} 0.0327658,12.8063        6
0.000000 0.000000          256          256.0 {0.0496107,0,12.8063} 0.0349663,12.8063        6
0.000000 0.000000          512          512.0 {0.0103763,0,12.8063} 0.0109516,12.8063        6
0.000000 0.000000         1024         1024.0 {0.0601825,0,12.8063} 0.0614093,12.8063        6
0.000000 0.000000         2048         2048.0 {0.0152916,0,12.8063} 0.040775,12.8063        6
0.000000 0.000000         4096         4096.0 {0.027353,0,12.8063} 0.0487662,12.8063        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {0.0503571,0,12.8063} 4.73021,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=1; id=2, #l=1; id=3, #l=0; id=4, #l=2; id=5, #l=1; id=6, #l=4; id=7, #l=0; id=8, #l=0; id=9, #l=1; id=10, #l=3; id=11, #l=2; id=12, #l=2; id=13, #l=2; id=14, #l=3; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.149814,0.40625        6
0.000000 0.000000            4            4.0 {0.120506,0,0.40625} 1.77278,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {1.94437,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.104704,0,0.40625} 1.2549,0.40625        6
0.000000 0.000000           64           64.0 {1.64986,0,0.40625} 0.812003,0.40625        6
0.000000 0.000000          128          128.0 {0.318741,0,0.40625} 1.06365,0.40625        6
0.000000 0.000000          256          256.0 {1.59465,0,0.40625} 1.13301,0.40625        6
-0.697115 -1.394231          512          512.0 {21.261,0,0.00625} 22.4398,0.00625        6
-0.617788 -0.538462         1024         1024.0 {14.2971,-1,0.40625} 14.3358,0.40625        6
-0.692308 -0.766827         2048         2048.0 {26.1128,-1,0.40625} 26.9161,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 0

Starting simulation for: --cats 512 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.858774 -1.025240         4096         4096.0 {17.3853,-1,0.40625} 18.0603,0.40625        6
-0.913161 -0.967548         8192         8192.0 {18.1105,-1,0.40625} 18.5651,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.882954
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3702; id=1, #l=615; id=2, #l=2972; id=3, #l=0; id=4, #l=586; id=5, #l=1616; id=6, #l=1600; id=7, #l=0; id=8, #l=0; id=9, #l=71; id=10, #l=395; id=11, #l=680; id=12, #l=438; id=13, #l=1025; id=14, #l=88; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.264785,0.20625        6
0.000000 0.000000            4            4.0 {0.207058,0,0.20625} 3.46154,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.79951,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.175932,0,0.20625} 2.44147,0.20625        6
0.000000 0.000000           64           64.0 {3.21943,0,0.20625} 1.5691,0.20625        6
0.000000 0.000000          128          128.0 {0.597521,0,0.20625} 2.06476,0.20625        6
0.000000 0.000000          256          256.0 {3.11068,0,0.20625} 2.20139,0.20625        6
-0.085265 -0.170529          512          512.0 {10.3715,0,0.20625} 10.4073,0.20625        6
-0.236761 -0.388258         1024         1024.0 {28.9792,-1,0.20625} 29.0554,0.20625        6
-0.529863 -0.822965         2048         2048.0 {26.3131,-1,0.20625} 27.8954,0.20625        6
-0.705428 -0.880992         4096         4096.0 {26.1529,-1,0.20625} 27.4825,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 1

Starting simulation for: --cats 512 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.739196 -0.772964         8192         8192.0 {16.2479,-1,0.20625} 17.1433,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.737931
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3108; id=1, #l=1291; id=2, #l=2357; id=3, #l=0; id=4, #l=1003; id=5, #l=1662; id=6, #l=1157; id=7, #l=0; id=8, #l=0; id=9, #l=300; id=10, #l=778; id=11, #l=693; id=12, #l=915; id=13, #l=914; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7801e-05,0.270168        6
0.000000 0.000000            2            2.0 {2.7801e-05,0,0.270168} 0.179007,0.270168        6
0.000000 0.000000            4            4.0 {0.134937,0,0.270168} 2.61946,0.270168        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.87747,0,0.270168} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.111175,0,0.270168} 1.84072,0.270168        6
0.000000 0.000000           64           64.0 {2.43462,0,0.270168} 1.17474,0.270168        6
-0.037313 -0.074627          128          128.0 {17.1068,0,0.139583} 19.2748,0.139583        6
-0.195896 -0.354478          256          256.0 {20.8203,0,0.139583} 19.4767,0.139583        6
-0.506841 -0.817786          512          512.0 {16.9818,-1,0.139583} 17.0346,0.139583        6
-0.591655 -0.676470         1024         1024.0 {23.82,-1,0.139583} 23.9326,0.139583        6
-0.651906 -0.712157         2048         2048.0 {25.3134,-1,0.139583} 27.6514,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 2

Starting simulation for: --cats 512 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.682299 -0.712691         4096         4096.0 {22.1215,-1,0.139583} 24.0861,0.139583        6
-0.733327 -0.784355         8192         8192.0 {24.4708,-1,0.139583} 25.7939,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 3

Starting simulation for: --cats 512 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.744901
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3221; id=1, #l=1074; id=2, #l=2025; id=3, #l=0; id=4, #l=0; id=5, #l=1455; id=6, #l=1034; id=7, #l=0; id=8, #l=0; id=9, #l=292; id=10, #l=376; id=11, #l=703; id=12, #l=1263; id=13, #l=645; id=14, #l=426; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00019657,0.0382101        6
0.000000 0.000000            2            2.0 {0.00019657,0,0.0382101} 1.26568,0.0382101        6
0.000000 0.000000            4            4.0 {0.954087,0,0.0382101} 18.5211,0.0382101        6
-0.408924 -0.817848            8            8.0 {22.6299,-1,0.0382101} 24.6323,0.0382101        6
-0.511155 -0.613386           16           16.0 {20.3454,-1,0.0382101} 22.5049,0.0382101        6
-0.466761 -0.422366           32           32.0 {0.786076,0,0.0382101} 13.015,0.0382101        6
-0.447143 -0.427525           64           64.0 {17.2142,0,0.0382101} 8.30609,0.0382101        6
-0.321086 -0.195029          128          128.0 {3.06173,0,0.0382101} 10.9816,0.0382101        6
-0.248319 -0.175553          256          256.0 {16.6272,-1,0.0382101} 11.7191,0.0382101        6
-0.239466 -0.230613          512          512.0 {3.47764,0,0.0382101} 3.67047,0.0382101        6
-0.270032 -0.300598         1024         1024.0 {22.7977,-1,0.0338065} 23.2625,0.0338065        6
-0.310422 -0.350813         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.316024 -0.321625         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.312210 -0.308396         8192         8192.0 {20.6363,-1,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.310587
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=145; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=134; id=8, #l=35; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=81; 
    n.a.     n.a.            1            1.0  unknown 2.93324e-07,25.6063        6
0.000000 0.000000            2            2.0 {2.93324e-07,0,25.6063} 0.00188867,25.6063        6
0.000000 0.000000            4            4.0 {0.0014237,0,25.6063} 0.0276375,25.6063        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0303598,0,25.6063} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00117299,0,25.6063} 0.0194211,25.6063        6
0.000000 0.000000           64           64.0 {0.0256873,0,25.6063} 0.0123945,25.6063        6
0.000000 0.000000          128          128.0 {0.00456875,0,25.6063} 0.0163869,25.6063        6
0.000000 0.000000          256          256.0 {0.0248114,0,25.6063} 0.0174874,25.6063        6
0.000000 0.000000          512          512.0 {0.0051894,0,25.6063} 0.00547714,25.6063        6
0.000000 0.000000         1024         1024.0 {0.0300986,0,25.6063} 0.0307122,25.6063        6
0.000000 0.000000         2048         2048.0 {0.00764769,0,25.6063} 0.0203925,25.6063        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 25

Starting simulation for: --cats 1024 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {0.0136799,0,25.6063} 0.0243891,25.6063        6
0.000000 0.000000         8192         8192.0 {0.0251847,0,25.6063} 4.73021,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 0

Starting simulation for: --cats 1024 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=0; id=2, #l=1; id=3, #l=0; id=4, #l=0; id=5, #l=1; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=2; id=12, #l=1; id=13, #l=0; id=14, #l=2; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.134429,0.40625        6
0.000000 0.000000            4            4.0 {0.105122,0,0.40625} 1.7574,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {1.92898,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0893194,0,0.40625} 1.23951,0.40625        6
0.000000 0.000000           64           64.0 {1.63448,0,0.40625} 0.796618,0.40625        6
0.000000 0.000000          128          128.0 {0.303357,0,0.40625} 1.04826,0.40625        6
-0.105769 -0.211538          256          256.0 {22.2562,-1,0.40625} 21.7946,0.40625        6
-0.524038 -0.942308          512          512.0 {21.0809,-1,0.40625} 21.0991,0.40625        6
-0.487981 -0.451923         1024         1024.0 {23.0818,-1,0.40625} 23.1204,0.40625        6
-0.486779 -0.485577         2048         2048.0 {11.082,0,0.40625} 11.8854,0.40625        6
-0.638221 -0.789663         4096         4096.0 {25.3699,-1,0.40625} 26.045,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.720853 -0.803486         8192         8192.0 {15.1413,-1,0.40625} 15.5958,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.757415
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3579; id=1, #l=1556; id=2, #l=2089; id=3, #l=0; id=4, #l=1506; id=5, #l=659; id=6, #l=1417; id=7, #l=0; id=8, #l=0; id=9, #l=101; id=10, #l=858; id=11, #l=561; id=12, #l=226; id=13, #l=389; id=14, #l=92; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.249633,0.20625        6
0.000000 0.000000            4            4.0 {0.191906,0,0.20625} 3.44639,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.78436,0,0.20625} 9.58583,0.00625        6
0.000000 0.000000           32           32.0 {0.160781,0,0.20625} 2.42632,0.20625        6
-0.075758 -0.151515           64           64.0 {20.6588,-1,0.20625} 19.0085,0.20625        6
-0.284091 -0.492424          128          128.0 {18.0369,-1,0.20625} 19.5042,0.20625        6
-0.625000 -0.965909          256          256.0 {20.5501,0,0.20625} 19.6408,0.20625        6
-0.833333 -1.041667          512          512.0 {10.3564,0,0.20625} 10.3921,0.20625        6
-0.719697 -0.606061         1024         1024.0 {16.2368,-1,0.20625} 16.313,0.20625        6
-0.699574 -0.679451         2048         2048.0 {15.5101,-1,0.20625} 17.0924,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 1

Starting simulation for: --cats 1024 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.674320 -0.649066         4096         4096.0 {26.9256,-1,0.20625} 28.2552,0.20625        6
-0.794268 -0.914215         8192         8192.0 {28.4752,-1,0.20625} 29.3706,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 2

Starting simulation for: --cats 1024 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.802482
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2790; id=1, #l=1669; id=2, #l=3338; id=3, #l=0; id=4, #l=1523; id=5, #l=1781; id=6, #l=1024; id=7, #l=0; id=8, #l=0; id=9, #l=275; id=10, #l=794; id=11, #l=895; id=12, #l=588; id=13, #l=715; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7661e-05,0.271535        6
0.000000 0.000000            2            2.0 {2.7661e-05,0,0.271535} 0.178105,0.271535        6
0.000000 0.000000            4            4.0 {0.134258,0,0.271535} 2.60627,0.271535        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.86298,0,0.271535} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.110616,0,0.271535} 1.83145,0.271535        6
0.000000 0.000000           64           64.0 {2.42236,0,0.271535} 1.16882,0.271535        6
-0.018657 -0.037313          128          128.0 {18.7182,0,0.00625} 23.0808,0.139583        6
-0.357587 -0.696517          256          256.0 {24.6262,0,0.139583} 23.2827,0.139583        6
-0.346704 -0.335821          512          512.0 {16.9669,-1,0.139583} 17.0197,0.139583        6
-0.413557 -0.480410         1024         1024.0 {18.7305,-1,0.139583} 18.843,0.139583        6
-0.542600 -0.671642         2048         2048.0 {20.5224,0,0.139583} 22.8604,0.139583        6
-0.524137 -0.505675         4096         4096.0 {18.9125,-1,0.139583} 20.8771,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.562988 -0.601839         8192         8192.0 {21.0231,-1,0.139583} 22.3461,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.583278
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2626; id=1, #l=743; id=2, #l=2344; id=3, #l=0; id=4, #l=0; id=5, #l=1325; id=6, #l=1220; id=7, #l=0; id=8, #l=0; id=9, #l=123; id=10, #l=355; id=11, #l=873; id=12, #l=967; id=13, #l=792; id=14, #l=136; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196467,0.03823        6
0.000000 0.000000            2            2.0 {0.000196467,0,0.03823} 1.26502,0.03823        6
0.000000 0.000000            4            4.0 {0.953589,0,0.03823} 18.5114,0.03823        6
-0.408710 -0.817421            8            8.0 {22.618,-1,0.03823} 24.6195,0.03823        6
-0.306533 -0.204355           16           16.0 {20.3348,0,0.03823} 22.4931,0.03823        6
-0.262130 -0.217727           32           32.0 {0.785665,0,0.03823} 13.0082,0.03823        6
-0.207698 -0.153266           64           64.0 {17.2052,-1,0.03823} 8.30175,0.03823        6
-0.154938 -0.102178          128          128.0 {3.06013,0,0.03823} 10.9759,0.03823        6
-0.189468 -0.223998          256          256.0 {16.6185,0,0.03823} 11.713,0.03823        6
-0.216847 -0.244227          512          512.0 {3.47583,0,0.03823} 3.66856,0.03823        6
-0.286049 -0.355250         1024         1024.0 {24.6628,0,0.03125} 25.1656,0.03125        6
-0.318380 -0.350711         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 3

Starting simulation for: --cats 1024 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.332358 -0.346337         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
-0.330153 -0.327948         8192         8192.0 {20.6363,-1,0.03125} 26.546,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 25

Starting simulation for: --cats 2048 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.329295
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=165; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=140; id=8, #l=40; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=73; 
    n.a.     n.a.            1            1.0  unknown 1.4668e-07,51.2062        6
0.000000 0.000000            2            2.0 {1.4668e-07,0,51.2062} 0.000944452,51.2062        6
0.000000 0.000000            4            4.0 {0.000711939,0,51.2062} 0.0138204,51.2062        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0151817,0,51.2062} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.000586569,0,51.2062} 0.00971176,51.2062        6
0.000000 0.000000           64           64.0 {0.0128452,0,51.2062} 0.006198,51.2062        6
0.000000 0.000000          128          128.0 {0.00228466,0,51.2062} 0.00819446,51.2062        6
0.000000 0.000000          256          256.0 {0.0124072,0,51.2062} 0.00874478,51.2062        6
0.000000 0.000000          512          512.0 {0.00259502,0,51.2062} 0.0027389,51.2062        6
0.000000 0.000000         1024         1024.0 {0.0150511,0,51.2062} 0.015358,51.2062        6
0.000000 0.000000         2048         2048.0 {0.00382431,0,51.2062} 0.0101975,51.2062        6
0.000000 0.000000         4096         4096.0 {0.00684076,0,51.2062} 0.012196,51.2062        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {0.0125939,0,51.2062} 4.73022,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=1; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=1; id=12, #l=1; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.126737,0.40625        6
0.000000 0.000000            4            4.0 {0.0974294,0,0.40625} 1.7497,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {1.92129,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0816271,0,0.40625} 1.23182,0.40625        6
0.000000 0.000000           64           64.0 {1.62679,0,0.40625} 0.788926,0.40625        6
0.000000 0.000000          128          128.0 {0.295664,0,0.40625} 1.04057,0.40625        6
0.000000 0.000000          256          256.0 {1.57158,0,0.40625} 1.10994,0.40625        6
-0.312500 -0.625000          512          512.0 {0.334784,0,0.40625} 0.352921,0.40625        6
-0.278846 -0.245192         1024         1024.0 {24.551,-1,0.40625} 24.5897,0.40625        6
-0.417067 -0.555288         2048         2048.0 {24.1205,-1,0.40625} 24.9238,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 0

Starting simulation for: --cats 2048 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.535457 -0.653846         4096         4096.0 {14.1623,-1,0.40625} 14.8373,0.40625        6
-0.696214 -0.856971         8192         8192.0 {18.0874,-1,0.40625} 18.542,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.682585
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3526; id=1, #l=1317; id=2, #l=2254; id=3, #l=0; id=4, #l=1287; id=5, #l=714; id=6, #l=1736; id=7, #l=0; id=8, #l=0; id=9, #l=64; id=10, #l=631; id=11, #l=430; id=12, #l=590; id=13, #l=1013; id=14, #l=30; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.242057,0.20625        6
0.000000 0.000000            4            4.0 {0.184331,0,0.20625} 3.43881,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.77679,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {4.80576,0,0.00625} 19.8733,0.20625        6
-0.227273 -0.454545           64           64.0 {20.6512,-1,0.20625} 19.0009,0.20625        6
-0.340909 -0.454545          128          128.0 {18.0293,0,0.20625} 19.4966,0.20625        6
-0.369318 -0.397727          256          256.0 {28.3001,-1,0.20625} 27.3908,0.20625        6
-0.468759 -0.568200          512          512.0 {18.1064,-1,0.20625} 18.1421,0.20625        6
-0.660516 -0.852273         1024         1024.0 {28.9565,-1,0.20625} 29.0327,0.20625        6
-0.727902 -0.795289         2048         2048.0 {12.6237,0,0.20625} 14.206,0.20625        6
-0.764282 -0.800662         4096         4096.0 {13.5847,-1,0.20625} 14.9143,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 1

Starting simulation for: --cats 2048 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.744629 -0.724976         8192         8192.0 {23.9525,-1,0.20625} 24.8479,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.738680
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3533; id=1, #l=995; id=2, #l=2766; id=3, #l=0; id=4, #l=612; id=5, #l=1241; id=6, #l=1245; id=7, #l=0; id=8, #l=0; id=9, #l=409; id=10, #l=270; id=11, #l=750; id=12, #l=959; id=13, #l=882; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7591e-05,0.272224        6
0.000000 0.000000            2            2.0 {2.7591e-05,0,0.272224} 0.177655,0.272224        6
0.000000 0.000000            4            4.0 {0.133918,0,0.272224} 2.59967,0.272224        6
0.000000 0.000000            8            8.0 {10.35,-1,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.85573,0,0.272224} 9.58581,0.00625        6
0.000000 0.000000           32           32.0 {0.110336,0,0.272224} 1.82681,0.272224        6
0.000000 0.000000           64           64.0 {2.41623,0,0.272224} 1.16586,0.272224        6
0.000000 0.000000          128          128.0 {0.429751,0,0.272224} 1.54141,0.272224        6
-0.348259 -0.696517          256          256.0 {13.1561,0,0.139583} 11.8125,0.139583        6
-0.483687 -0.619115          512          512.0 {21.261,0,0.00625} 22.4398,0.00625        6
-0.478095 -0.472503         1024         1024.0 {17.9469,-1,0.139583} 18.0595,0.139583        6
-0.684025 -0.889955         2048         2048.0 {13.8283,-1,0.139583} 16.1663,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 2

Starting simulation for: --cats 2048 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.676018 -0.668012         4096         4096.0 {26.3677,-1,0.139583} 28.3323,0.139583        6
-0.699504 -0.722990         8192         8192.0 {23.0455,-1,0.139583} 24.3685,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 3

Starting simulation for: --cats 2048 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.722283
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2871; id=1, #l=1101; id=2, #l=2422; id=3, #l=2; id=4, #l=0; id=5, #l=1372; id=6, #l=965; id=7, #l=0; id=8, #l=0; id=9, #l=289; id=10, #l=477; id=11, #l=608; id=12, #l=1022; id=13, #l=909; id=14, #l=225; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196416,0.03824        6
0.000000 0.000000            2            2.0 {0.000196416,0,0.03824} 1.26469,0.03824        6
0.000000 0.000000            4            4.0 {0.953339,0,0.03824} 18.5066,0.03824        6
-0.204302 -0.408604            8            8.0 {22.6121,-1,0.03824} 24.613,0.03824        6
-0.931453 -1.658604           16           16.0 {20.3295,-1,0.03824} 22.4872,0.03824        6
-0.618953 -0.306453           32           32.0 {0.78546,0,0.03824} 13.0048,0.03824        6
-0.609444 -0.599936           64           64.0 {19.4437,-1,0.0338288} 9.38184,0.0338288        6
-0.486741 -0.364037          128          128.0 {3.45826,0,0.0338288} 12.4039,0.0338288        6
-0.366643 -0.246546          256          256.0 {18.7807,0,0.0338288} 13.2369,0.0338288        6
-0.398588 -0.430533          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.372356 -0.346123         1024         1024.0 {24.6628,-1,0.03125} 25.1656,0.03125        6
-0.378046 -0.383736         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.348571 -0.319096         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.336429 -0.324287         8192         8192.0 {20.6363,0,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.337621
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 25

Plotting...
</pre></div>
</div>
<img alt="../_images/python_cats_21_99.png" src="../_images/python_cats_21_99.png" />
</div>
</div>
</div>
<div class="section" id="id2">
<h3>Without Learning<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># do parameter sweeping</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">]</span>
<span class="n">bandwidths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span>

<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="k">for</span> <span class="n">actions</span> <span class="ow">in</span> <span class="n">num_actions</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="n">bandwidths</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">bd</span> <span class="o">&gt;=</span> <span class="n">actions</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting simulation for: --cats </span><span class="si">{}</span><span class="s2"> --bandwidth </span><span class="si">{}</span><span class="s2"> --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
        <span class="n">rr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done with simulation for num_actions: </span><span class="si">{}</span><span class="s2"> and bandwidth: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)][</span><span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">rr</span><span class="p">,</span> <span class="n">hits</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Plotting...&quot;</span><span class="p">)</span>
<span class="n">plot_reward_sweep</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">bandwidths</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting simulation for: --cats 8 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 8 and bandwidth: 0

Starting simulation for: --cats 8 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=158; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=145; id=8, #l=44; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=79; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
    n.a.     n.a.            2            2.0  unknown 0.234482,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.43124,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.41116,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.53879,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.03446,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.17109,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.679995,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.81296,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.53176,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.02794,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 1.10366,0.40625        6
    n.a.     n.a.            4            4.0  unknown 2.72663,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.20875,0.40625        6
    n.a.     n.a.           64           64.0  unknown 1.76585,0.40625        6
    n.a.     n.a.          128          128.0  unknown 2.0175,0.40625        6
    n.a.     n.a.          256          256.0  unknown 2.08686,0.40625        6
    n.a.     n.a.          512          512.0  unknown 1.32984,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.92043,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         2048         2048.0  unknown 2.26997,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 2.52188,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
    n.a.     n.a.            2            2.0  unknown 0.234482,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.43124,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.41116,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.53879,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.03446,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.17109,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.679995,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.81296,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.53176,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 1

Starting simulation for: --cats 8 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 8 and bandwidth: 2

Starting simulation for: --cats 8 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 3.02794,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 3.21214,0.139583        6
    n.a.     n.a.            4            4.0  unknown 7.93571,0.139583        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 6.42844,0.139583        6
    n.a.     n.a.           64           64.0  unknown 5.13941,0.139583        6
    n.a.     n.a.          128          128.0  unknown 5.87181,0.139583        6
    n.a.     n.a.          256          256.0  unknown 6.0737,0.139583        6
    n.a.     n.a.          512          512.0  unknown 3.87044,0.139583        6
    n.a.     n.a.         1024         1024.0  unknown 8.49975,0.139583        6
    n.a.     n.a.         2048         2048.0  unknown 6.60663,0.139583        6
    n.a.     n.a.         4096         4096.0  unknown 7.33979,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 9.31589e-06,0.80625        6
    n.a.     n.a.            2            2.0  unknown 0.0599837,0.80625        6
    n.a.     n.a.            4            4.0  unknown 0.877758,0.80625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.616809,0.80625        6
    n.a.     n.a.           64           64.0  unknown 0.393645,0.80625        6
    n.a.     n.a.          128          128.0  unknown 0.520443,0.80625        6
    n.a.     n.a.          256          256.0  unknown 0.555395,0.80625        6
    n.a.     n.a.          512          512.0  unknown 0.173952,0.80625        6
    n.a.     n.a.         1024         1024.0  unknown 0.975409,0.80625        6
    n.a.     n.a.         2048         2048.0  unknown 0.647659,0.80625        6
    n.a.     n.a.         4096         4096.0  unknown 0.774589,0.80625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 32 and bandwidth: 0

Starting simulation for: --cats 32 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.611352,0.40625        6
    n.a.     n.a.            4            4.0  unknown 2.23432,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.71644,0.40625        6
    n.a.     n.a.           64           64.0  unknown 1.27354,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.52519,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.59455,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.837536,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.42812,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.77766,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 2.02957,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 1

Starting simulation for: --cats 32 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 32 and bandwidth: 2

Starting simulation for: --cats 32 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.71933,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.91608,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.89601,0.20625        6
    n.a.     n.a.           64           64.0  unknown 2.02364,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.51931,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.65594,0.20625        6
    n.a.     n.a.          512          512.0  unknown 1.16484,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 4.29781,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 3.01661,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.51279,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.19857e-05,0.234821        6
    n.a.     n.a.            2            2.0  unknown 0.205952,0.234821        6
    n.a.     n.a.            4            4.0  unknown 3.01375,0.234821        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.11779,0.234821        6
    n.a.     n.a.           64           64.0  unknown 1.35156,0.234821        6
    n.a.     n.a.          128          128.0  unknown 1.78692,0.234821        6
    n.a.     n.a.          256          256.0  unknown 1.90693,0.234821        6
    n.a.     n.a.          512          512.0  unknown 0.597258,0.234821        6
    n.a.     n.a.         1024         1024.0  unknown 3.34903,0.234821        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         2048         2048.0  unknown 2.22371,0.234821        6
    n.a.     n.a.         4096         4096.0  unknown 2.65952,0.234821        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000199639,0.0376226        6
    n.a.     n.a.            2            2.0  unknown 1.28545,0.0376226        6
    n.a.     n.a.            4            4.0  unknown 18.8103,0.0376226        6
    n.a.     n.a.            8            8.0  unknown 25.017,0.0376226        6
    n.a.     n.a.           16           16.0  unknown 22.8563,0.0376226        6
    n.a.     n.a.           32           32.0  unknown 13.2182,0.0376226        6
    n.a.     n.a.           64           64.0  unknown 8.4358,0.0376226        6
    n.a.     n.a.          128          128.0  unknown 11.1531,0.0376226        6
    n.a.     n.a.          256          256.0  unknown 11.9021,0.0376226        6
    n.a.     n.a.          512          512.0  unknown 3.72779,0.0376226        6
    n.a.     n.a.         1024         1024.0  unknown 20.903,0.0376226        6
    n.a.     n.a.         2048 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 32 and bandwidth: 25

Starting simulation for: --cats 64 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>        2048.0  unknown 13.8793,0.0376226        6
    n.a.     n.a.         4096         4096.0  unknown 16.5994,0.0376226        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 4.67607e-06,1.60625        6
    n.a.     n.a.            2            2.0  unknown 0.0301085,1.60625        6
    n.a.     n.a.            4            4.0  unknown 0.440587,1.60625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.309605,1.60625        6
    n.a.     n.a.           64           64.0  unknown 0.197588,1.60625        6
    n.a.     n.a.          128          128.0  unknown 0.261234,1.60625        6
    n.a.     n.a.          256          256.0  unknown 0.278778,1.60625        6
    n.a.     n.a.          512          512.0  unknown 0.0873145,1.60625        6
    n.a.     n.a.         1024         1024.0  unknown 0.489602,1.60625        6
    n.a.     n.a.         2048         2048.0  unknown 0.32509,1.60625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 0.388802,1.60625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.365198,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.98817,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.47028,0.40625        6
    n.a.     n.a.           64           64.0  unknown 1.02739,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.27903,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.3484,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.591382,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.18197,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.53151,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 1.78342,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 0

Starting simulation for: --cats 64 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 64 and bandwidth: 1

Starting simulation for: --cats 64 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.476906,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.67366,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58583,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.65359,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.78122,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.27689,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.41351,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.922419,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 4.05539,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.77418,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.27036,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 2

Starting simulation for: --cats 64 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 64 and bandwidth: 3

Starting simulation for: --cats 64 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.97576e-05,0.252404        6
    n.a.     n.a.            2            2.0  unknown 0.191605,0.252404        6
    n.a.     n.a.            4            4.0  unknown 2.80381,0.252404        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.97027,0.252404        6
    n.a.     n.a.           64           64.0  unknown 1.25741,0.252404        6
    n.a.     n.a.          128          128.0  unknown 1.66244,0.252404        6
    n.a.     n.a.          256          256.0  unknown 1.77409,0.252404        6
    n.a.     n.a.          512          512.0  unknown 0.555653,0.252404        6
    n.a.     n.a.         1024         1024.0  unknown 3.11573,0.252404        6
    n.a.     n.a.         2048         2048.0  unknown 2.06881,0.252404        6
    n.a.     n.a.         4096         4096.0  unknown 2.47426,0.252404        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000198004,0.0379332        6
    n.a.     n.a.            2            2.0  unknown 1.27492,0.0379332        6
    n.a.     n.a.            4            4.0  unknown 18.6563,0.0379332        6
    n.a.     n.a.            8            8.0  unknown 24.8121,0.0379332        6
    n.a.     n.a.           16           16.0  unknown 22.6691,0.0379332        6
    n.a.     n.a.           32           32.0  unknown 13.11,0.0379332        6
    n.a.     n.a.           64           64.0  unknown 8.36672,0.0379332        6
    n.a.     n.a.          128          128.0  unknown 11.0618,0.0379332        6
    n.a. 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.          256          256.0  unknown 11.8046,0.0379332        6
    n.a.     n.a.          512          512.0  unknown 3.69726,0.0379332        6
    n.a.     n.a.         1024         1024.0  unknown 20.7318,0.0379332        6
    n.a.     n.a.         2048         2048.0  unknown 13.7657,0.0379332        6
    n.a.     n.a.         4096         4096.0  unknown 16.4635,0.0379332        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.34259e-06,3.20625        6
    n.a.     n.a.            2            2.0  unknown 0.0150836,3.20625        6
    n.a.     n.a.            4            4.0  unknown 0.220723,3.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.155104,3.20625        6
    n.a.     n.a.           64           64.0  unknown 0.0989867,3.20625        6
    n.a.     n.a.          128          128.0  unknown 0.130872,3.20625        6
    n.a.     n.a.          256          256.0  unknown 0.139661,3.20625        6
    n.a.     n.a.          512          512.0  unknown 0.0437424,3.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 25

Starting simulation for: --cats 128 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 128 and bandwidth: 0

Starting simulation for: --cats 128 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         1024         1024.0  unknown 0.245278,3.20625        6
    n.a.     n.a.         2048         2048.0  unknown 0.162862,3.20625        6
    n.a.     n.a.         4096         4096.0  unknown 0.19478,3.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.242121,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.86509,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.34721,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.904311,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.15596,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.22532,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.468305,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.05889,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         2048         2048.0  unknown 1.40843,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 1.66034,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.355694,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.55245,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.53238,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.66001,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.15567,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.2923,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.801207,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.93417,0.20625        6
    n.a.     n.a. 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 1

Starting simulation for: --cats 128 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 128 and bandwidth: 2

Starting simulation for: --cats 128 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>        2048         2048.0  unknown 2.65297,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.14915,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.86404e-05,0.26225        6
    n.a.     n.a.            2            2.0  unknown 0.184411,0.26225        6
    n.a.     n.a.            4            4.0  unknown 2.69854,0.26225        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.89629,0.26225        6
    n.a.     n.a.           64           64.0  unknown 1.2102,0.26225        6
    n.a.     n.a.          128          128.0  unknown 1.60003,0.26225        6
    n.a.     n.a.          256          256.0  unknown 1.70748,0.26225        6
    n.a.     n.a.          512          512.0  unknown 0.534791,0.26225        6
    n.a.     n.a.         1024         1024.0  unknown 2.99875,0.26225        6
    n.a.     n.a.         2048         2048.0  unknown 1.99114,0.26225        6
    n.a.     n.a.         4096         4096.0  unknown 2.38136,0.26225        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000197185,0.0380908        6
    n.a.     n.a.            2            2.0  unknown 1.26965,0.0380908        6
    n.a.     n.a.            4            4.0  unknown 18.5791,0.0380908        6
    n.a.     n.a.            8            8.0  unknown 24.7095,0.0380908        6
    n.a.     n.a.           16           16.0  unknown 22.5753,0.0380908        6
    n.a.     n.a.           32           32.0  unknown 13.0557,0.0380908        6
    n.a.     n.a.           64           64.0  unknown 8.3321,0.0380908        6
    n.a.     n.a.          128          128.0  unknown 11.016,0.0380908        6
    n.a.     n.a.          256          256.0  unknown 11.7558,0.0380908        6
    n.a.     n.a.          512          512.0  unknown 3.68196,0.0380908        6
    n.a.     n.a.         1024         1024.0  unknown 20.646,0.0380908        6
    n.a.     n.a.         2048         2048.0  unknown 13.7087,0.0380908        6
    n.a.     n.a.         4096         4096.0  unknown 16.3954,0.0380908        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 3

Starting simulation for: --cats 128 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 128 and bandwidth: 25

Starting simulation for: --cats 256 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 1.17244e-06,6.40625        6
    n.a.     n.a.            2            2.0  unknown 0.00754917,6.40625        6
    n.a.     n.a.            4            4.0  unknown 0.110469,6.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.0776277,6.40625        6
    n.a.     n.a.           64           64.0  unknown 0.0495416,6.40625        6
    n.a.     n.a.          128          128.0  unknown 0.0654997,6.40625        6
    n.a.     n.a.          256          256.0  unknown 0.0698985,6.40625        6
    n.a.     n.a.          512          512.0  unknown 0.0218925,6.40625        6
    n.a.     n.a.         1024         1024.0  unknown 0.122759,6.40625        6
    n.a.     n.a.         2048         2048.0  unknown 0.0815103,6.40625        6
    n.a.     n.a.         4096         4096.0  unknown 0.0974849,6.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.180583,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.80355,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.28567,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.842772,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.09442,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.16378,0.40625        6
    n.a.   
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 0

Starting simulation for: --cats 256 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 256 and bandwidth: 1

Starting simulation for: --cats 256 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  n.a.          512          512.0  unknown 0.406767,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 1.99735,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.34689,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 1.5988,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.295088,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.49184,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.47177,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.5994,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.09507,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.2317,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.740601,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.87357,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         2048         2048.0  unknown 2.59236,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.08855,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.80809e-05,0.267474        6
    n.a.     n.a.            2            2.0  unknown 0.180809,0.267474        6
    n.a.     n.a.            4            4.0  unknown 2.64583,0.267474        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58581,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.85925,0.267474        6
    n.a.     n.a.           64           64.0  unknown 1.18657,0.267474        6
    n.a.     n.a.          128          128.0  unknown 1.56878,0.267474        6
    n.a.     n.a.          256          256.0  unknown 1.67413,0.267474        6
    n.a.     n.a.          512          512.0  unknown 0.524345,0.267474        6
    n.a.     n.a.         1024         1024.0  unknown 2.94018,0.267474        6
    n.a.     n.a.         2048         2048.0  unknown 1.95224,0.267474        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 2

Starting simulation for: --cats 256 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 256 and bandwidth: 3

Starting simulation for: --cats 256 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 2.33485,0.267474        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196775,0.0381702        6
    n.a.     n.a.            2            2.0  unknown 1.26701,0.0381702        6
    n.a.     n.a.            4            4.0  unknown 18.5404,0.0381702        6
    n.a.     n.a.            8            8.0  unknown 24.6581,0.0381702        6
    n.a.     n.a.           16           16.0  unknown 22.5283,0.0381702        6
    n.a.     n.a.           32           32.0  unknown 13.0286,0.0381702        6
    n.a.     n.a.           64           64.0  unknown 8.31476,0.0381702        6
    n.a.     n.a.          128          128.0  unknown 10.9931,0.0381702        6
    n.a.     n.a.          256          256.0  unknown 11.7313,0.0381702        6
    n.a.     n.a.          512          512.0  unknown 3.67431,0.0381702        6
    n.a.     n.a.         1024         1024.0  unknown 20.6031,0.0381702        6
    n.a.     n.a.         2048         2048.0  unknown 13.6802,0.0381702        6
    n.a.     n.a.         4096         4096.0  unknown 16.3613,0.0381702        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 25

Starting simulation for: --cats 512 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 512 and bandwidth: 0

Starting simulation for: --cats 512 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 5.86506e-07,12.8063        6
    n.a.     n.a.            2            2.0  unknown 0.00377643,12.8063        6
    n.a.     n.a.            4            4.0  unknown 0.0552615,12.8063        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.0388328,12.8063        6
    n.a.     n.a.           64           64.0  unknown 0.0247829,12.8063        6
    n.a.     n.a.          128          128.0  unknown 0.0327658,12.8063        6
    n.a.     n.a.          256          256.0  unknown 0.0349663,12.8063        6
    n.a.     n.a.          512          512.0  unknown 0.0109516,12.8063        6
    n.a.     n.a.         1024         1024.0  unknown 0.0614093,12.8063        6
    n.a.     n.a.         2048         2048.0  unknown 0.040775,12.8063        6
    n.a.     n.a.         4096         4096.0  unknown 0.0487662,12.8063        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.149814,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.77278,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.2549,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.812003,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.          128          128.0  unknown 1.06365,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.13301,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.375997,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 1.96658,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.31612,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 1.56803,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.264785,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.46154,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.44147,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.5691,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.06476,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.20139,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.710298,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.84327,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 1

Starting simulation for: --cats 512 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 512 and bandwidth: 2

Starting simulation for: --cats 512 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         2048         2048.0  unknown 2.56206,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.05824,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7801e-05,0.270168        6
    n.a.     n.a.            2            2.0  unknown 0.179007,0.270168        6
    n.a.     n.a.            4            4.0  unknown 2.61946,0.270168        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.84072,0.270168        6
    n.a.     n.a.           64           64.0  unknown 1.17474,0.270168        6
    n.a.     n.a.          128          128.0  unknown 1.55314,0.270168        6
    n.a.     n.a.          256          256.0  unknown 1.65744,0.270168        6
    n.a.     n.a.          512          512.0  unknown 0.519119,0.270168        6
    n.a.     n.a.         1024         1024.0  unknown 2.91087,0.270168        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         2048         2048.0  unknown 1.93278,0.270168        6
    n.a.     n.a.         4096         4096.0  unknown 2.31157,0.270168        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00019657,0.0382101        6
    n.a.     n.a.            2            2.0  unknown 1.26568,0.0382101        6
    n.a.     n.a.            4            4.0  unknown 18.5211,0.0382101        6
    n.a.     n.a.            8            8.0  unknown 24.6323,0.0382101        6
    n.a.     n.a.           16           16.0  unknown 22.5049,0.0382101        6
    n.a.     n.a.           32           32.0  unknown 13.015,0.0382101        6
    n.a.     n.a.           64           64.0  unknown 8.30609,0.0382101        6
    n.a.     n.a.          128          128.0  unknown 10.9816,0.0382101        6
    n.a.     n.a.          256          256.0  unknown 11.7191,0.0382101        6
    n.a.     n.a.          512          512.0  unknown 3.67047,0.0382101        6
    n.a.     n.a.         1024         1024.0  unknown 20.5816,0.0382101        6
    n.a.     n.a.         2048         2048.0  unknown 13.6659,0.0382101        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 3

Starting simulation for: --cats 512 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 512 and bandwidth: 25

Starting simulation for: --cats 1024 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 16.3442,0.0382101        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.93324e-07,25.6063        6
    n.a.     n.a.            2            2.0  unknown 0.00188867,25.6063        6
    n.a.     n.a.            4            4.0  unknown 0.0276375,25.6063        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.0194211,25.6063        6
    n.a.     n.a.           64           64.0  unknown 0.0123945,25.6063        6
    n.a.     n.a.          128          128.0  unknown 0.0163869,25.6063        6
    n.a.     n.a.          256          256.0  unknown 0.0174874,25.6063        6
    n.a.     n.a.          512          512.0  unknown 0.00547714,25.6063        6
    n.a.     n.a.         1024         1024.0  unknown 0.0307122,25.6063        6
    n.a.     n.a.         2048         2048.0  unknown 0.0203925,25.6063        6
    n.a.     n.a.         4096         4096.0  unknown 0.0243891,25.6063        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.134429,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.7574,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.23951,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.796618,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.04826,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.11763,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.360613,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 1.9512,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.30074,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 1.55265,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 0

Starting simulation for: --cats 1024 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 1024 and bandwidth: 1

Starting simulation for: --cats 1024 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.249633,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.44639,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58583,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.42632,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.55395,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.04961,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.18624,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.695147,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.82811,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.54691,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.04309,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 2

Starting simulation for: --cats 1024 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 1024 and bandwidth: 3

Starting simulation for: --cats 1024 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7661e-05,0.271535        6
    n.a.     n.a.            2            2.0  unknown 0.178105,0.271535        6
    n.a.     n.a.            4            4.0  unknown 2.60627,0.271535        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.83145,0.271535        6
    n.a.     n.a.           64           64.0  unknown 1.16882,0.271535        6
    n.a.     n.a.          128          128.0  unknown 1.54532,0.271535        6
    n.a.     n.a.          256          256.0  unknown 1.6491,0.271535        6
    n.a.     n.a.          512          512.0  unknown 0.516504,0.271535        6
    n.a.     n.a.         1024         1024.0  unknown 2.89621,0.271535        6
    n.a.     n.a.         2048         2048.0  unknown 1.92305,0.271535        6
    n.a.     n.a.         4096         4096.0  unknown 2.29993,0.271535        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196467,0.03823        6
    n.a.     n.a.            2            2.0  unknown 1.26502,0.03823        6
    n.a.     n.a.            4            4.0  unknown 18.5114,0.03823        6
    n.a.     n.a.            8            8.0  unknown 24.6195,0.03823        6
    n.a.     n.a.           16           16.0  unknown 22.4931,0.03823        6
    n.a.     n.a.           32           32.0  unknown 13.0082,0.03823        6
    n.a.     n.a.           64           64.0  unknown 8.30175,0.03823        6
    n.a.     n.a.          128          128.0  unknown 10.9759,0.03823        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.          256          256.0  unknown 11.713,0.03823        6
    n.a.     n.a.          512          512.0  unknown 3.66856,0.03823        6
    n.a.     n.a.         1024         1024.0  unknown 20.5708,0.03823        6
    n.a.     n.a.         2048         2048.0  unknown 13.6588,0.03823        6
    n.a.     n.a.         4096         4096.0  unknown 16.3357,0.03823        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 1.4668e-07,51.2062        6
    n.a.     n.a.            2            2.0  unknown 0.000944452,51.2062        6
    n.a.     n.a.            4            4.0  unknown 0.0138204,51.2062        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.00971176,51.2062        6
    n.a.     n.a.           64           64.0  unknown 0.006198,51.2062        6
    n.a.     n.a.          128          128.0  unknown 0.00819446,51.2062        6
    n.a.     n.a.          256          256.0  unknown 0.00874478,51.2062        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 25

Starting simulation for: --cats 2048 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.          512          512.0  unknown 0.0027389,51.2062        6
    n.a.     n.a.         1024         1024.0  unknown 0.015358,51.2062        6
    n.a.     n.a.         2048         2048.0  unknown 0.0101975,51.2062        6
    n.a.     n.a.         4096         4096.0  unknown 0.012196,51.2062        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.126737,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.7497,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.23182,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.788926,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.04057,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.10994,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.352921,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 1.9435,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 0

Starting simulation for: --cats 2048 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 2048 and bandwidth: 1

Starting simulation for: --cats 2048 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         2048         2048.0  unknown 1.29305,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 1.54495,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.242057,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.43881,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.41874,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.54637,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.04204,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.17867,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.687571,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.82054,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.53933,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 3.03551,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7591e-05,0.272224        6
    n.a.     n.a.            2            2.0  unknown 0.177655,0.272224        6
    n.a.     n.a.            4            4.0  unknown 2.59967,0.272224        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58581,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.82681,0.272224        6
    n.a.     n.a.           64           64.0  unknown 1.16586,0.272224        6
    n.a.     n.a.          128          128.0  unknown 1.54141,0.272224        6
    n.a.     n.a.          256          256.0  unknown 1.64492,0.272224        6
    n.a.     n.a.          512          512.0  unknown 0.515197,0.272224        6
    n.a.     n.a.         1024         1024.0  unknown 2.88888,0.272224        6
    n.a.     n.a.         2048         2048.0  unknown 1.91818,0.272224        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 2

Starting simulation for: --cats 2048 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 2048 and bandwidth: 3

Starting simulation for: --cats 2048 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 2.29411,0.272224        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196416,0.03824        6
    n.a.     n.a.            2            2.0  unknown 1.26469,0.03824        6
    n.a.     n.a.            4            4.0  unknown 18.5066,0.03824        6
    n.a.     n.a.            8            8.0  unknown 24.613,0.03824        6
    n.a.     n.a.           16           16.0  unknown 22.4872,0.03824        6
    n.a.     n.a.           32           32.0  unknown 13.0048,0.03824        6
    n.a.     n.a.           64           64.0  unknown 8.29959,0.03824        6
    n.a.     n.a.          128          128.0  unknown 10.973,0.03824        6
    n.a.     n.a.          256          256.0  unknown 11.7099,0.03824        6
    n.a.     n.a.          512          512.0  unknown 3.6676,0.03824        6
    n.a.     n.a.         1024         1024.0  unknown 20.5655,0.03824        6
    n.a.     n.a.         2048         2048.0  unknown 13.6552,0.03824        6
    n.a.     n.a.         4096         4096.0  unknown 16.3314,0.03824        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 25

Plotting...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
</pre></div>
</div>
<img alt="../_images/python_cats_23_55.png" src="../_images/python_cats_23_55.png" />
</div>
</div>
</div>
</div>
<div class="section" id="scenario-2">
<h2>Scenario 2<a class="headerlink" href="#scenario-2" title="Permalink to this headline">¶</a></h2>
<p>In the real world peoples preferences change as e.g. the seasons change. So now in the simulation we are going to incorporate two different cost functions, and swap over to the second one halfway through. Below is a a table of the new cost function we are going to use, get_cost_1:</p>
<div class="section" id="living-room">
<h3>Living Room<a class="headerlink" href="#living-room" title="Permalink to this headline">¶</a></h3>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p></p></th>
<th class="text-align:center head"><p>get_cost</p></th>
<th class="text-align:center head"><p>get_cost_1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><strong>Morning</strong></p></td>
<td class="text-align:center"><p>Cold</p></td>
<td class="text-align:center"><p>Hot</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><strong>Afternoon</strong></p></td>
<td class="text-align:center"><p>Hot</p></td>
<td class="text-align:center"><p>Cold</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="bedroom">
<h3>Bedroom<a class="headerlink" href="#bedroom" title="Permalink to this headline">¶</a></h3>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p></p></th>
<th class="text-align:center head"><p>get_cost</p></th>
<th class="text-align:center head"><p>get_cost_1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><strong>Morning</strong></p></td>
<td class="text-align:center"><p>Hot</p></td>
<td class="text-align:center"><p>Cold</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><strong>Afternoon</strong></p></td>
<td class="text-align:center"><p>Cold</p></td>
<td class="text-align:center"><p>Cold</p></td>
</tr>
</tbody>
</table>
<p>Below we define the new cost function</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_cost_1</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">):</span>
    <span class="nb">range</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">max_value</span> <span class="o">-</span> <span class="n">min_value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Living Room&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">29</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Bedroom&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
</pre></div>
</div>
</div>
</div>
<p>To make it easy to show the effect of the cost function changing we are going to modify the run_simulation function. It is a little less readable now, but it supports accepting a list of cost functions and it will operate over each cost function in turn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_simulation_multiple_cost_functions</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">cost_functions</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="n">reward_rate</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">hits</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">cost_sum</span> <span class="o">=</span> <span class="mf">0.</span>

    <span class="n">start_counter</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">end_counter</span> <span class="o">=</span> <span class="n">start_counter</span> <span class="o">+</span> <span class="n">num_iterations</span>
    <span class="k">for</span> <span class="n">cost_function</span> <span class="ow">in</span> <span class="n">cost_functions</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_counter</span><span class="p">,</span> <span class="n">end_counter</span><span class="p">):</span>
            <span class="c1"># 1. In each simulation choose a room</span>
            <span class="n">room</span> <span class="o">=</span> <span class="n">choose_room</span><span class="p">(</span><span class="n">rooms</span><span class="p">)</span>
            <span class="c1"># 2. Choose time of day for a given room</span>
            <span class="n">time_of_day</span> <span class="o">=</span> <span class="n">choose_time_of_day</span><span class="p">(</span><span class="n">times_of_day</span><span class="p">)</span>
            <span class="c1"># 3. Pass context to vw to get a temperature</span>
            <span class="n">context</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;room&#39;</span><span class="p">:</span> <span class="n">room</span><span class="p">,</span> <span class="s1">&#39;time_of_day&#39;</span><span class="p">:</span> <span class="n">time_of_day</span><span class="p">}</span>
            <span class="n">temperature</span><span class="p">,</span> <span class="n">pdf_value</span> <span class="o">=</span> <span class="n">predict_temperature</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
            
            <span class="c1"># 4. Get cost of the action we chose</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="n">cost_function</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">cost</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="mf">0.75</span><span class="p">:</span> <span class="c1"># count something as a hit only if it has a high reward</span>
                <span class="n">hits</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">cost_sum</span> <span class="o">+=</span> <span class="n">cost</span>

            <span class="k">if</span> <span class="n">do_learn</span><span class="p">:</span>
                <span class="c1"># 5. Inform VW of what happened so we can learn from it</span>
                <span class="n">txt_ex</span> <span class="o">=</span> <span class="n">to_vw_example_format</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cats_label</span><span class="o">=</span><span class="p">(</span><span class="n">temperature</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">pdf_value</span><span class="p">))</span>
                <span class="n">vw_format</span> <span class="o">=</span> <span class="n">vw</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">txt_ex</span><span class="p">,</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="o">.</span><span class="n">lContinuous</span><span class="p">)</span>
                <span class="c1"># 6. Learn</span>
                <span class="n">vw</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">vw_format</span><span class="p">)</span>
                <span class="c1"># 7. Let VW know you&#39;re done with these objects</span>
                <span class="n">vw</span><span class="o">.</span><span class="n">finish_example</span><span class="p">(</span><span class="n">vw_format</span><span class="p">)</span>

            <span class="c1"># We negate this so that on the plot instead of minimizing cost, we are maximizing reward</span>
            <span class="n">reward_rate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">cost_sum</span><span class="o">/</span><span class="n">i</span><span class="p">)</span>
        
        <span class="n">start_counter</span> <span class="o">=</span> <span class="n">end_counter</span>
        <span class="n">end_counter</span> <span class="o">=</span> <span class="n">start_counter</span> <span class="o">+</span> <span class="n">num_iterations</span>

    <span class="k">return</span> <span class="n">reward_rate</span><span class="p">,</span> <span class="n">hits</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id3">
<h3>With Learning<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>Now that we have run a parameter sweep we can better pick the values of num_actions and bandwidth. For the next scenario we will pick <code class="docutils literal notranslate"><span class="pre">num_actions</span> <span class="pre">128</span></code> and <code class="docutils literal notranslate"><span class="pre">bandwidth</span> <span class="pre">2</span></code>.</p>
<p>Let us now switch to the second cost function after a few samples (running the first cost function). Recall that this cost function changes the preferences of the room temperatures but it is still working with the same continuous action space as before. We should see the learner pick up these changes and optimize towards the new preferences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># use first reward function initially and then switch to second reward function</span>

<span class="c1"># Instantiate learner in VW</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Instantiate VW learner</span>
<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidth</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>

<span class="n">num_iterations_per_cost_func</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">cost_functions</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_cost</span><span class="p">,</span> <span class="n">get_cost_1</span><span class="p">]</span>
<span class="n">total_iterations</span> <span class="o">=</span> <span class="n">num_iterations_per_cost_func</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">cost_functions</span><span class="p">)</span>

<span class="n">ctr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation_multiple_cost_functions</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations_per_cost_func</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">cost_functions</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
<span class="n">plot_reward_rate</span><span class="p">(</span><span class="n">total_iterations</span><span class="p">,</span> <span class="n">ctr</span><span class="p">,</span> <span class="s1">&#39;reward rate with num_actions = 32 and bandwidth = 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.355694,0.20625        6
0.000000 0.000000            4            4.0 {0.297967,0,0.20625} 3.55245,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.89042,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.266841,0,0.20625} 2.53238,0.20625        6
-0.075758 -0.151515           64           64.0 {20.7649,-1,0.20625} 19.1146,0.20625        6
-0.189394 -0.303030          128          128.0 {18.143,-1,0.20625} 19.6102,0.20625        6
-0.255682 -0.321970          256          256.0 {20.6561,-1,0.20625} 19.7468,0.20625        6
-0.473485 -0.691288          512          512.0 {18.22,-1,0.20625} 18.2558,0.20625        6
-0.553977 -0.634470         1024         1024.0 {16.9489,-1,0.20625} 17.0251,0.20625        6
-0.712595 -0.871212         2048         2048.0 {21.9192,0,0.20625} 23.5015,0.20625        6
-0.680634 -0.648674         4096         4096.0 {17.5772,-1,0.20625} 18.9067,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.732718 -0.784801         8192         8192.0 {25.7934,-1,0.20625} 26.6888,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.687737 -0.642756        16384        16384.0 {15.0593,-1,0.20625} 9.50664,0.00625        6

finished run
number of examples = 20000
weighted example sum = 20000.000000
weighted label sum = 20000.000000
average loss = -0.710545
total feature number = 120000
</pre></div>
</div>
<img alt="../_images/python_cats_29_3.png" src="../_images/python_cats_29_3.png" />
</div>
</div>
</div>
<div class="section" id="id4">
<h3>Without Learning<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># use first reward function initially and then switch to second reward function</span>

<span class="c1"># Instantiate learner in VW</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Instantiate VW learner</span>
<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidth</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>

<span class="n">num_iterations_per_cost_func</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">cost_functions</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_cost</span><span class="p">,</span> <span class="n">get_cost_1</span><span class="p">]</span>
<span class="n">total_iterations</span> <span class="o">=</span> <span class="n">num_iterations_per_cost_func</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">cost_functions</span><span class="p">)</span>

<span class="n">ctr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation_multiple_cost_functions</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations_per_cost_func</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">cost_functions</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
<span class="n">plot_reward_rate</span><span class="p">(</span><span class="n">total_iterations</span><span class="p">,</span> <span class="n">ctr</span><span class="p">,</span> <span class="s1">&#39;reward rate with num_actions = 32 and bandwidth = 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=5868; id=1, #l=3708; id=2, #l=3799; id=3, #l=0; id=4, #l=3496; id=5, #l=3426; id=6, #l=1901; id=7, #l=0; id=8, #l=0; id=9, #l=318; id=10, #l=1777; id=11, #l=2296; id=12, #l=1925; id=13, #l=734; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.355694,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.55245,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.53238,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.66001,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.15567,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.2923,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.801207,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.93417,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.65297,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.14915,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         8192         8192.0  unknown 4.73022,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = n.a.
total feature number = 60000
</pre></div>
</div>
<img alt="../_images/python_cats_31_2.png" src="../_images/python_cats_31_2.png" />
</div>
</div>
</div>
</div>
<div class="section" id="scenario-3">
<h2>Scenario 3<a class="headerlink" href="#scenario-3" title="Permalink to this headline">¶</a></h2>
<div class="section" id="better-cost-function">
<h3>Better cost function<a class="headerlink" href="#better-cost-function" title="Permalink to this headline">¶</a></h3>
<p>The cost function we have been using until now has been a bit too simplistic but has served us well enough to showcase the differences in learning and also in showing CB pickup the new cost cost function and adjust to it.</p>
<p>A slightly better cost function for our simulated world could be the difference between the temperature recommended and the temperature chosen. The smaller the difference the better the thermostat is doing. We are going to model that by taking the absolute cost: <code class="docutils literal notranslate"><span class="pre">1.0</span> <span class="pre">-</span> <span class="pre">|selected_temperature</span> <span class="pre">-</span> <span class="pre">predicted_temerature|</span> <span class="pre">/</span> <span class="pre">range</span></code> and the transforming that cost into a reward by multiplying it with <code class="docutils literal notranslate"><span class="pre">-1</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_smooth_cost</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">):</span>
    <span class="nb">range</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">max_value</span> <span class="o">-</span> <span class="n">min_value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Living Room&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">29</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">/</span> <span class="nb">range</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">cost</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">/</span> <span class="nb">range</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">cost</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Bedroom&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">/</span> <span class="nb">range</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">cost</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">/</span> <span class="nb">range</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">cost</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s try the original paramter sweep with the new cost function <code class="docutils literal notranslate"><span class="pre">get_smooth_cost</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># do parameter sweeping</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">]</span>
<span class="n">bandwidths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span>

<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="k">for</span> <span class="n">actions</span> <span class="ow">in</span> <span class="n">num_actions</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="n">bandwidths</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">bd</span> <span class="o">&gt;=</span> <span class="n">actions</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting simulation for: --cats </span><span class="si">{}</span><span class="s2"> --bandwidth </span><span class="si">{}</span><span class="s2"> --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
        <span class="n">rr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_smooth_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done with simulation for num_actions: </span><span class="si">{}</span><span class="s2"> and bandwidth: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)][</span><span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">rr</span><span class="p">,</span> <span class="n">hits</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Plotting...&quot;</span><span class="p">)</span>
<span class="n">plot_reward_sweep</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">bandwidths</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting simulation for: --cats 8 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
0.000000 0.000000            2            2.0 {3.64167e-05,-0.483655,0.20625} 0.234482,0.20625        6
0.000000 0.000000            4            4.0 {0.176755,-0.456013,0.20625} 3.43124,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,-0.812652,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {11.5268,-0.815115,0.20625} 11.9268,0.20625        6
0.000000 0.000000           32           32.0 {4.80576,-0.291584,0.00625} 10.1687,0.20625        6
0.000000 0.000000           64           64.0 {22.5831,-0.828904,0.20625} 20.9327,0.20625        6
0.000000 0.000000          128          128.0 {8.32479,-0.767732,0.20625} 9.79204,0.20625        6
0.000000 0.000000          256          256.0 {10.838,-0.861115,0.20625} 9.92867,0.20625        6
0.000000 0.000000          512          512.0 {20.0382,-0.933927,0.20625} 20.0739,0.20625        6
0.000000 0.000000         1024         1024.0 {11.4944,-0.82772,0.20625} 11.5705,0.20625        6
0.000000 0.000000         2048         2048.0 {24.2222,-0.931245,0.20625} 25.8045,0.20625        6
0.000000 0.000000         4096         4096.0 {21.0923,-0.893877,0.20625} 22.4219,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {22.5207,-0.769337,0.20625} 23.4161,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4291; id=1, #l=1024; id=2, #l=3508; id=3, #l=449; id=4, #l=815; id=5, #l=3414; id=6, #l=322; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,-0.122314,0.00625} 1.10366,0.40625        6
-0.316238 -0.632476            4            4.0 {1.07435,-0.513887,0.40625} 2.72663,0.40625        6
-0.158119 0.000000            8            8.0 {10.3501,-0.789748,0.00625} 22.5925,0.00625        6
-0.249117 -0.340114           16           16.0 {10.7751,-0.835468,0.40625} 10.9782,0.40625        6
-0.303164 -0.357212           32           32.0 {1.05855,-0.530991,0.40625} 2.20875,0.40625        6
-0.307905 -0.312645           64           64.0 {22.296,-0.786096,0.40625} 21.4582,0.40625        6
-0.417309 -0.526713          128          128.0 {18.7182,-0.921664,0.00625} 21.7098,0.40625        6
-0.484472 -0.551635          256          256.0 {22.2408,-0.817461,0.40625} 21.7792,0.40625        6
-0.571344 -0.658216          512          512.0 {17.0656,-0.740816,0.40625} 17.0837,0.40625        6
-0.630425 -0.689506         1024         1024.0 {18.6356,-0.932781,0.40625} 18.6743,0.40625        6
-0.641999 -0.653573         2048         2048.0 {13.282,-0.561168,0.40625} 14.0854,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 0

Starting simulation for: --cats 8 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.720285 -0.798571         4096         4096.0 {21.5392,-0.828879,0.40625} 22.2142,0.40625        6
-0.755136 -0.789987         8192         8192.0 {14.3874,-0.961054,0.40625} 14.842,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.787973
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 1

Starting simulation for: --cats 8 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4284; id=1, #l=923; id=2, #l=3590; id=3, #l=275; id=4, #l=894; id=5, #l=2891; id=6, #l=940; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
-0.589031 -0.589031            2            2.0 {3.64167e-05,-0.48595,0.20625} 0.234482,0.20625        6
-0.599895 -0.610759            4            4.0 {0.176755,-0.503876,0.20625} 3.43124,0.20625        6
-0.299947 0.000000            8            8.0 {10.3501,-0.785107,0.00625} 22.5925,0.00625        6
-0.196845 -0.093742           16           16.0 {3.76921,-0.58736,0.20625} 9.58582,0.00625        6
-0.227387 -0.257929           32           32.0 {4.80576,-0.660384,0.00625} 21.8051,0.20625        6
-0.382515 -0.537642           64           64.0 {30.3406,-0.949797,0.20625} 28.6903,0.20625        6
-0.533681 -0.684846          128          128.0 {18.7182,-0.908209,0.00625} 21.4284,0.20625        6
-0.564941 -0.596202          256          256.0 {22.4743,-0.777917,0.20625} 21.565,0.20625        6
-0.775957 -0.986973          512          512.0 {20.0382,-0.930683,0.20625} 20.0739,0.20625        6
-0.732648 -0.689339         1024         1024.0 {19.2519,-0.939095,0.20625} 19.3281,0.20625        6
-0.766300 -0.799952         2048         2048.0 {12.5858,-0.842339,0.20625} 14.1681,0.20625        6
-0.820591 -0.874882         4096         4096.0 {17.2135,-0.993442,0.20625} 18.5431,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.814751 -0.808911         8192         8192.0 {18.6419,-0.897652,0.20625} 19.5373,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.831189
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4223; id=1, #l=1888; id=2, #l=2567; id=3, #l=284; id=4, #l=1861; id=5, #l=2587; id=6, #l=268; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-16.725697 -16.725697            2            2.0 {0.00120175,-0.522678,0.00625} 3.21214,0.139583        6
-8.698120 -0.670544            4            4.0 {3.12685,-0.561581,0.139583} 7.93571,0.139583        6
-4.349060 0.000000            8            8.0 {10.3501,-0.835834,0.00625} 22.5925,0.00625        6
-2.433735 -0.518409           16           16.0 {19.8978,-0.83449,0.139583} 20.4889,0.139583        6
-1.459997 -0.486259           32           32.0 {4.80576,-0.288487,0.00625} 25.5329,0.139583        6
-0.924550 -0.389103           64           64.0 {7.57796,-0.68567,0.139583} 5.13941,0.139583        6
-0.704075 -0.483600          128          128.0 {3.7038,-0.593693,0.139583} 5.87181,0.139583        6
-0.553017 -0.401960          256          256.0 {26.5217,-0.654863,0.139583} 25.1782,0.139583        6
-0.721287 -0.889556          512          512.0 {7.63855,-0.737871,0.139583} 7.69134,0.139583        6
-0.729378 -0.737469         1024         1024.0 {16.029,-0.615384,0.139583} 16.1415,0.139583        6
-0.760408 -0.791438         2048         2048.0 {19.5522,-0.788263,0.139583} 21.8902,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 2

Starting simulation for: --cats 8 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.824565 -0.888721         4096         4096.0 {16.8379,-0.977475,0.139583} 18.8025,0.139583        6
-0.829653 -0.834741         8192         8192.0 {18.9484,-0.934111,0.139583} 20.2715,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.826699
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1812; id=1, #l=3073; id=2, #l=3039; id=3, #l=0; id=4, #l=1910; id=5, #l=1418; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 9.31589e-06,0.80625        6
0.000000 0.000000            2            2.0 {9.31589e-06,-0.173774,0.80625} 0.0599837,0.80625        6
0.000000 0.000000            4            4.0 {0.0452164,-0.49191,0.80625} 0.877758,0.80625        6
0.000000 0.000000            8            8.0 {10.3501,-0.827744,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.964217,-0.18233,0.80625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {4.00625,-0.588132,0.80625} 4.5858,0.80625        6
0.000000 0.000000           64           64.0 {21.653,-0.841502,0.80625} 21.2309,0.80625        6
0.000000 0.000000          128          128.0 {5.10634,-0.260326,0.80625} 5.48168,0.80625        6
0.000000 0.000000          256          256.0 {21.6252,-0.885332,0.80625} 21.3926,0.80625        6
0.000000 0.000000          512          512.0 {5.12605,-0.358119,0.80625} 5.13519,0.80625        6
0.000000 0.000000         1024         1024.0 {21.7931,-0.815111,0.80625} 21.8126,0.80625        6
0.000000 0.000000         2048         2048.0 {29.0181,-0.654312,0.80625} 29.4229,0.80625        6
0.000000 0.000000         4096         4096.0 {20.2794,-0.923119,0.80625} 20.6196,0.80625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {21.6371,-0.845752,0.80625} 21.8661,0.80625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4128; id=1, #l=258; id=2, #l=3919; id=3, #l=257; id=4, #l=64; id=5, #l=2022; id=6, #l=1948; id=7, #l=106; id=8, #l=209; id=9, #l=61; id=10, #l=64; id=11, #l=47; id=12, #l=2020; id=13, #l=64; id=14, #l=1927; id=15, #l=91; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-48.977081 -48.977081            2            2.0 {0.00120175,-0.45916,0.00625} 0.611352,0.40625        6
-24.488541 0.000000            4            4.0 {0.582045,-0.479175,0.40625} 2.23432,0.40625        6
-12.244270 0.000000            8            8.0 {10.3501,-0.511493,0.00625} 22.5925,0.00625        6
-6.210122 -0.175973           16           16.0 {2.40591,-0.577221,0.40625} 9.58582,0.00625        6
-3.225171 -0.240220           32           32.0 {3.52009,-0.609814,0.40625} 4.67028,0.40625        6
-1.799058 -0.372946           64           64.0 {20.8191,-0.866123,0.40625} 19.9812,0.40625        6
-1.119987 -0.440916          128          128.0 {18.7182,-0.903855,0.00625} 20.2329,0.40625        6
-0.780687 -0.441386          256          256.0 {20.7639,-0.756862,0.40625} 20.3022,0.40625        6
-0.895969 -1.011252          512          512.0 {19.5271,-0.861027,0.40625} 19.5452,0.40625        6
-0.816360 -0.736750         1024         1024.0 {28.9741,-0.912041,0.40625} 29.0127,0.40625        6
-0.981438 -1.146517         2048         2048.0 {16.7282,-0.959723,0.40625} 17.5315,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 0

Starting simulation for: --cats 32 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.787424 -0.593409         4096         4096.0 {22.0315,-0.840948,0.40625} 22.7065,0.40625        6
-0.768083 -0.748743         8192         8192.0 {23.7413,-0.779807,0.40625} 24.1959,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 1

Starting simulation for: --cats 32 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.773698
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4211; id=1, #l=528; id=2, #l=3030; id=3, #l=195; id=4, #l=414; id=5, #l=3413; id=6, #l=1094; id=7, #l=146; id=8, #l=152; id=9, #l=207; id=10, #l=310; id=11, #l=695; id=12, #l=1773; id=13, #l=1103; id=14, #l=104; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-31.506697 -31.506697            2            2.0 {0.00120175,-0.492292,0.00625} 0.71933,0.20625        6
-15.753348 0.000000            4            4.0 {0.661603,-0.159803,0.20625} 3.91608,0.20625        6
-7.876674 0.000000            8            8.0 {10.3501,-0.783543,0.00625} 22.5925,0.00625        6
-4.141945 -0.407215           16           16.0 {10.0722,-0.765832,0.20625} 10.4723,0.20625        6
-2.130471 -0.118997           32           32.0 {4.80576,-0.637311,0.00625} 8.7142,0.20625        6
-1.311765 -0.493058           64           64.0 {9.49215,-0.773713,0.20625} 7.84182,0.20625        6
-0.908079 -0.504393          128          128.0 {18.5066,-0.917316,0.20625} 19.9739,0.20625        6
-0.901030 -0.893980          256          256.0 {11.3228,-0.850116,0.20625} 10.4135,0.20625        6
-1.263789 -1.626549          512          512.0 {10.8261,-0.799955,0.20625} 10.8618,0.20625        6
-0.882867 -0.501944         1024         1024.0 {13.9186,-0.882546,0.20625} 13.9948,0.20625        6
-0.905584 -0.928302         2048         2048.0 {11.1313,-0.848795,0.20625} 12.7136,0.20625        6
-0.908202 -0.910820         4096         4096.0 {13.8196,-0.885358,0.20625} 15.1492,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.916352 -0.924502         8192         8192.0 {25.9146,-0.96192,0.20625} 26.81,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.927522
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3783; id=1, #l=3293; id=2, #l=1136; id=3, #l=291; id=4, #l=1831; id=5, #l=1893; id=6, #l=826; id=7, #l=0; id=8, #l=159; id=9, #l=1331; id=10, #l=1409; id=11, #l=1212; id=12, #l=556; id=13, #l=447; id=14, #l=0; id=15, #l=49; 
    n.a.     n.a.            1            1.0  unknown 3.19857e-05,0.234821        6
-0.602801 -0.602801            2            2.0 {3.19857e-05,-0.495427,0.234821} 0.205952,0.234821        6
-0.301401 0.000000            4            4.0 {0.155249,-0.444878,0.234821} 3.01375,0.234821        6
-0.150700 0.000000            8            8.0 {10.3501,-0.424792,0.00625} 22.5925,0.00625        6
-0.141323 -0.131945           16           16.0 {3.3106,-0.581391,0.234821} 9.58582,0.00625        6
-1.359653 -2.577984           32           32.0 {4.80576,-0.616554,0.00625} 12.6374,0.139583        6
-0.942597 -0.525541           64           64.0 {4.33577,-0.592328,0.151705} 2.09207,0.151705        6
-0.954284 -0.965971          128          128.0 {9.91276,-0.825488,0.139583} 12.0808,0.139583        6
-1.242391 -1.530498          256          256.0 {28.9098,-0.977074,0.139583} 27.5662,0.139583        6
-0.992825 -0.743259          512          512.0 {18.6236,-0.892111,0.139583} 18.6764,0.139583        6
-0.895157 -0.797490         1024         1024.0 {21.2827,-0.805093,0.139583} 21.3953,0.139583        6
-0.847233 -0.799310         2048         2048.0 {18.1194,-0.954212,0.139583} 20.4574,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 2

Starting simulation for: --cats 32 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.853745 -0.860257         4096         4096.0 {24.0021,-0.892782,0.139583} 25.9667,0.139583        6
-0.822190 -0.790634         8192         8192.0 {25.1574,-0.936766,0.139583} 26.4805,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.823786
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4160; id=1, #l=1194; id=2, #l=1733; id=3, #l=431; id=4, #l=0; id=5, #l=1601; id=6, #l=1480; id=7, #l=95; id=8, #l=0; id=9, #l=491; id=10, #l=615; id=11, #l=941; id=12, #l=617; id=13, #l=996; id=14, #l=448; id=15, #l=43; 
    n.a.     n.a.            1            1.0  unknown 0.000199639,0.0376226        6
-0.444847 -0.444847            2            2.0 {0.000199639,-0.443511,0.0376226} 1.28545,0.0376226        6
-0.424817 -0.404788            4            4.0 {0.968985,-0.487333,0.0376226} 18.8103,0.0376226        6
-0.547043 -0.669269            8            8.0 {22.9832,-0.837803,0.0376226} 25.017,0.0376226        6
-0.612450 -0.677857           16           16.0 {20.6631,-0.839073,0.0376226} 22.8563,0.0376226        6
-0.621359 -0.630267           32           32.0 {0.798351,-0.526932,0.0376226} 13.2182,0.0376226        6
-0.743487 -0.865615           64           64.0 {17.483,-0.996525,0.0376226} 8.4358,0.0376226        6
-0.760077 -0.776668          128          128.0 {3.74364,-0.555302,0.03125} 13.4274,0.03125        6
-0.764901 -0.769725          256          256.0 {20.3305,-0.915312,0.03125} 14.3292,0.03125        6
-0.761190 -0.757479          512          512.0 {4.25219,-0.606396,0.03125} 4.48797,0.03125        6
-0.749019 -0.736848         1024         1024.0 {24.6628,-0.758336,0.03125} 25.1656,0.03125        6
-0.742033 -0.735047         2048         2048.0 {6.26651,-0.719778,0.03125} 16.7096,0.03125        6
-0.739681 -0.737330         4096         4096.0 {11.2093,-0.863969,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.737030 -0.734379         8192         8192.0 {20.6363,-0.787295,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.736950
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=2; id=2, #l=0; id=3, #l=459; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=301; id=8, #l=146; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=281; id=15, #l=161; 
    n.a.     n.a.            1            1.0  unknown 4.67607e-06,1.60625        6
0.000000 0.000000            2            2.0 {4.67607e-06,-0.521156,1.60625} 0.0301085,1.60625        6
0.000000 0.000000            4            4.0 {0.0226962,-0.517564,1.60625} 0.440587,1.60625        6
0.000000 0.000000            8            8.0 {10.3501,-0.785634,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.483984,-0.480588,1.60625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0186995,-0.508929,1.60625} 0.309605,1.60625        6
0.000000 0.000000           64           64.0 {4.39393,-0.646916,1.60625} 4.18202,1.60625        6
0.000000 0.000000          128          128.0 {18.7182,-0.713907,0.00625} 21.1795,1.60625        6
0.000000 0.000000          256          256.0 {4.37997,-0.623611,1.60625} 4.26321,1.60625        6
0.000000 0.000000          512          512.0 {4.06716,-0.610761,1.60625} 4.07175,1.60625        6
0.000000 0.000000         1024         1024.0 {13.9273,-0.918699,1.60625} 13.9371,1.60625        6
0.000000 0.000000         2048         2048.0 {21.5383,-0.812051,1.60625} 21.7414,1.60625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 25

Starting simulation for: --cats 64 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {29.6033,-0.546667,1.60625} 29.774,1.60625        6
0.000000 0.000000         8192         8192.0 {13.849,-0.871345,1.60625} 13.9639,1.60625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 0

Starting simulation for: --cats 64 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4049; id=1, #l=1096; id=2, #l=2993; id=3, #l=348; id=4, #l=779; id=5, #l=2099; id=6, #l=931; id=7, #l=106; id=8, #l=273; id=9, #l=32; id=10, #l=787; id=11, #l=391; id=12, #l=1730; id=13, #l=22; id=14, #l=947; id=15, #l=103; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-18.267639 -18.267639            2            2.0 {0.00120175,-0.142716,0.00625} 0.365198,0.40625        6
-9.133820 0.000000            4            4.0 {0.335891,-0.112255,0.40625} 1.98817,0.40625        6
-4.566910 0.000000            8            8.0 {10.3501,-0.777044,0.00625} 22.5925,0.00625        6
-2.326699 -0.086488           16           16.0 {2.15975,-0.185619,0.40625} 9.58582,0.00625        6
-1.305127 -0.283556           32           32.0 {3.27393,-0.593073,0.40625} 4.42413,0.40625        6
-0.810563 -0.316000           64           64.0 {4.81909,-0.612842,0.40625} 3.98123,0.40625        6
-1.399871 -1.989179          128          128.0 {18.7182,-0.682336,0.00625} 20.9713,0.40625        6
-0.907067 -0.414264          256          256.0 {21.01,-0.890507,0.40625} 20.5484,0.40625        6
-0.950693 -0.994319          512          512.0 {21.2502,-0.799317,0.40625} 21.2683,0.40625        6
-0.974327 -0.997960         1024         1024.0 {22.8202,-0.815283,0.40625} 22.8589,0.40625        6
-1.053153 -1.131979         2048         2048.0 {24.359,-0.787703,0.40625} 25.1623,0.40625        6
-0.895711 -0.738270         4096         4096.0 {20.8007,-0.832775,0.40625} 21.4757,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.845075 -0.794438         8192         8192.0 {23.0028,-0.768745,0.40625} 23.4574,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.878463
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4160; id=1, #l=324; id=2, #l=3404; id=3, #l=233; id=4, #l=208; id=5, #l=2359; id=6, #l=1926; id=7, #l=136; id=8, #l=195; id=9, #l=148; id=10, #l=130; id=11, #l=526; id=12, #l=1677; id=13, #l=1429; id=14, #l=630; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-35.352158 -35.352158            2            2.0 {0.00120175,-0.49714,0.00625} 0.476906,0.20625        6
-17.676079 0.000000            4            4.0 {0.419179,-0.115297,0.20625} 3.67366,0.20625        6
-8.838039 0.000000            8            8.0 {10.3501,-0.78913,0.00625} 22.5925,0.00625        6
-4.543617 -0.249194           16           16.0 {9.82982,-0.82234,0.20625} 10.2299,0.20625        6
-2.360226 -0.176836           32           32.0 {0.388053,-0.542598,0.20625} 2.65359,0.20625        6
-1.351346 -0.342466           64           64.0 {20.8861,-0.852928,0.20625} 19.2358,0.20625        6
-0.941193 -0.531039          128          128.0 {7.11267,-0.745173,0.20625} 8.57992,0.20625        6
-1.215431 -1.489668          256          256.0 {23.6864,-0.946259,0.20625} 22.7772,0.20625        6
-0.998539 -0.781648          512          512.0 {21.2503,-0.876063,0.20625} 21.2861,0.20625        6
-0.899756 -0.800973         1024         1024.0 {23.3731,-0.871512,0.20625} 23.4493,0.20625        6
-1.018332 -1.136907         2048         2048.0 {22.0404,-0.853538,0.20625} 23.6227,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 1

Starting simulation for: --cats 64 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-1.006960 -0.995588         4096         4096.0 {22.7893,-0.789801,0.20625} 24.1188,0.20625        6
-0.917668 -0.828377         8192         8192.0 {23.7328,-0.771936,0.20625} 24.6282,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.899768
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4183; id=1, #l=1978; id=2, #l=1217; id=3, #l=248; id=4, #l=1547; id=5, #l=2558; id=6, #l=1613; id=7, #l=0; id=8, #l=176; id=9, #l=784; id=10, #l=710; id=11, #l=1064; id=12, #l=1560; id=13, #l=1000; id=14, #l=0; id=15, #l=46; 
    n.a.     n.a.            1            1.0  unknown 2.97576e-05,0.252404        6
-0.594324 -0.594324            2            2.0 {2.97576e-05,-0.487531,0.252404} 0.191605,0.252404        6
-0.478224 -0.362124            4            4.0 {0.144434,-0.525559,0.252404} 2.80381,0.252404        6
-0.239112 0.000000            8            8.0 {10.3501,-0.845095,0.00625} 22.5925,0.00625        6
-0.143646 -0.048180           16           16.0 {3.07998,-0.552604,0.252404} 9.58582,0.00625        6
-1.281573 -2.419499           32           32.0 {1.40921,-0.51853,0.139583} 4.7568,0.139583        6
-0.908866 -0.536159           64           64.0 {23.1003,-0.81915,0.139583} 20.6618,0.139583        6
-0.722799 -0.536732          128          128.0 {18.7182,-0.895802,0.00625} 22.3494,0.139583        6
-0.563219 -0.403639          256          256.0 {20.5516,-0.827353,0.139583} 19.208,0.139583        6
-0.625355 -0.687491          512          512.0 {9.7878,-0.747918,0.139583} 9.84059,0.139583        6
-0.581891 -0.538427         1024         1024.0 {15.3126,-0.927986,0.139583} 15.4251,0.139583        6
-0.707426 -0.832960         2048         2048.0 {21.7015,-0.862144,0.139583} 24.0395,0.139583        6
-0.738325 -0.769224         4096         4096.0 {21.3752,-0.887124,0.139583} 23.3398,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 2

Starting simulation for: --cats 64 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.763874 -0.789424         8192         8192.0 {23.4857,-0.741189,0.139583} 24.8088,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.769423
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4289; id=1, #l=558; id=2, #l=2247; id=3, #l=243; id=4, #l=0; id=5, #l=2381; id=6, #l=1896; id=7, #l=67; id=8, #l=0; id=9, #l=185; id=10, #l=354; id=11, #l=1017; id=12, #l=854; id=13, #l=1554; id=14, #l=650; id=15, #l=32; 
    n.a.     n.a.            1            1.0  unknown 0.000198004,0.0379332        6
-0.443797 -0.443797            2            2.0 {0.000198004,-0.441909,0.0379332} 1.27492,0.0379332        6
-0.432355 -0.420914            4            4.0 {0.961051,-0.510931,0.0379332} 18.6563,0.0379332        6
-0.549109 -0.665863            8            8.0 {22.795,-0.875139,0.0379332} 24.8121,0.0379332        6
-1.025747 -1.502386           16           16.0 {20.4939,-0.859642,0.0379332} 22.6691,0.0379332        6
-0.837529 -0.649311           32           32.0 {0.791813,-0.510752,0.0379332} 13.11,0.0379332        6
-0.806196 -0.774863           64           64.0 {17.3399,-0.706509,0.0379332} 8.36672,0.0379332        6
-0.778287 -0.750379          128          128.0 {3.74364,-0.25144,0.03125} 13.4274,0.03125        6
-0.777417 -0.776547          256          256.0 {20.3305,-0.862493,0.03125} 14.3292,0.03125        6
-0.760953 -0.744489          512          512.0 {4.25219,-0.59092,0.03125} 4.48797,0.03125        6
-0.747992 -0.735030         1024         1024.0 {24.6628,-0.957109,0.03125} 25.1656,0.03125        6
-0.745261 -0.742530         2048         2048.0 {6.26651,-0.649811,0.03125} 16.7096,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 3

Starting simulation for: --cats 64 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.740427 -0.735593         4096         4096.0 {11.2093,-0.515075,0.03125} 19.9844,0.03125        6
-0.736944 -0.733462         8192         8192.0 {20.6363,-0.881778,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.736531
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 25

Starting simulation for: --cats 128 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=459; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=301; id=8, #l=146; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=281; id=15, #l=161; 
    n.a.     n.a.            1            1.0  unknown 2.34259e-06,3.20625        6
0.000000 0.000000            2            2.0 {2.34259e-06,-0.474311,3.20625} 0.0150836,3.20625        6
0.000000 0.000000            4            4.0 {0.0113702,-0.474088,3.20625} 0.220723,3.20625        6
0.000000 0.000000            8            8.0 {10.3501,-0.809335,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.242464,-0.475818,3.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00936795,-0.525411,3.20625} 0.155104,3.20625        6
0.000000 0.000000           64           64.0 {0.205148,-0.119342,3.20625} 0.0989867,3.20625        6
0.000000 0.000000          128          128.0 {5.27625,-0.682277,3.20625} 5.37064,3.20625        6
0.000000 0.000000          256          256.0 {0.198153,-0.112936,3.20625} 0.139661,3.20625        6
0.000000 0.000000          512          512.0 {0.0414444,-0.127019,3.20625} 0.0437424,3.20625        6
0.000000 0.000000         1024         1024.0 {0.240378,-0.502954,3.20625} 0.245278,3.20625        6
0.000000 0.000000         2048         2048.0 {13.5348,-0.613341,3.20625} 13.6365,3.20625        6
0.000000 0.000000         4096         4096.0 {25.31,-0.890551,3.20625} 25.3956,3.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {21.9087,-0.792727,3.20625} 21.9663,3.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4051; id=1, #l=2165; id=2, #l=1897; id=3, #l=1540; id=4, #l=635; id=5, #l=1107; id=6, #l=806; id=7, #l=976; id=8, #l=585; id=9, #l=9; id=10, #l=633; id=11, #l=13; id=12, #l=1107; id=13, #l=658; id=14, #l=171; id=15, #l=538; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-63.199604 -63.199604            2            2.0 {0.00120175,-0.444372,0.00625} 0.242121,0.40625        6
-31.599802 0.000000            4            4.0 {0.212814,-0.487306,0.40625} 1.86509,0.40625        6
-15.799901 0.000000            8            8.0 {10.3501,-0.848612,0.00625} 22.5925,0.00625        6
-7.899951 0.000000           16           16.0 {2.03668,-0.173818,0.40625} 9.58582,0.00625        6
-7.258054 -6.616158           32           32.0 {0.197012,-0.519699,0.40625} 1.34721,0.40625        6
-3.887498 -0.516942           64           64.0 {20.9422,-0.892931,0.40625} 20.1043,0.40625        6
-2.166779 -0.446061          128          128.0 {18.7182,-0.957491,0.00625} 20.8483,0.40625        6
-1.293203 -0.419627          256          256.0 {12.2716,-0.911731,0.40625} 11.8099,0.40625        6
-1.424915 -1.556627          512          512.0 {11.0348,-0.869739,0.40625} 11.0529,0.40625        6
-1.052954 -0.680992         1024         1024.0 {20.2356,-0.820136,0.40625} 20.2743,0.40625        6
-0.881239 -0.709524         2048         2048.0 {24.2359,-0.760061,0.40625} 25.0392,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 0

Starting simulation for: --cats 128 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.810213 -0.739187         4096         4096.0 {19.9392,-0.846847,0.40625} 20.6142,0.40625        6
-0.832236 -0.854259         8192         8192.0 {21.6489,-0.795531,0.40625} 22.1035,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 1

Starting simulation for: --cats 128 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.835419
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4127; id=1, #l=542; id=2, #l=3804; id=3, #l=208; id=4, #l=368; id=5, #l=1545; id=6, #l=1921; id=7, #l=120; id=8, #l=126; id=9, #l=176; id=10, #l=339; id=11, #l=774; id=12, #l=1543; id=13, #l=713; id=14, #l=380; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-29.651133 -29.651133            2            2.0 {0.00120175,-0.440134,0.00625} 0.355694,0.20625        6
-14.825566 0.000000            4            4.0 {0.297967,-0.45758,0.20625} 3.55245,0.20625        6
-7.412783 0.000000            8            8.0 {10.3501,-0.440505,0.00625} 22.5925,0.00625        6
-3.706392 0.000000           16           16.0 {3.89042,-0.310712,0.20625} 9.58582,0.00625        6
-1.871495 -0.036599           32           32.0 {1.23654,-0.50569,0.20625} 3.50207,0.20625        6
-1.132079 -0.392663           64           64.0 {13.0073,-0.850537,0.20625} 11.357,0.20625        6
-0.832403 -0.532727          128          128.0 {18.143,-0.957959,0.20625} 19.6102,0.20625        6
-0.644014 -0.455625          256          256.0 {12.8986,-0.88676,0.20625} 11.9893,0.20625        6
-0.932427 -1.220839          512          512.0 {10.4625,-0.849753,0.20625} 10.4982,0.20625        6
-0.802669 -0.672912         1024         1024.0 {23.4944,-0.785095,0.20625} 23.5705,0.20625        6
-0.816589 -0.830508         2048         2048.0 {27.7374,-0.958479,0.20625} 29.3196,0.20625        6
-0.826142 -0.835696         4096         4096.0 {18.062,-0.934602,0.20625} 19.3916,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.825906 -0.825671         8192         8192.0 {23.854,-0.765742,0.20625} 24.7494,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.838774
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4110; id=1, #l=1134; id=2, #l=2220; id=3, #l=298; id=4, #l=857; id=5, #l=2530; id=6, #l=1674; id=7, #l=0; id=8, #l=154; id=9, #l=334; id=10, #l=404; id=11, #l=810; id=12, #l=1513; id=13, #l=1060; id=14, #l=0; id=15, #l=57; 
    n.a.     n.a.            1            1.0  unknown 2.86404e-05,0.26225        6
-0.582406 -0.582406            2            2.0 {2.86404e-05,-0.4773,0.26225} 0.184411,0.26225        6
-0.448292 -0.314177            4            4.0 {0.139011,-0.46346,0.26225} 2.69854,0.26225        6
-0.224146 0.000000            8            8.0 {10.3501,-0.827347,0.00625} 22.5925,0.00625        6
-0.266037 -0.307927           16           16.0 {14.2858,-0.622675,0.139583} 14.877,0.139583        6
-0.261780 -0.257524           32           32.0 {4.80576,-0.592769,0.00625} 23.7419,0.139583        6
-0.355899 -0.450017           64           64.0 {5.78691,-0.630208,0.139583} 3.34837,0.139583        6
-0.470495 -0.585091          128          128.0 {9.55455,-0.395317,0.139583} 11.7226,0.139583        6
-0.574253 -0.678011          256          256.0 {26.6412,-0.703341,0.139583} 25.2976,0.139583        6
-0.835720 -1.097187          512          512.0 {21.261,-0.799474,0.00625} 22.4398,0.00625        6
-0.750230 -0.664741         1024         1024.0 {15.9096,-0.941402,0.139583} 16.0221,0.139583        6
-0.820481 -0.890732         2048         2048.0 {19.194,-0.78753,0.139583} 21.532,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 2

Starting simulation for: --cats 128 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.828373 -0.836264         4096         4096.0 {17.1961,-0.983935,0.139583} 19.1607,0.139583        6
-0.880127 -0.931882         8192         8192.0 {15.4857,-0.931667,0.139583} 16.8088,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.864738
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2594; id=1, #l=1919; id=2, #l=2995; id=3, #l=239; id=4, #l=0; id=5, #l=1588; id=6, #l=956; id=7, #l=70; id=8, #l=0; id=9, #l=464; id=10, #l=978; id=11, #l=1341; id=12, #l=1137; id=13, #l=755; id=14, #l=112; id=15, #l=32; 
    n.a.     n.a.            1            1.0  unknown 0.000197185,0.0380908        6
-0.465706 -0.465706            2            2.0 {0.000197185,-0.46787,0.0380908} 1.26965,0.0380908        6
-0.447348 -0.428990            4            4.0 {0.957074,-0.522898,0.0380908} 18.5791,0.0380908        6
-0.583479 -0.719611            8            8.0 {22.7007,-0.888829,0.0380908} 24.7095,0.0380908        6
-0.984691 -1.385902           16           16.0 {20.4091,-0.74785,0.0380908} 22.5753,0.0380908        6
-0.784068 -0.583444           32           32.0 {0.788537,-0.483392,0.0380908} 13.0557,0.0380908        6
-0.827767 -0.871466           64           64.0 {19.5077,-0.919511,0.0337178} 9.41272,0.0337178        6
-0.809862 -0.791957          128          128.0 {3.74364,-0.647635,0.03125} 13.4274,0.03125        6
-0.791277 -0.772692          256          256.0 {20.3305,-0.838337,0.03125} 14.3292,0.03125        6
-0.770005 -0.748733          512          512.0 {4.25219,-0.657683,0.03125} 4.48797,0.03125        6
-0.757992 -0.745979         1024         1024.0 {24.6628,-0.907539,0.03125} 25.1656,0.03125        6
-0.748157 -0.738322         2048         2048.0 {6.26651,-0.717142,0.03125} 16.7096,0.03125        6
-0.741542 -0.734926         4096         4096.0 {11.2093,-0.838206,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 3

Starting simulation for: --cats 128 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.738828 -0.736113         8192         8192.0 {20.6363,-0.850365,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.739527
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=460; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=302; id=8, #l=147; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=280; id=15, #l=162; 
    n.a.     n.a.            1            1.0  unknown 1.17244e-06,6.40625        6
0.000000 0.000000            2            2.0 {1.17244e-06,-0.113876,6.40625} 0.00754917,6.40625        6
0.000000 0.000000            4            4.0 {0.00569065,-0.452176,6.40625} 0.110469,6.40625        6
0.000000 0.000000            8            8.0 {10.3501,-0.447332,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.12135,-0.533079,6.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00468855,-0.165861,6.40625} 0.0776277,6.40625        6
0.000000 0.000000           64           64.0 {0.102674,-0.516463,6.40625} 0.0495416,6.40625        6
0.000000 0.000000          128          128.0 {0.0182616,-0.202498,6.40625} 0.0654997,6.40625        6
0.000000 0.000000          256          256.0 {0.099173,-0.449983,6.40625} 0.0698985,6.40625        6
0.000000 0.000000          512          512.0 {0.0207424,-0.464018,6.40625} 0.0218925,6.40625        6
0.000000 0.000000         1024         1024.0 {0.245184,-0.536432,6.40625} 0.247637,6.40625        6
0.000000 0.000000         2048         2048.0 {0.654959,-0.538483,6.40625} 0.705901,6.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 25

Starting simulation for: --cats 256 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {22.0332,-0.892791,6.40625} 22.076,6.40625        6
0.000000 0.000000         8192         8192.0 {25.4509,-0.898957,6.40625} 25.4797,6.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4045; id=1, #l=1917; id=2, #l=2136; id=3, #l=1912; id=4, #l=15; id=5, #l=1011; id=6, #l=1136; id=7, #l=1650; id=8, #l=269; id=9, #l=5; id=10, #l=20; id=11, #l=134; id=12, #l=885; id=13, #l=1135; id=14, #l=6; id=15, #l=1087; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-65.962639 -65.962639            2            2.0 {0.00120175,-0.489566,0.00625} 0.180583,0.40625        6
-32.981319 0.000000            4            4.0 {0.151276,-0.517195,0.40625} 1.80355,0.40625        6
-16.490660 0.000000            8            8.0 {10.3501,-0.474623,0.00625} 22.5925,0.00625        6
-8.276243 -0.061826           16           16.0 {1.97514,-0.553771,0.40625} 9.58582,0.00625        6
-4.178432 -0.080621           32           32.0 {0.135473,-0.530078,0.40625} 1.28567,0.40625        6
-2.237092 -0.295751           64           64.0 {21.3729,-0.871832,0.40625} 20.5351,0.40625        6
-1.435049 -0.633006          128          128.0 {18.7182,-0.744728,0.00625} 21.7713,0.40625        6
-0.927694 -0.420340          256          256.0 {21.5639,-0.860712,0.40625} 21.1022,0.40625        6
-0.719053 -0.510411          512          512.0 {21.0656,-0.790485,0.40625} 21.0837,0.40625        6
-0.602425 -0.485797         1024         1024.0 {23.1279,-0.837788,0.40625} 23.1666,0.40625        6
-0.875636 -1.148846         2048         2048.0 {20.2359,-0.926907,0.40625} 21.0392,0.40625        6
-0.843033 -0.810430         4096         4096.0 {19.2623,-0.875608,0.40625} 19.9373,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 0

Starting simulation for: --cats 256 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.821592 -0.800151         8192         8192.0 {19.9874,-0.892695,0.40625} 20.442,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.848035
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4093; id=1, #l=144; id=2, #l=3479; id=3, #l=211; id=4, #l=242; id=5, #l=3446; id=6, #l=1099; id=7, #l=146; id=8, #l=207; id=9, #l=226; id=10, #l=97; id=11, #l=769; id=12, #l=1928; id=13, #l=746; id=14, #l=111; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-34.640945 -34.640945            2            2.0 {0.00120175,-0.50067,0.00625} 0.295088,0.20625        6
-17.320473 0.000000            4            4.0 {0.237361,-0.481751,0.20625} 3.49184,0.20625        6
-8.660236 0.000000            8            8.0 {10.3501,-0.843056,0.00625} 22.5925,0.00625        6
-4.423340 -0.186443           16           16.0 {3.82982,-0.270748,0.20625} 9.58582,0.00625        6
-2.274624 -0.125909           32           32.0 {4.80576,-0.650378,0.00625} 19.9263,0.20625        6
-1.286176 -0.297727           64           64.0 {5.18912,-0.678844,0.20625} 3.53879,0.20625        6
-0.924102 -0.562029          128          128.0 {18.0824,-0.725239,0.20625} 19.5496,0.20625        6
-0.684474 -0.444846          256          256.0 {4.83795,-0.63298,0.20625} 3.92867,0.20625        6
-0.974681 -1.264887          512          512.0 {10.4018,-0.838998,0.20625} 10.4376,0.20625        6
-0.734089 -0.493496         1024         1024.0 {23.1913,-0.916098,0.20625} 23.2675,0.20625        6
-0.823277 -0.912465         2048         2048.0 {21.7374,-0.789698,0.20625} 23.3196,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 1

Starting simulation for: --cats 256 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.838841 -0.854405         4096         4096.0 {9.63777,-0.781874,0.20625} 10.9673,0.20625        6
-0.851955 -0.865069         8192         8192.0 {20.157,-0.928542,0.20625} 21.0524,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 2

Starting simulation for: --cats 256 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.844717
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4014; id=1, #l=1543; id=2, #l=2201; id=3, #l=362; id=4, #l=1054; id=5, #l=2495; id=6, #l=1050; id=7, #l=0; id=8, #l=249; id=9, #l=471; id=10, #l=979; id=11, #l=1141; id=12, #l=1489; id=13, #l=636; id=14, #l=0; id=15, #l=59; 
    n.a.     n.a.            1            1.0  unknown 2.80809e-05,0.267474        6
-0.604257 -0.604257            2            2.0 {2.80809e-05,-0.515174,0.267474} 0.180809,0.267474        6
-0.476274 -0.348292            4            4.0 {0.136296,-0.529843,0.267474} 2.64583,0.267474        6
-0.238137 0.000000            8            8.0 {10.35,-0.779672,0.00625} 22.5925,0.00625        6
-0.177846 -0.117555           16           16.0 {2.90644,-0.199939,0.267474} 9.58581,0.00625        6
-0.111814 -0.045781           32           32.0 {4.80576,-0.596297,0.00625} 12.2195,0.139583        6
-0.292192 -0.472570           64           64.0 {13.369,-0.863696,0.139583} 10.9305,0.139583        6
-0.457414 -0.622637          128          128.0 {18.7182,-0.91807,0.00625} 22.1703,0.139583        6
-0.606656 -0.755898          256          256.0 {24.671,-0.88821,0.139583} 23.3274,0.139583        6
-0.679989 -0.753322          512          512.0 {21.0714,-0.785991,0.139583} 21.1242,0.139583        6
-0.635460 -0.590932         1024         1024.0 {25.6409,-0.672596,0.139583} 25.7535,0.139583        6
-0.657666 -0.679872         2048         2048.0 {21.5224,-0.85928,0.139583} 23.8604,0.139583        6
-0.733656 -0.809645         4096         4096.0 {23.1066,-0.790504,0.139583} 25.0711,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.792492 -0.851329         8192         8192.0 {21.038,-0.840557,0.139583} 22.3611,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.796126
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3816; id=1, #l=1338; id=2, #l=1379; id=3, #l=249; id=4, #l=0; id=5, #l=1383; id=6, #l=1719; id=7, #l=75; id=8, #l=0; id=9, #l=393; id=10, #l=621; id=11, #l=915; id=12, #l=1121; id=13, #l=1148; id=14, #l=484; id=15, #l=33; 
    n.a.     n.a.            1            1.0  unknown 0.000196775,0.0381702        6
-0.510489 -0.510489            2            2.0 {0.000196775,-0.512711,0.0381702} 1.26701,0.0381702        6
-0.482591 -0.454694            4            4.0 {0.955083,-0.555385,0.0381702} 18.5404,0.0381702        6
-0.551787 -0.620983            8            8.0 {22.6535,-0.763597,0.0381702} 24.6581,0.0381702        6
-0.983499 -1.415211           16           16.0 {20.3667,-0.85811,0.0381702} 22.5283,0.0381702        6
-0.764354 -0.545210           32           32.0 {0.786897,-0.50084,0.0381702} 13.0286,0.0381702        6
-0.791313 -0.818271           64           64.0 {19.4736,-0.884217,0.0337769} 9.39625,0.0337769        6
-0.765744 -0.740176          128          128.0 {3.74364,-0.55794,0.03125} 13.4274,0.03125        6
-0.768001 -0.770259          256          256.0 {20.3305,-0.843945,0.03125} 14.3292,0.03125        6
-0.752800 -0.737599          512          512.0 {4.25219,-0.319006,0.03125} 4.48797,0.03125        6
-0.745914 -0.739027         1024         1024.0 {24.6628,-0.700016,0.03125} 25.1656,0.03125        6
-0.742552 -0.739190         2048         2048.0 {6.26651,-0.662457,0.03125} 16.7096,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 3

Starting simulation for: --cats 256 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.737779 -0.733007         4096         4096.0 {11.2093,-0.84568,0.03125} 19.9844,0.03125        6
-0.736373 -0.734966         8192         8192.0 {20.6363,-0.859957,0.03125} 26.546,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 25

Starting simulation for: --cats 512 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.735888
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=461; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=302; id=8, #l=148; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=280; id=15, #l=162; 
    n.a.     n.a.            1            1.0  unknown 5.86506e-07,12.8063        6
0.000000 0.000000            2            2.0 {5.86506e-07,-0.523118,12.8063} 0.00377643,12.8063        6
0.000000 0.000000            4            4.0 {0.00284671,-0.478164,12.8063} 0.0552615,12.8063        6
0.000000 0.000000            8            8.0 {10.3501,-0.785257,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0607047,-0.458985,12.8063} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00234542,-0.499124,12.8063} 0.0388328,12.8063        6
0.000000 0.000000           64           64.0 {0.0513621,-0.469883,12.8063} 0.0247829,12.8063        6
0.000000 0.000000          128          128.0 {0.00913528,-0.517435,12.8063} 0.0327658,12.8063        6
0.000000 0.000000          256          256.0 {0.0496107,-0.47704,12.8063} 0.0349663,12.8063        6
0.000000 0.000000          512          512.0 {0.0103763,-0.519995,12.8063} 0.0109516,12.8063        6
0.000000 0.000000         1024         1024.0 {0.0601825,-0.165883,12.8063} 0.0614093,12.8063        6
0.000000 0.000000         2048         2048.0 {0.140231,-0.483252,12.8063} 0.165714,12.8063        6
0.000000 0.000000         4096         4096.0 {2.52613,-0.561487,12.8063} 2.54755,12.8063        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {13.6687,-0.623073,12.8063} 13.6831,12.8063        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4028; id=1, #l=4031; id=2, #l=2; id=3, #l=2597; id=4, #l=1436; id=5, #l=4; id=6, #l=2; id=7, #l=2587; id=8, #l=14; id=9, #l=2; id=10, #l=1437; id=11, #l=8; id=12, #l=5; id=13, #l=5; id=14, #l=1; id=15, #l=1880; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-63.936001 -63.936001            2            2.0 {0.00120175,-0.462038,0.00625} 0.149814,0.40625        6
-31.968000 0.000000            4            4.0 {0.120506,-0.460871,0.40625} 1.77278,0.40625        6
-15.984000 0.000000            8            8.0 {10.3501,-0.796757,0.00625} 22.5925,0.00625        6
-8.022387 -0.060775           16           16.0 {1.94437,-0.580523,0.40625} 9.58582,0.00625        6
-4.048589 -0.074791           32           32.0 {3.05855,-0.563285,0.40625} 4.20875,0.40625        6
-2.255601 -0.462612           64           64.0 {1.64986,-0.507281,0.40625} 0.812003,0.40625        6
-1.359645 -0.463688          128          128.0 {0.318741,-0.523093,0.40625} 1.06365,0.40625        6
-0.867410 -0.375175          256          256.0 {1.59465,-0.499022,0.40625} 1.13301,0.40625        6
-1.159648 -1.451887          512          512.0 {12.1732,-0.869042,0.40625} 12.1914,0.40625        6
-0.822921 -0.486194         1024         1024.0 {13.8048,-0.927673,0.40625} 13.8435,0.40625        6
-0.860174 -0.897427         2048         2048.0 {9.86666,-0.801547,0.40625} 10.67,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 0

Starting simulation for: --cats 512 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.744394 -0.628614         4096         4096.0 {16.2161,-0.995335,0.40625} 16.8911,0.40625        6
-0.805189 -0.865985         8192         8192.0 {15.8951,-0.972452,0.40625} 16.3497,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 1

Starting simulation for: --cats 512 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.852131
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3832; id=1, #l=2425; id=2, #l=1956; id=3, #l=198; id=4, #l=2380; id=5, #l=1072; id=6, #l=1069; id=7, #l=172; id=8, #l=153; id=9, #l=108; id=10, #l=1609; id=11, #l=771; id=12, #l=170; id=13, #l=800; id=14, #l=184; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-31.688307 -31.688307            2            2.0 {0.00120175,-0.451806,0.00625} 0.264785,0.20625        6
-15.844153 0.000000            4            4.0 {0.207058,-0.512925,0.20625} 3.46154,0.20625        6
-7.922077 0.000000            8            8.0 {10.3501,-0.444278,0.00625} 22.5925,0.00625        6
-4.061330 -0.200582           16           16.0 {3.79951,-0.248723,0.20625} 9.58582,0.00625        6
-2.104437 -0.147544           32           32.0 {0.175932,-0.502856,0.20625} 2.44147,0.20625        6
-1.209356 -0.314275           64           64.0 {5.15882,-0.68654,0.20625} 3.50849,0.20625        6
-0.832911 -0.456465          128          128.0 {2.53691,-0.224271,0.20625} 4.00416,0.20625        6
-0.845042 -0.857173          256          256.0 {5.05007,-0.368494,0.20625} 4.14079,0.20625        6
-1.050415 -1.255788          512          512.0 {12.3109,-0.488932,0.20625} 12.3467,0.20625        6
-0.903239 -0.756062         1024         1024.0 {16.6156,-0.984217,0.20625} 16.6917,0.20625        6
-0.888985 -0.874731         2048         2048.0 {12.6161,-0.85652,0.20625} 14.1984,0.20625        6
-0.892942 -0.896899         4096         4096.0 {21.5469,-0.812899,0.20625} 22.8764,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.871810 -0.850679         8192         8192.0 {26.3085,-0.990168,0.20625} 27.2039,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.868687
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4204; id=1, #l=570; id=2, #l=2712; id=3, #l=285; id=4, #l=354; id=5, #l=2705; id=6, #l=1932; id=7, #l=0; id=8, #l=157; id=9, #l=252; id=10, #l=98; id=11, #l=1300; id=12, #l=1913; id=13, #l=840; id=14, #l=0; id=15, #l=55; 
    n.a.     n.a.            1            1.0  unknown 2.7801e-05,0.270168        6
-0.542319 -0.542319            2            2.0 {2.7801e-05,-0.462444,0.270168} 0.179007,0.270168        6
-0.437999 -0.333678            4            4.0 {0.134937,-0.504271,0.270168} 2.61946,0.270168        6
-0.218999 0.000000            8            8.0 {10.3501,-0.516591,0.00625} 22.5925,0.00625        6
-0.172655 -0.126310           16           16.0 {2.87747,-0.552437,0.270168} 9.58582,0.00625        6
-0.187287 -0.201919           32           32.0 {4.80576,-0.589571,0.00625} 23.6523,0.139583        6
-0.793190 -1.399092           64           64.0 {13.3392,-0.900869,0.139583} 10.9006,0.139583        6
-0.683300 -0.573411          128          128.0 {17.1068,-0.978359,0.139583} 19.2748,0.139583        6
-0.713148 -0.742996          256          256.0 {23.6859,-0.812458,0.139583} 22.3424,0.139583        6
-0.797857 -0.882565          512          512.0 {12.8624,-0.887183,0.139583} 12.9152,0.139583        6
-0.676724 -0.555590         1024         1024.0 {17.1932,-0.977857,0.139583} 17.3057,0.139583        6
-0.762197 -0.847670         2048         2048.0 {21.8507,-0.810498,0.139583} 24.1887,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 2

Starting simulation for: --cats 512 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.729627 -0.697056         4096         4096.0 {22.9573,-0.763519,0.139583} 24.9219,0.139583        6
-0.771388 -0.813150         8192         8192.0 {22.441,-0.852461,0.139583} 23.764,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 3

Starting simulation for: --cats 512 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.771905
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3998; id=1, #l=1406; id=2, #l=1697; id=3, #l=206; id=4, #l=0; id=5, #l=1379; id=6, #l=1754; id=7, #l=70; id=8, #l=0; id=9, #l=443; id=10, #l=491; id=11, #l=1789; id=12, #l=557; id=13, #l=1445; id=14, #l=241; id=15, #l=31; 
    n.a.     n.a.            1            1.0  unknown 0.00019657,0.0382101        6
-0.468229 -0.468229            2            2.0 {0.00019657,-0.4702,0.0382101} 1.26568,0.0382101        6
-0.443658 -0.419086            4            4.0 {0.954087,-0.512425,0.0382101} 18.5211,0.0382101        6
-0.550807 -0.657957            8            8.0 {22.6299,-0.852045,0.0382101} 24.6323,0.0382101        6
-0.978482 -1.406157           16           16.0 {20.3454,-0.858493,0.0382101} 22.5049,0.0382101        6
-0.781102 -0.583722           32           32.0 {0.786076,-0.478653,0.0382101} 13.015,0.0382101        6
-0.817496 -0.853889           64           64.0 {19.4565,-0.95012,0.0338065} 9.38802,0.0338065        6
-0.816260 -0.815024          128          128.0 {3.74364,-0.579567,0.03125} 13.4274,0.03125        6
-0.785985 -0.755711          256          256.0 {20.3305,-0.892073,0.03125} 14.3292,0.03125        6
-0.779508 -0.773031          512          512.0 {4.25219,-0.589976,0.03125} 4.48797,0.03125        6
-0.757358 -0.735207         1024         1024.0 {24.6628,-0.778039,0.03125} 25.1656,0.03125        6
-0.747656 -0.737955         2048         2048.0 {6.26651,-0.710017,0.03125} 16.7096,0.03125        6
-0.742715 -0.737775         4096         4096.0 {11.2093,-0.452236,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.738561 -0.734406         8192         8192.0 {20.6363,-0.851144,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.739314
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=462; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=302; id=8, #l=149; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=280; id=15, #l=162; 
    n.a.     n.a.            1            1.0  unknown 2.93324e-07,25.6063        6
0.000000 0.000000            2            2.0 {2.93324e-07,-0.482018,25.6063} 0.00188867,25.6063        6
0.000000 0.000000            4            4.0 {0.0014237,-0.489648,25.6063} 0.0276375,25.6063        6
0.000000 0.000000            8            8.0 {10.3501,-0.849342,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0303598,-0.181436,25.6063} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00117299,-0.49202,25.6063} 0.0194211,25.6063        6
0.000000 0.000000           64           64.0 {0.0256873,-0.507802,25.6063} 0.0123945,25.6063        6
0.000000 0.000000          128          128.0 {0.00456875,-0.45283,25.6063} 0.0163869,25.6063        6
0.000000 0.000000          256          256.0 {0.0248114,-0.529913,25.6063} 0.0174874,25.6063        6
0.000000 0.000000          512          512.0 {0.0051894,-0.475992,25.6063} 0.00547714,25.6063        6
0.000000 0.000000         1024         1024.0 {0.0300986,-0.46732,25.6063} 0.0307122,25.6063        6
0.000000 0.000000         2048         2048.0 {0.00764769,-0.479249,25.6063} 0.0203925,25.6063        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 25

Starting simulation for: --cats 1024 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {1.26337,-0.181694,25.6063} 1.27408,25.6063        6
0.000000 0.000000         8192         8192.0 {0.0251847,-0.473039,25.6063} 4.73021,0.00625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4000; id=1, #l=3217; id=2, #l=785; id=3, #l=3217; id=4, #l=2; id=5, #l=784; id=6, #l=1; id=7, #l=3217; id=8, #l=1; id=9, #l=0; id=10, #l=3; id=11, #l=785; id=12, #l=2; id=13, #l=1; id=14, #l=1; id=15, #l=2868; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-66.983650 -66.983650            2            2.0 {0.00120175,-0.47752,0.00625} 0.134429,0.40625        6
-33.491825 0.000000            4            4.0 {0.105122,-0.468967,0.40625} 1.7574,0.40625        6
-16.745913 0.000000            8            8.0 {10.3501,-0.781602,0.00625} 22.5925,0.00625        6
-8.458253 -0.170593           16           16.0 {1.92898,-0.225113,0.40625} 9.58582,0.00625        6
-7.315871 -6.173489           32           32.0 {1.07393,-0.490646,0.40625} 2.22413,0.40625        6
-3.765703 -0.215536           64           64.0 {5.57294,-0.304657,0.40625} 4.73508,0.40625        6
-2.142575 -0.519446          128          128.0 {18.7182,-0.941993,0.00625} 20.7406,0.40625        6
-1.268974 -0.395373          256          256.0 {22.2562,-0.826592,0.40625} 21.7946,0.40625        6
-1.373584 -1.478195          512          512.0 {21.261,-0.838356,0.00625} 22.4398,0.00625        6
-1.051885 -0.730187         1024         1024.0 {30.9587,-0.895262,0.40625} 30.9974,0.40625        6
-0.971488 -0.891091         2048         2048.0 {15.6359,-0.995129,0.40625} 16.4392,0.40625        6
-0.864239 -0.756990         4096         4096.0 {16.0161,-0.970933,0.40625} 16.6911,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 0

Starting simulation for: --cats 1024 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.790994 -0.717750         8192         8192.0 {24.3413,-0.73906,0.40625} 24.7958,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.822999
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4029; id=1, #l=535; id=2, #l=3987; id=3, #l=164; id=4, #l=487; id=5, #l=2164; id=6, #l=1941; id=7, #l=139; id=8, #l=174; id=9, #l=107; id=10, #l=481; id=11, #l=976; id=12, #l=488; id=13, #l=916; id=14, #l=407; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-34.740707 -34.740707            2            2.0 {0.00120175,-0.485149,0.00625} 0.249633,0.20625        6
-17.370354 0.000000            4            4.0 {0.191906,-0.504964,0.20625} 3.44639,0.20625        6
-8.685177 0.000000            8            8.0 {10.3501,-0.84861,0.00625} 22.5925,0.00625        6
-4.444490 -0.203803           16           16.0 {3.78436,-0.311459,0.20625} 9.58583,0.00625        6
-2.236732 -0.028974           32           32.0 {2.10017,-0.511799,0.20625} 4.36571,0.20625        6
-1.265918 -0.295103           64           64.0 {5.14367,-0.368395,0.20625} 3.49334,0.20625        6
-1.244286 -1.222654          128          128.0 {18.0369,-0.682497,0.20625} 19.5042,0.20625        6
-0.831400 -0.418514          256          256.0 {20.5501,-0.760333,0.20625} 19.6408,0.20625        6
-0.770097 -0.708795          512          512.0 {18.114,-0.783043,0.20625} 18.1497,0.20625        6
-0.703749 -0.637401         1024         1024.0 {21.2065,-0.896354,0.20625} 21.2827,0.20625        6
-0.757784 -0.811819         2048         2048.0 {21.9343,-0.826636,0.20625} 23.5166,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 1

Starting simulation for: --cats 1024 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.827206 -0.896628         4096         4096.0 {22.6832,-0.842937,0.20625} 24.0128,0.20625        6
-0.832222 -0.837238         8192         8192.0 {22.1419,-0.842185,0.20625} 23.0373,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.837255
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4082; id=1, #l=1649; id=2, #l=2107; id=3, #l=317; id=4, #l=886; id=5, #l=2122; id=6, #l=970; id=7, #l=0; id=8, #l=241; id=9, #l=654; id=10, #l=591; id=11, #l=1250; id=12, #l=1191; id=13, #l=627; id=14, #l=0; id=15, #l=65; 
    n.a.     n.a.            1            1.0  unknown 2.7661e-05,0.271535        6
-0.178887 -0.178887            2            2.0 {2.7661e-05,-0.154071,0.271535} 0.178105,0.271535        6
-0.261643 -0.344400            4            4.0 {0.134258,-0.52457,0.271535} 2.60627,0.271535        6
-0.130822 0.000000            8            8.0 {10.3501,-0.850482,0.00625} 22.5925,0.00625        6
-0.224023 -0.317225           16           16.0 {14.1814,-0.635022,0.139583} 14.7725,0.139583        6
-0.257310 -0.290596           32           32.0 {0.110616,-0.465651,0.271535} 1.83145,0.271535        6
-0.397704 -0.538098           64           64.0 {23.8317,-0.84016,0.139583} 21.3931,0.139583        6
-0.523683 -0.649662          128          128.0 {18.7182,-0.772011,0.00625} 23.0808,0.139583        6
-0.479343 -0.435002          256          256.0 {24.6262,-0.710597,0.139583} 23.2827,0.139583        6
-0.582580 -0.685818          512          512.0 {21.0266,-0.843655,0.139583} 21.0794,0.139583        6
-0.615443 -0.648305         1024         1024.0 {15.0887,-0.968162,0.139583} 15.2012,0.139583        6
-0.714008 -0.812572         2048         2048.0 {18.3433,-0.713904,0.139583} 20.6813,0.139583        6
-0.714834 -0.715660         4096         4096.0 {19.2409,-0.703809,0.139583} 21.2055,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 2

Starting simulation for: --cats 1024 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.794673 -0.874513         8192         8192.0 {16.1872,-0.97934,0.139583} 17.5103,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.804244
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3335; id=1, #l=2287; id=2, #l=1946; id=3, #l=236; id=4, #l=0; id=5, #l=1144; id=6, #l=1041; id=7, #l=68; id=8, #l=0; id=9, #l=663; id=10, #l=1316; id=11, #l=1342; id=12, #l=1109; id=13, #l=898; id=14, #l=105; id=15, #l=31; 
    n.a.     n.a.            1            1.0  unknown 0.000196467,0.03823        6
-0.113592 -0.113592            2            2.0 {0.000196467,-0.114062,0.03823} 1.26502,0.03823        6
-0.269243 -0.424894            4            4.0 {0.953589,-0.519798,0.03823} 18.5114,0.03823        6
-0.486033 -0.702823            8            8.0 {22.618,-0.819295,0.03823} 24.6195,0.03823        6
-1.104560 -1.723087           16           16.0 {20.3348,-0.863672,0.03823} 22.4931,0.03823        6
-0.832595 -0.560629           32           32.0 {0.785665,-0.126859,0.03823} 13.0082,0.03823        6
-0.859621 -0.886647           64           64.0 {19.448,-0.900539,0.0338214} 9.3839,0.0338214        6
-0.814775 -0.769929          128          128.0 {3.74364,-0.609939,0.03125} 13.4274,0.03125        6
-0.792552 -0.770330          256          256.0 {20.3305,-0.83577,0.03125} 14.3292,0.03125        6
-0.770251 -0.747950          512          512.0 {4.25219,-0.260875,0.03125} 4.48797,0.03125        6
-0.755622 -0.740993         1024         1024.0 {24.6628,-0.967215,0.03125} 25.1656,0.03125        6
-0.751098 -0.746573         2048         2048.0 {6.26651,-0.719284,0.03125} 16.7096,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 3

Starting simulation for: --cats 1024 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.743471 -0.735845         4096         4096.0 {11.2093,-0.814451,0.03125} 19.9844,0.03125        6
-0.738275 -0.733078         8192         8192.0 {20.6363,-0.844573,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.738048
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 25

Starting simulation for: --cats 2048 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=463; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=302; id=8, #l=150; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=280; id=15, #l=162; 
    n.a.     n.a.            1            1.0  unknown 1.4668e-07,51.2062        6
0.000000 0.000000            2            2.0 {1.4668e-07,-0.214437,51.2062} 0.000944452,51.2062        6
0.000000 0.000000            4            4.0 {0.000711939,-0.495118,51.2062} 0.0138204,51.2062        6
0.000000 0.000000            8            8.0 {10.3501,-0.540492,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0151817,-0.439576,51.2062} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.000586569,-0.133288,51.2062} 0.00971176,51.2062        6
0.000000 0.000000           64           64.0 {0.0128452,-0.463791,51.2062} 0.006198,51.2062        6
0.000000 0.000000          128          128.0 {0.00228466,-0.211047,51.2062} 0.00819446,51.2062        6
0.000000 0.000000          256          256.0 {0.0124072,-0.466006,51.2062} 0.00874478,51.2062        6
0.000000 0.000000          512          512.0 {0.00259502,-0.48068,51.2062} 0.0027389,51.2062        6
0.000000 0.000000         1024         1024.0 {0.0150511,-0.507619,51.2062} 0.015358,51.2062        6
0.000000 0.000000         2048         2048.0 {0.00382431,-0.501283,51.2062} 0.0101975,51.2062        6
0.000000 0.000000         4096         4096.0 {16.7548,-0.978353,51.2062} 16.7602,51.2062        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {16.7605,-0.998073,51.2062} 16.7642,51.2062        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4011; id=1, #l=3218; id=2, #l=793; id=3, #l=3219; id=4, #l=0; id=5, #l=793; id=6, #l=1; id=7, #l=2600; id=8, #l=619; id=9, #l=0; id=10, #l=0; id=11, #l=794; id=12, #l=0; id=13, #l=0; id=14, #l=1; id=15, #l=2600; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-71.215225 -71.215225            2            2.0 {0.00120175,-0.504209,0.00625} 0.126737,0.40625        6
-35.607613 0.000000            4            4.0 {0.0974294,-0.188248,0.40625} 1.7497,0.40625        6
-17.803806 0.000000            8            8.0 {10.3501,-0.825688,0.00625} 22.5925,0.00625        6
-8.995194 -0.186582           16           16.0 {1.92129,-0.16529,0.40625} 9.58582,0.00625        6
-4.514102 -0.033010           32           32.0 {4.80576,-0.60734,0.00625} 19.9395,0.40625        6
-2.439089 -0.364076           64           64.0 {21.3191,-0.832735,0.40625} 20.4812,0.40625        6
-1.494823 -0.550558          128          128.0 {18.7182,-0.899035,0.00625} 20.7329,0.40625        6
-0.962686 -0.430548          256          256.0 {21.2639,-0.893758,0.40625} 20.8022,0.40625        6
-1.247674 -1.532663          512          512.0 {4.27325,-0.62691,0.40625} 4.29138,0.40625        6
-1.153578 -1.059482         1024         1024.0 {21.5971,-0.862992,0.40625} 21.6358,0.40625        6
-0.972813 -0.792048         2048         2048.0 {12.9513,-0.903943,0.40625} 13.7546,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 0

Starting simulation for: --cats 2048 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.848098 -0.723383         4096         4096.0 {24.8699,-0.774814,0.40625} 25.545,0.40625        6
-0.864032 -0.879965         8192         8192.0 {13.9028,-0.944352,0.40625} 14.3574,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 1

Starting simulation for: --cats 2048 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.840004
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4083; id=1, #l=940; id=2, #l=2781; id=3, #l=204; id=4, #l=849; id=5, #l=1203; id=6, #l=3135; id=7, #l=158; id=8, #l=151; id=9, #l=100; id=10, #l=422; id=11, #l=174; id=12, #l=1451; id=13, #l=2168; id=14, #l=86; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-31.533667 -31.533667            2            2.0 {0.00120175,-0.441902,0.00625} 0.242057,0.20625        6
-15.766833 0.000000            4            4.0 {0.184331,-0.116719,0.20625} 3.43881,0.20625        6
-7.883417 0.000000            8            8.0 {10.3501,-0.813918,0.00625} 22.5925,0.00625        6
-4.039070 -0.194724           16           16.0 {3.77679,-0.597934,0.20625} 9.58582,0.00625        6
-2.058677 -0.078283           32           32.0 {2.0926,-0.553935,0.20625} 4.35813,0.20625        6
-1.193332 -0.327987           64           64.0 {5.13609,-0.661143,0.20625} 3.48576,0.20625        6
-0.844784 -0.496237          128          128.0 {18.0293,-0.941982,0.20625} 19.4966,0.20625        6
-0.921367 -0.997949          256          256.0 {20.5425,-0.897362,0.20625} 19.6332,0.20625        6
-1.153804 -1.386240          512          512.0 {14.2428,-0.576552,0.20625} 14.2785,0.20625        6
-0.947186 -0.740568         1024         1024.0 {23.2595,-0.829501,0.20625} 23.3357,0.20625        6
-0.964709 -0.982231         2048         2048.0 {21.0783,-0.814862,0.20625} 22.6605,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.886641 -0.808574         4096         4096.0 {22.0241,-0.794113,0.20625} 23.3537,0.20625        6
-0.837971 -0.789301         8192         8192.0 {19.5282,-0.875821,0.20625} 20.4236,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.853578
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3954; id=1, #l=584; id=2, #l=2952; id=3, #l=282; id=4, #l=490; id=5, #l=3475; id=6, #l=1839; id=7, #l=0; id=8, #l=136; id=9, #l=191; id=10, #l=240; id=11, #l=813; id=12, #l=2044; id=13, #l=788; id=14, #l=0; id=15, #l=50; 
    n.a.     n.a.            1            1.0  unknown 2.7591e-05,0.272224        6
-0.535172 -0.535172            2            2.0 {2.7591e-05,-0.463238,0.272224} 0.177655,0.272224        6
-0.321678 -0.108185            4            4.0 {0.133918,-0.164969,0.272224} 2.59967,0.272224        6
-0.160839 0.000000            8            8.0 {10.35,-0.812759,0.00625} 22.5925,0.00625        6
-0.272886 -0.384933           16           16.0 {14.1739,-0.902641,0.139583} 14.765,0.139583        6
-0.257219 -0.241551           32           32.0 {0.110336,-0.100881,0.272224} 1.82681,0.272224        6
-0.375632 -0.494045           64           64.0 {20.9586,-0.854979,0.139583} 18.52,0.139583        6
-0.512680 -0.649728          128          128.0 {9.44261,-0.796123,0.139583} 11.6106,0.139583        6
-0.485112 -0.457544          256          256.0 {20.7979,-0.827791,0.139583} 19.4543,0.139583        6
-0.732411 -0.979711          512          512.0 {17.6759,-0.970062,0.139583} 17.7286,0.139583        6
-0.654956 -0.577500         1024         1024.0 {24.1558,-0.922921,0.139583} 24.2684,0.139583        6
-0.774735 -0.894513         2048         2048.0 {20.0373,-0.896794,0.139583} 22.3753,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 2

Starting simulation for: --cats 2048 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.771678 -0.768621         4096         4096.0 {21.1289,-0.849471,0.139583} 23.0935,0.139583        6
-0.819668 -0.867659         8192         8192.0 {22.9857,-0.757752,0.139583} 24.3088,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 3

Starting simulation for: --cats 2048 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.807067
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3855; id=1, #l=822; id=2, #l=1984; id=3, #l=231; id=4, #l=0; id=5, #l=1897; id=6, #l=2124; id=7, #l=76; id=8, #l=0; id=9, #l=169; id=10, #l=552; id=11, #l=1474; id=12, #l=1245; id=13, #l=1451; id=14, #l=208; id=15, #l=32; 
    n.a.     n.a.            1            1.0  unknown 0.000196416,0.03824        6
-0.462015 -0.462015            2            2.0 {0.000196416,-0.463908,0.03824} 1.26469,0.03824        6
-0.445874 -0.429733            4            4.0 {0.953339,-0.525856,0.03824} 18.5066,0.03824        6
-0.543606 -0.641339            8            8.0 {22.6121,-0.784761,0.03824} 24.613,0.03824        6
-0.998328 -1.453049           16           16.0 {20.3295,-0.872913,0.03824} 22.4872,0.03824        6
-0.774714 -0.551099           32           32.0 {0.78546,-0.503237,0.03824} 13.0048,0.03824        6
-0.784744 -0.794774           64           64.0 {19.4437,-0.91181,0.0338288} 9.38184,0.0338288        6
-0.800780 -0.816816          128          128.0 {3.74364,-0.334332,0.03125} 13.4274,0.03125        6
-0.779289 -0.757798          256          256.0 {20.3305,-0.8754,0.03125} 14.3292,0.03125        6
-0.762387 -0.745485          512          512.0 {4.25219,-0.602242,0.03125} 4.48797,0.03125        6
-0.745041 -0.727695         1024         1024.0 {24.6628,-0.707079,0.03125} 25.1656,0.03125        6
-0.745422 -0.745804         2048         2048.0 {6.26651,-0.702116,0.03125} 16.7096,0.03125        6
-0.740483 -0.735544         4096         4096.0 {11.2093,-0.495665,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.739720 -0.738957         8192         8192.0 {20.6363,-0.908406,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.738936
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 25

Plotting...
</pre></div>
</div>
<img alt="../_images/python_cats_35_99.png" src="../_images/python_cats_35_99.png" />
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "VowpalWabbit/vowpal_wabbit",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="off_policy_evaluation.html" title="previous page">Offline policy evaluation using the VW command line</a>
    <a class='right-next' id="next-link" href="python_classification.html" title="next page">Classification with Vowpal Wabbit</a>

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, John langford et al.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.4.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>