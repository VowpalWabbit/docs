
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Simulating a smart thermostat using CATS: a Contextual Bandit algorithm with a continuous action space &#8212; VowpalWabbit latest documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/basic.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nav.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".cell"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Classification with Vowpal Wabbit" href="python_classification.html" />
    <link rel="prev" title="Offline policy evaluation using the VW command line" href="off_policy_evaluation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <div class="navbar_container main_nav_container">
  <div class="container nav_wrapper">
    <div class="logo">
      <a href="https://vowpalwabbit.org/index.html">
        <?xml version="1.0" encoding="UTF-8"?>
<svg width="172px" height="30px" viewBox="0 0 172 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 57.1 (83088) - https://sketch.com -->
    <title>logo_vw_horiz_gray</title>
    <desc>Created with Sketch.</desc>
    <g id="Styles" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Desktop-Copy" transform="translate(-944.000000, -314.000000)">
            <g id="logo_vw_horiz_gray" transform="translate(941.000000, 314.000000)">
                <rect id="framework" x="0" y="0" width="175" height="30"></rect>
                <path d="M49.488,22 L46.59,22 L42.252,10.12 L44.88,10.12 L47.382,17.68 L48.066,20.02 L48.732,17.698 L51.252,10.12 L53.808,10.12 L49.488,22 Z M58.524,12.82 C59.9760073,12.82 61.106996,13.2339959 61.917,14.062 C62.7270041,14.8900041 63.132,16.0359927 63.132,17.5 C63.132,18.9640073 62.7270041,20.1099959 61.917,20.938 C61.106996,21.7660041 59.9760073,22.18 58.524,22.18 C57.0719927,22.18 55.9410041,21.7660041 55.131,20.938 C54.320996,20.1099959 53.916,18.9640073 53.916,17.5 C53.916,16.0359927 54.320996,14.8900041 55.131,14.062 C55.9410041,13.2339959 57.0719927,12.82 58.524,12.82 Z M58.524,14.656 C57.8279965,14.656 57.2970018,14.8929976 56.931,15.367 C56.5649982,15.8410024 56.382,16.5519953 56.382,17.5 C56.382,18.4480047 56.5649982,19.1589976 56.931,19.633 C57.2970018,20.1070024 57.8279965,20.344 58.524,20.344 C59.2200035,20.344 59.7509982,20.1070024 60.117,19.633 C60.4830018,19.1589976 60.666,18.4480047 60.666,17.5 C60.666,16.5519953 60.4830018,15.8410024 60.117,15.367 C59.7509982,14.8929976 59.2200035,14.656 58.524,14.656 Z M79.368,13 L76.506,22 L73.644,22 L71.682,15.646 L69.792,22 L66.948,22 L64.086,13 L66.696,13 L68.496,20.02 L70.512,13 L72.942,13 L74.958,20.02 L76.758,13 L79.368,13 Z M86.316,12.82 C87.516006,12.82 88.4579966,13.2309959 89.142,14.053 C89.8260034,14.8750041 90.168,16.0179927 90.168,17.482 C90.168,18.9580074 89.8260034,20.1099959 89.142,20.938 C88.4579966,21.7660041 87.516006,22.18 86.316,22.18 C85.6679968,22.18 85.1040024,22.0330015 84.624,21.739 C84.1439976,21.4449985 83.7660014,21.0400026 83.49,20.524 L83.49,25.78 L81.024,25.78 L81.024,13 L83.202,13 L83.292,14.782 C83.5560013,14.181997 83.9489974,13.7050018 84.471,13.351 C84.9930026,12.9969982 85.6079965,12.82 86.316,12.82 Z M85.578,20.29 C86.2500034,20.29 86.7719981,20.0500024 87.144,19.57 C87.5160019,19.0899976 87.702,18.4000045 87.702,17.5 C87.702,16.5999955 87.5160019,15.9100024 87.144,15.43 C86.7719981,14.9499976 86.2500034,14.71 85.578,14.71 C84.977997,14.71 84.4920019,14.9169979 84.12,15.331 C83.7479981,15.7450021 83.5380002,16.3359962 83.49,17.104 L83.49,17.896 C83.5380002,18.6520038 83.7479981,19.2399979 84.12,19.66 C84.4920019,20.0800021 84.977997,20.29 85.578,20.29 Z M100.518,20.506 C100.770001,20.506 100.973999,20.4820002 101.13,20.434 L100.95,21.928 C100.613998,22.0960008 100.224002,22.18 99.78,22.18 C98.6279942,22.18 97.9380011,21.7300045 97.71,20.83 C97.4459987,21.2740022 97.0380028,21.6099989 96.486,21.838 C95.9339972,22.0660011 95.2800038,22.18 94.524,22.18 C93.6479956,22.18 92.9640025,21.982002 92.472,21.586 C91.9799975,21.189998 91.734,20.6200037 91.734,19.876 C91.734,18.4119927 92.9039883,17.4640022 95.244,17.032 L97.404,16.618 L97.404,16.186 C97.404,15.7059976 97.2690014,15.3250014 96.999,15.043 C96.7289987,14.7609986 96.3540024,14.62 95.874,14.62 C95.3219972,14.62 94.8720017,14.7399988 94.524,14.98 C94.1759983,15.2200012 93.9360007,15.6099973 93.804,16.15 L91.842,15.322 C92.034001,14.5419961 92.4659966,13.9300022 93.138,13.486 C93.8100034,13.0419978 94.6859946,12.82 95.766,12.82 C97.0500064,12.82 98.0519964,13.0989972 98.772,13.657 C99.4920036,14.2150028 99.852,15.0399945 99.852,16.132 L99.852,19.822 C99.852,20.0620012 99.9059995,20.2359995 100.014,20.344 C100.122001,20.4520005 100.289999,20.506 100.518,20.506 Z M95.298,20.506 C95.8260026,20.506 96.3089978,20.3770013 96.747,20.119 C97.1850022,19.8609987 97.404,19.5100022 97.404,19.066 L97.404,18.13 L95.478,18.562 C95.069998,18.6580005 94.767001,18.7869992 94.569,18.949 C94.370999,19.1110008 94.272,19.3359986 94.272,19.624 C94.272,19.9120014 94.3619991,20.1309992 94.542,20.281 C94.7220009,20.4310007 94.9739984,20.506 95.298,20.506 Z M105.054,19.138 C105.054,19.5700022 105.116999,19.8699992 105.243,20.038 C105.369001,20.2060008 105.599998,20.29 105.936,20.29 C106.140001,20.29 106.316999,20.2750001 106.467,20.245 C106.617001,20.2149998 106.793999,20.1640004 106.998,20.092 L106.782,21.802 C106.589999,21.9220006 106.338002,22.0149997 106.026,22.081 C105.713998,22.1470003 105.408002,22.18 105.108,22.18 C104.231996,22.18 103.593002,21.9670021 103.191,21.541 C102.788998,21.1149979 102.588,20.4340047 102.588,19.498 L102.588,9.058 L105.054,9.058 L105.054,19.138 Z M118.482,22 L115.62,22 L112.164,10.12 L114.846,10.12 L117.15,20.038 L119.526,10.12 L121.902,10.12 L124.314,20.038 L126.618,10.12 L129.174,10.12 L125.718,22 L122.928,22 L121.272,15.52 L120.714,12.712 L120.678,12.712 L120.12,15.52 L118.482,22 Z M138.336,20.506 C138.588001,20.506 138.791999,20.4820002 138.948,20.434 L138.768,21.928 C138.431998,22.0960008 138.042002,22.18 137.598,22.18 C136.445994,22.18 135.756001,21.7300045 135.528,20.83 C135.263999,21.2740022 134.856003,21.6099989 134.304,21.838 C133.751997,22.0660011 133.098004,22.18 132.342,22.18 C131.465996,22.18 130.782002,21.982002 130.29,21.586 C129.797998,21.189998 129.552,20.6200037 129.552,19.876 C129.552,18.4119927 130.721988,17.4640022 133.062,17.032 L135.222,16.618 L135.222,16.186 C135.222,15.7059976 135.087001,15.3250014 134.817,15.043 C134.546999,14.7609986 134.172002,14.62 133.692,14.62 C133.139997,14.62 132.690002,14.7399988 132.342,14.98 C131.993998,15.2200012 131.754001,15.6099973 131.622,16.15 L129.66,15.322 C129.852001,14.5419961 130.283997,13.9300022 130.956,13.486 C131.628003,13.0419978 132.503995,12.82 133.584,12.82 C134.868006,12.82 135.869996,13.0989972 136.59,13.657 C137.310004,14.2150028 137.67,15.0399945 137.67,16.132 L137.67,19.822 C137.67,20.0620012 137.723999,20.2359995 137.832,20.344 C137.940001,20.4520005 138.107999,20.506 138.336,20.506 Z M133.116,20.506 C133.644003,20.506 134.126998,20.3770013 134.565,20.119 C135.003002,19.8609987 135.222,19.5100022 135.222,19.066 L135.222,18.13 L133.296,18.562 C132.887998,18.6580005 132.585001,18.7869992 132.387,18.949 C132.188999,19.1110008 132.09,19.3359986 132.09,19.624 C132.09,19.9120014 132.179999,20.1309992 132.36,20.281 C132.540001,20.4310007 132.791998,20.506 133.116,20.506 Z M145.734,12.82 C146.934006,12.82 147.875997,13.2339959 148.56,14.062 C149.244003,14.8900041 149.586,16.0419926 149.586,17.518 C149.586,18.9820073 149.244003,20.1249959 148.56,20.947 C147.875997,21.7690041 146.934006,22.18 145.734,22.18 C145.025996,22.18 144.411003,22.0030018 143.889,21.649 C143.366997,21.2949982 142.974001,20.818003 142.71,20.218 L142.62,22 L140.442,22 L140.442,9.058 L142.908,9.058 L142.908,14.476 C143.184001,13.9599974 143.561998,13.5550015 144.042,13.261 C144.522002,12.9669985 145.085997,12.82 145.734,12.82 Z M144.996,20.29 C145.668003,20.29 146.189998,20.0500024 146.562,19.57 C146.934002,19.0899976 147.12,18.4000045 147.12,17.5 C147.12,16.5999955 146.934002,15.9100024 146.562,15.43 C146.189998,14.9499976 145.668003,14.71 144.996,14.71 C144.395997,14.71 143.910002,14.9199979 143.538,15.34 C143.165998,15.7600021 142.956,16.3479962 142.908,17.104 L142.908,17.896 C142.956,18.6640038 143.165998,19.2549979 143.538,19.669 C143.910002,20.0830021 144.395997,20.29 144.996,20.29 Z M157.056,12.82 C158.256006,12.82 159.197997,13.2339959 159.882,14.062 C160.566003,14.8900041 160.908,16.0419926 160.908,17.518 C160.908,18.9820073 160.566003,20.1249959 159.882,20.947 C159.197997,21.7690041 158.256006,22.18 157.056,22.18 C156.347996,22.18 155.733003,22.0030018 155.211,21.649 C154.688997,21.2949982 154.296001,20.818003 154.032,20.218 L153.942,22 L151.764,22 L151.764,9.058 L154.23,9.058 L154.23,14.476 C154.506001,13.9599974 154.883998,13.5550015 155.364,13.261 C155.844002,12.9669985 156.407997,12.82 157.056,12.82 Z M156.318,20.29 C156.990003,20.29 157.511998,20.0500024 157.884,19.57 C158.256002,19.0899976 158.442,18.4000045 158.442,17.5 C158.442,16.5999955 158.256002,15.9100024 157.884,15.43 C157.511998,14.9499976 156.990003,14.71 156.318,14.71 C155.717997,14.71 155.232002,14.9199979 154.86,15.34 C154.487998,15.7600021 154.278,16.3479962 154.23,17.104 L154.23,17.896 C154.278,18.6640038 154.487998,19.2549979 154.86,19.669 C155.232002,20.0830021 155.717997,20.29 156.318,20.29 Z M164.328,11.704 C163.307995,11.704 162.798,11.2660044 162.798,10.39 C162.798,9.50199556 163.307995,9.058 164.328,9.058 C165.348005,9.058 165.858,9.50199556 165.858,10.39 C165.858,11.2660044 165.348005,11.704 164.328,11.704 Z M165.552,22 L163.086,22 L163.086,13 L165.552,13 L165.552,22 Z M174.336,21.442 C174.047999,21.6700011 173.685002,21.8499993 173.247,21.982 C172.808998,22.1140007 172.350002,22.18 171.87,22.18 C169.86599,22.18 168.864,21.2740091 168.864,19.462 L168.864,14.836 L167.226,14.836 L167.226,13 L168.864,13 L168.864,10.93 L171.33,10.246 L171.33,13 L174.246,13 L174.246,14.836 L171.33,14.836 L171.33,19.066 C171.33,19.8940041 171.743996,20.308 172.572,20.308 C173.100003,20.308 173.561998,20.1400017 173.958,19.804 L174.336,21.442 Z" id="VowpalWabbit" fill="#333333" fill-rule="nonzero"></path>
                <g id="logo_vw_color" transform="translate(3.000000, 0.000000)" fill="#2A3B93">
                    <path d="M27.9875518,16.6117194 C27.9875518,9.21947752 21.9666728,9.36035971 21.9666728,9.36035971 C21.3736977,6.15536974 20.3362508,3.5963294 19.3414955,1.96947553 C18.1790857,0.436543115 17.3241355,0 17.3241355,0 C16.2887633,0.700737156 15.7766231,3.93943024 15.7766231,3.93943024 C14.1726939,1.18184505 12.329851,1.05294263 12.329851,1.05294263 C9.93824094,8.37466357 17.0427696,11.1203489 17.0427696,11.1203489 C9.97542657,11.1203489 6.33307087,15.0400524 4.59284756,17.9877167 C4.0042614,19.0524794 3.60319929,20.0302689 3.35048069,20.7371557 L2.99801525,21.8605394 C1.89952322,21.2108361 0.011355398,21.1878349 0.011355398,21.1878349 C-0.278708419,29.2136474 5.0845596,28.0167877 5.0845596,28.0167877 C5.0845596,29.1432063 6.56177043,30 6.56177043,30 L18.0978518,30 C18.0978518,30 17.9248509,28.5478912 16.7183131,27.7616983 C16.5196972,27.4693917 16.4533057,27.212705 16.6897456,26.9422016 C17.354698,26.1816454 17.8296525,27.1798804 17.8296525,27.1798804 L18.3302221,27.8553801 C19.7539686,29.627988 20.7440159,29.9516816 21.1646284,30 L21.391732,30 C20.5763614,27.5009384 20.6054875,25.3190215 20.6054875,25.3190215 C20.4822802,22.1365535 22.8107704,19.2166024 22.8107704,19.2166024 C28.5084697,19.2166024 27.9875518,16.6117194 27.9875518,16.6117194" id="logo_rabbit"></path>
                </g>
            </g>
        </g>
    </g>
</svg>
      </a>
    </div>

    <div class="nav">
      <a href="https://vowpalwabbit.org/start.html">
        Get started
      </a>
      <a href="https://vowpalwabbit.org/features.html">
        Features
      </a>
      <a href="https://vowpalwabbit.org/tutorials.html">
        Tutorials
      </a>
      <a href="https://vowpalwabbit.org/blog.html">
        Blog
      </a>
      <a href="https://vowpalwabbit.org/research.html">
        Research
      </a>
      <div class="external_links">
        <a class="active" href="index.html">
          Doc
        </a>

        <a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki" target="_blank">
          Wiki
        </a>

        <a href="https://github.com/VowpalWabbit/vowpal_wabbit" target="_blank" class="github_link">
          <?xml version="1.0" encoding="UTF-8"?>
<svg width="30px" height="30px" viewBox="0 0 30 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 53 (72520) - https://sketchapp.com -->
    <title>GitHub</title>
    <desc>Created with Sketch.</desc>
    <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="HD_Desktop_header_Home" transform="translate(-1538.000000, -58.000000)" fill="#FFFFFF">
            <g id="Header">
                <path d="M1568,73.7951128 C1567.94603,74.2583723 1567.89891,74.7224863 1567.83682,75.1847206 C1567.56271,77.2238487 1566.86543,79.1138828 1565.7732,80.8526868 C1564.55268,82.7956941 1562.9969,84.4188114 1561.05088,85.6538569 C1560.03339,86.2996179 1558.94817,86.8066231 1557.80753,87.1895684 C1557.17559,87.4016322 1556.73848,87.0743943 1556.73531,86.4093237 C1556.72907,85.1020808 1556.73745,83.7947524 1556.73164,82.487424 C1556.72804,81.6908602 1556.64825,80.9063436 1556.21259,80.2087201 C1556.0855,80.0052003 1555.92463,79.8226135 1555.77393,79.6234512 C1556.35935,79.5140871 1556.9463,79.4362506 1557.51632,79.2916849 C1559.04696,78.9034423 1560.41543,78.2275208 1561.34791,76.8924242 C1562.03287,75.9115647 1562.34632,74.7851144 1562.48436,73.6108172 C1562.59169,72.6982249 1562.62222,71.7826422 1562.42971,70.8740656 C1562.23608,69.9599354 1561.84044,69.1418405 1561.22834,68.4359293 C1561.07756,68.2620575 1561.04763,68.1215929 1561.12221,67.896713 C1561.52468,66.6818314 1561.3562,65.491984 1560.9042,64.3262309 C1560.87829,64.2595017 1560.76574,64.1973008 1560.68569,64.1853391 C1560.15364,64.1058793 1559.65196,64.2559986 1559.18533,64.4761793 C1558.42904,64.8332361 1557.69764,65.242668 1556.9487,65.6159585 C1556.82229,65.6790137 1556.64782,65.7219904 1556.51706,65.6889249 C1554.16941,65.0964789 1551.82595,65.097077 1549.47805,65.6883268 C1549.34078,65.7228448 1549.14638,65.677134 1549.02331,65.5987849 C1548.07109,64.9919849 1547.06446,64.5120644 1545.97001,64.2236166 C1545.9511,64.218661 1545.93272,64.2115694 1545.91364,64.2077246 C1545.22551,64.0670892 1545.09971,64.1456947 1544.9036,64.8108506 C1544.58682,65.884755 1544.5296,66.9550708 1544.90668,68.0296587 C1544.93627,68.1139033 1544.90129,68.2616303 1544.8404,68.3306664 C1543.60397,69.7341156 1543.31096,71.3989279 1543.46559,73.1936101 C1543.55933,74.2817831 1543.81162,75.3262104 1544.29869,76.3083514 C1544.97176,77.6654063 1546.11181,78.4952066 1547.4926,78.982475 C1548.35956,79.2884382 1549.27852,79.4473579 1550.18824,79.6758264 C1550.19526,79.6319098 1550.20056,79.6666842 1550.18568,79.6820635 C1549.71726,80.1697591 1549.45556,80.755028 1549.34531,81.4170227 C1549.33137,81.5007546 1549.27365,81.6203716 1549.20685,81.6454912 C1548.16482,82.0372369 1547.11706,82.2433199 1546.08683,81.6149888 C1545.61867,81.3295314 1545.27683,80.9169382 1545.00101,80.4479541 C1544.56852,79.712395 1543.95864,79.179074 1543.13923,78.9361661 C1542.84434,78.8487602 1542.50823,78.8709748 1542.19359,78.8892591 C1541.97909,78.9018189 1541.90862,79.062362 1542.05256,79.2422147 C1542.18529,79.4077988 1542.32025,79.5950849 1542.4978,79.6971865 C1543.28625,80.1507913 1543.72798,80.8753286 1544.08881,81.6641173 C1544.30382,82.1341266 1544.48812,82.6140471 1544.88675,82.9753759 C1545.52169,83.5510755 1546.29115,83.7682658 1547.11612,83.8044072 C1547.81434,83.834995 1548.51496,83.8107298 1549.24722,83.8107298 C1549.24611,83.8009041 1549.26073,83.8742123 1549.26167,83.9476058 C1549.27211,84.7377616 1549.2828,85.5279173 1549.28844,86.3180731 C1549.294,87.0913115 1548.82935,87.4109452 1548.0952,87.1563319 C1544.28705,85.8355039 1541.4928,83.3342269 1539.62819,79.7992882 C1538.22405,77.1372118 1537.78027,74.2780237 1538.09739,71.2935795 C1538.4294,68.1688416 1539.66702,65.4337134 1541.73193,63.0872551 C1543.89022,60.6347648 1546.57714,59.0045559 1549.78825,58.3523869 C1554.45335,57.4048494 1558.71409,58.3562318 1562.44442,61.3515269 C1565.27245,63.6222848 1567.02271,66.5767393 1567.72914,70.1361141 C1567.83314,70.6605492 1567.87265,71.197715 1567.94398,71.7286436 C1567.95792,71.832625 1567.9811,71.9354102 1568,72.0387934 L1568,73.7951128 Z" id="GitHub"></path>
            </g>
        </g>
    </g>
</svg>
          <div>
            GitHub
          </div>
        </a>
      </div>
    </div>
  </div>
</div>
    <div class="navbar_container mobile_nav_container">
  <div class="container nav_wrapper">
    <div class="hamburger_icon">
      <?xml version="1.0" encoding="UTF-8"?>
<svg width="18px" height="16px" viewBox="0 0 18 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: sketchtool 57.1 (101010) - https://sketch.com -->
    <title>8049A6A1-2687-43E9-9B5D-E205E8F9E871</title>
    <desc>Created with sketchtool.</desc>
    <g id="Pages" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd" stroke-linecap="round">
        <g id="Mobile_home" transform="translate(-12.000000, -56.000000)" stroke="#FFFFFF" stroke-width="2">
            <g id="header">
                <g id="ui_header_mobile_dk" transform="translate(12.000000, 44.000000)">
                    <g id="icon_menu" transform="translate(1.000000, 12.500000)">
                        <g id="Line">
                            <path d="M16,0.5 L0,0.5"></path>
                            <path d="M16,7.5 L0,7.5"></path>
                            <path d="M16,14.5 L0,14.5"></path>
                        </g>
                    </g>
                </g>
            </g>
        </g>
    </g>
</svg>
    </div>
    <div class="logo">
      <a href="https://vowpalwabbit.org/index.html">
        <?xml version="1.0" encoding="UTF-8"?>
<svg width="172px" height="30px" viewBox="0 0 172 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 57.1 (83088) - https://sketch.com -->
    <title>logo_vw_horiz_gray</title>
    <desc>Created with Sketch.</desc>
    <g id="Styles" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="Desktop-Copy" transform="translate(-944.000000, -314.000000)">
            <g id="logo_vw_horiz_gray" transform="translate(941.000000, 314.000000)">
                <rect id="framework" x="0" y="0" width="175" height="30"></rect>
                <path d="M49.488,22 L46.59,22 L42.252,10.12 L44.88,10.12 L47.382,17.68 L48.066,20.02 L48.732,17.698 L51.252,10.12 L53.808,10.12 L49.488,22 Z M58.524,12.82 C59.9760073,12.82 61.106996,13.2339959 61.917,14.062 C62.7270041,14.8900041 63.132,16.0359927 63.132,17.5 C63.132,18.9640073 62.7270041,20.1099959 61.917,20.938 C61.106996,21.7660041 59.9760073,22.18 58.524,22.18 C57.0719927,22.18 55.9410041,21.7660041 55.131,20.938 C54.320996,20.1099959 53.916,18.9640073 53.916,17.5 C53.916,16.0359927 54.320996,14.8900041 55.131,14.062 C55.9410041,13.2339959 57.0719927,12.82 58.524,12.82 Z M58.524,14.656 C57.8279965,14.656 57.2970018,14.8929976 56.931,15.367 C56.5649982,15.8410024 56.382,16.5519953 56.382,17.5 C56.382,18.4480047 56.5649982,19.1589976 56.931,19.633 C57.2970018,20.1070024 57.8279965,20.344 58.524,20.344 C59.2200035,20.344 59.7509982,20.1070024 60.117,19.633 C60.4830018,19.1589976 60.666,18.4480047 60.666,17.5 C60.666,16.5519953 60.4830018,15.8410024 60.117,15.367 C59.7509982,14.8929976 59.2200035,14.656 58.524,14.656 Z M79.368,13 L76.506,22 L73.644,22 L71.682,15.646 L69.792,22 L66.948,22 L64.086,13 L66.696,13 L68.496,20.02 L70.512,13 L72.942,13 L74.958,20.02 L76.758,13 L79.368,13 Z M86.316,12.82 C87.516006,12.82 88.4579966,13.2309959 89.142,14.053 C89.8260034,14.8750041 90.168,16.0179927 90.168,17.482 C90.168,18.9580074 89.8260034,20.1099959 89.142,20.938 C88.4579966,21.7660041 87.516006,22.18 86.316,22.18 C85.6679968,22.18 85.1040024,22.0330015 84.624,21.739 C84.1439976,21.4449985 83.7660014,21.0400026 83.49,20.524 L83.49,25.78 L81.024,25.78 L81.024,13 L83.202,13 L83.292,14.782 C83.5560013,14.181997 83.9489974,13.7050018 84.471,13.351 C84.9930026,12.9969982 85.6079965,12.82 86.316,12.82 Z M85.578,20.29 C86.2500034,20.29 86.7719981,20.0500024 87.144,19.57 C87.5160019,19.0899976 87.702,18.4000045 87.702,17.5 C87.702,16.5999955 87.5160019,15.9100024 87.144,15.43 C86.7719981,14.9499976 86.2500034,14.71 85.578,14.71 C84.977997,14.71 84.4920019,14.9169979 84.12,15.331 C83.7479981,15.7450021 83.5380002,16.3359962 83.49,17.104 L83.49,17.896 C83.5380002,18.6520038 83.7479981,19.2399979 84.12,19.66 C84.4920019,20.0800021 84.977997,20.29 85.578,20.29 Z M100.518,20.506 C100.770001,20.506 100.973999,20.4820002 101.13,20.434 L100.95,21.928 C100.613998,22.0960008 100.224002,22.18 99.78,22.18 C98.6279942,22.18 97.9380011,21.7300045 97.71,20.83 C97.4459987,21.2740022 97.0380028,21.6099989 96.486,21.838 C95.9339972,22.0660011 95.2800038,22.18 94.524,22.18 C93.6479956,22.18 92.9640025,21.982002 92.472,21.586 C91.9799975,21.189998 91.734,20.6200037 91.734,19.876 C91.734,18.4119927 92.9039883,17.4640022 95.244,17.032 L97.404,16.618 L97.404,16.186 C97.404,15.7059976 97.2690014,15.3250014 96.999,15.043 C96.7289987,14.7609986 96.3540024,14.62 95.874,14.62 C95.3219972,14.62 94.8720017,14.7399988 94.524,14.98 C94.1759983,15.2200012 93.9360007,15.6099973 93.804,16.15 L91.842,15.322 C92.034001,14.5419961 92.4659966,13.9300022 93.138,13.486 C93.8100034,13.0419978 94.6859946,12.82 95.766,12.82 C97.0500064,12.82 98.0519964,13.0989972 98.772,13.657 C99.4920036,14.2150028 99.852,15.0399945 99.852,16.132 L99.852,19.822 C99.852,20.0620012 99.9059995,20.2359995 100.014,20.344 C100.122001,20.4520005 100.289999,20.506 100.518,20.506 Z M95.298,20.506 C95.8260026,20.506 96.3089978,20.3770013 96.747,20.119 C97.1850022,19.8609987 97.404,19.5100022 97.404,19.066 L97.404,18.13 L95.478,18.562 C95.069998,18.6580005 94.767001,18.7869992 94.569,18.949 C94.370999,19.1110008 94.272,19.3359986 94.272,19.624 C94.272,19.9120014 94.3619991,20.1309992 94.542,20.281 C94.7220009,20.4310007 94.9739984,20.506 95.298,20.506 Z M105.054,19.138 C105.054,19.5700022 105.116999,19.8699992 105.243,20.038 C105.369001,20.2060008 105.599998,20.29 105.936,20.29 C106.140001,20.29 106.316999,20.2750001 106.467,20.245 C106.617001,20.2149998 106.793999,20.1640004 106.998,20.092 L106.782,21.802 C106.589999,21.9220006 106.338002,22.0149997 106.026,22.081 C105.713998,22.1470003 105.408002,22.18 105.108,22.18 C104.231996,22.18 103.593002,21.9670021 103.191,21.541 C102.788998,21.1149979 102.588,20.4340047 102.588,19.498 L102.588,9.058 L105.054,9.058 L105.054,19.138 Z M118.482,22 L115.62,22 L112.164,10.12 L114.846,10.12 L117.15,20.038 L119.526,10.12 L121.902,10.12 L124.314,20.038 L126.618,10.12 L129.174,10.12 L125.718,22 L122.928,22 L121.272,15.52 L120.714,12.712 L120.678,12.712 L120.12,15.52 L118.482,22 Z M138.336,20.506 C138.588001,20.506 138.791999,20.4820002 138.948,20.434 L138.768,21.928 C138.431998,22.0960008 138.042002,22.18 137.598,22.18 C136.445994,22.18 135.756001,21.7300045 135.528,20.83 C135.263999,21.2740022 134.856003,21.6099989 134.304,21.838 C133.751997,22.0660011 133.098004,22.18 132.342,22.18 C131.465996,22.18 130.782002,21.982002 130.29,21.586 C129.797998,21.189998 129.552,20.6200037 129.552,19.876 C129.552,18.4119927 130.721988,17.4640022 133.062,17.032 L135.222,16.618 L135.222,16.186 C135.222,15.7059976 135.087001,15.3250014 134.817,15.043 C134.546999,14.7609986 134.172002,14.62 133.692,14.62 C133.139997,14.62 132.690002,14.7399988 132.342,14.98 C131.993998,15.2200012 131.754001,15.6099973 131.622,16.15 L129.66,15.322 C129.852001,14.5419961 130.283997,13.9300022 130.956,13.486 C131.628003,13.0419978 132.503995,12.82 133.584,12.82 C134.868006,12.82 135.869996,13.0989972 136.59,13.657 C137.310004,14.2150028 137.67,15.0399945 137.67,16.132 L137.67,19.822 C137.67,20.0620012 137.723999,20.2359995 137.832,20.344 C137.940001,20.4520005 138.107999,20.506 138.336,20.506 Z M133.116,20.506 C133.644003,20.506 134.126998,20.3770013 134.565,20.119 C135.003002,19.8609987 135.222,19.5100022 135.222,19.066 L135.222,18.13 L133.296,18.562 C132.887998,18.6580005 132.585001,18.7869992 132.387,18.949 C132.188999,19.1110008 132.09,19.3359986 132.09,19.624 C132.09,19.9120014 132.179999,20.1309992 132.36,20.281 C132.540001,20.4310007 132.791998,20.506 133.116,20.506 Z M145.734,12.82 C146.934006,12.82 147.875997,13.2339959 148.56,14.062 C149.244003,14.8900041 149.586,16.0419926 149.586,17.518 C149.586,18.9820073 149.244003,20.1249959 148.56,20.947 C147.875997,21.7690041 146.934006,22.18 145.734,22.18 C145.025996,22.18 144.411003,22.0030018 143.889,21.649 C143.366997,21.2949982 142.974001,20.818003 142.71,20.218 L142.62,22 L140.442,22 L140.442,9.058 L142.908,9.058 L142.908,14.476 C143.184001,13.9599974 143.561998,13.5550015 144.042,13.261 C144.522002,12.9669985 145.085997,12.82 145.734,12.82 Z M144.996,20.29 C145.668003,20.29 146.189998,20.0500024 146.562,19.57 C146.934002,19.0899976 147.12,18.4000045 147.12,17.5 C147.12,16.5999955 146.934002,15.9100024 146.562,15.43 C146.189998,14.9499976 145.668003,14.71 144.996,14.71 C144.395997,14.71 143.910002,14.9199979 143.538,15.34 C143.165998,15.7600021 142.956,16.3479962 142.908,17.104 L142.908,17.896 C142.956,18.6640038 143.165998,19.2549979 143.538,19.669 C143.910002,20.0830021 144.395997,20.29 144.996,20.29 Z M157.056,12.82 C158.256006,12.82 159.197997,13.2339959 159.882,14.062 C160.566003,14.8900041 160.908,16.0419926 160.908,17.518 C160.908,18.9820073 160.566003,20.1249959 159.882,20.947 C159.197997,21.7690041 158.256006,22.18 157.056,22.18 C156.347996,22.18 155.733003,22.0030018 155.211,21.649 C154.688997,21.2949982 154.296001,20.818003 154.032,20.218 L153.942,22 L151.764,22 L151.764,9.058 L154.23,9.058 L154.23,14.476 C154.506001,13.9599974 154.883998,13.5550015 155.364,13.261 C155.844002,12.9669985 156.407997,12.82 157.056,12.82 Z M156.318,20.29 C156.990003,20.29 157.511998,20.0500024 157.884,19.57 C158.256002,19.0899976 158.442,18.4000045 158.442,17.5 C158.442,16.5999955 158.256002,15.9100024 157.884,15.43 C157.511998,14.9499976 156.990003,14.71 156.318,14.71 C155.717997,14.71 155.232002,14.9199979 154.86,15.34 C154.487998,15.7600021 154.278,16.3479962 154.23,17.104 L154.23,17.896 C154.278,18.6640038 154.487998,19.2549979 154.86,19.669 C155.232002,20.0830021 155.717997,20.29 156.318,20.29 Z M164.328,11.704 C163.307995,11.704 162.798,11.2660044 162.798,10.39 C162.798,9.50199556 163.307995,9.058 164.328,9.058 C165.348005,9.058 165.858,9.50199556 165.858,10.39 C165.858,11.2660044 165.348005,11.704 164.328,11.704 Z M165.552,22 L163.086,22 L163.086,13 L165.552,13 L165.552,22 Z M174.336,21.442 C174.047999,21.6700011 173.685002,21.8499993 173.247,21.982 C172.808998,22.1140007 172.350002,22.18 171.87,22.18 C169.86599,22.18 168.864,21.2740091 168.864,19.462 L168.864,14.836 L167.226,14.836 L167.226,13 L168.864,13 L168.864,10.93 L171.33,10.246 L171.33,13 L174.246,13 L174.246,14.836 L171.33,14.836 L171.33,19.066 C171.33,19.8940041 171.743996,20.308 172.572,20.308 C173.100003,20.308 173.561998,20.1400017 173.958,19.804 L174.336,21.442 Z" id="VowpalWabbit" fill="#333333" fill-rule="nonzero"></path>
                <g id="logo_vw_color" transform="translate(3.000000, 0.000000)" fill="#2A3B93">
                    <path d="M27.9875518,16.6117194 C27.9875518,9.21947752 21.9666728,9.36035971 21.9666728,9.36035971 C21.3736977,6.15536974 20.3362508,3.5963294 19.3414955,1.96947553 C18.1790857,0.436543115 17.3241355,0 17.3241355,0 C16.2887633,0.700737156 15.7766231,3.93943024 15.7766231,3.93943024 C14.1726939,1.18184505 12.329851,1.05294263 12.329851,1.05294263 C9.93824094,8.37466357 17.0427696,11.1203489 17.0427696,11.1203489 C9.97542657,11.1203489 6.33307087,15.0400524 4.59284756,17.9877167 C4.0042614,19.0524794 3.60319929,20.0302689 3.35048069,20.7371557 L2.99801525,21.8605394 C1.89952322,21.2108361 0.011355398,21.1878349 0.011355398,21.1878349 C-0.278708419,29.2136474 5.0845596,28.0167877 5.0845596,28.0167877 C5.0845596,29.1432063 6.56177043,30 6.56177043,30 L18.0978518,30 C18.0978518,30 17.9248509,28.5478912 16.7183131,27.7616983 C16.5196972,27.4693917 16.4533057,27.212705 16.6897456,26.9422016 C17.354698,26.1816454 17.8296525,27.1798804 17.8296525,27.1798804 L18.3302221,27.8553801 C19.7539686,29.627988 20.7440159,29.9516816 21.1646284,30 L21.391732,30 C20.5763614,27.5009384 20.6054875,25.3190215 20.6054875,25.3190215 C20.4822802,22.1365535 22.8107704,19.2166024 22.8107704,19.2166024 C28.5084697,19.2166024 27.9875518,16.6117194 27.9875518,16.6117194" id="logo_rabbit"></path>
                </g>
            </g>
        </g>
    </g>
</svg>
      </a>
    </div>
  </div>
</div>

<div class="mobile_nav">
  <button type="button" class="go_back_button">
    <
  </button>

  <a href="https://vowpalwabbit.org/start.html">
    Get started
  </a>
  <a href="https://vowpalwabbit.org/features.html">
    Features
  </a>
  <a href="https://vowpalwabbit.org/tutorials.html">
    Tutorials
  </a>
  <a href="https://vowpalwabbit.org/blog.html">
    Blog
  </a>
  <a href="https://vowpalwabbit.org/research.html">
    Research
  </a>
  <div class="external_links">
    <a href="https://github.com/VowpalWabbit/vowpalwabbit.github.io/issues/new"
      target="_blank"
    >
      Feedback
    </a>

    <a class="active" href="index.html">
      Doc
    </a>

    <a href="https://github.com/VowpalWabbit/vowpal_wabbit/wiki" target="_blank">
      Wiki
    </a>

    <a href="https://github.com/VowpalWabbit/vowpal_wabbit" target="_blank" class="github_link">
      <?xml version="1.0" encoding="UTF-8"?>
<svg width="30px" height="30px" viewBox="0 0 30 30" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
    <!-- Generator: Sketch 53 (72520) - https://sketchapp.com -->
    <title>GitHub</title>
    <desc>Created with Sketch.</desc>
    <g id="Symbols" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
        <g id="HD_Desktop_header_Home" transform="translate(-1538.000000, -58.000000)" fill="#FFFFFF">
            <g id="Header">
                <path d="M1568,73.7951128 C1567.94603,74.2583723 1567.89891,74.7224863 1567.83682,75.1847206 C1567.56271,77.2238487 1566.86543,79.1138828 1565.7732,80.8526868 C1564.55268,82.7956941 1562.9969,84.4188114 1561.05088,85.6538569 C1560.03339,86.2996179 1558.94817,86.8066231 1557.80753,87.1895684 C1557.17559,87.4016322 1556.73848,87.0743943 1556.73531,86.4093237 C1556.72907,85.1020808 1556.73745,83.7947524 1556.73164,82.487424 C1556.72804,81.6908602 1556.64825,80.9063436 1556.21259,80.2087201 C1556.0855,80.0052003 1555.92463,79.8226135 1555.77393,79.6234512 C1556.35935,79.5140871 1556.9463,79.4362506 1557.51632,79.2916849 C1559.04696,78.9034423 1560.41543,78.2275208 1561.34791,76.8924242 C1562.03287,75.9115647 1562.34632,74.7851144 1562.48436,73.6108172 C1562.59169,72.6982249 1562.62222,71.7826422 1562.42971,70.8740656 C1562.23608,69.9599354 1561.84044,69.1418405 1561.22834,68.4359293 C1561.07756,68.2620575 1561.04763,68.1215929 1561.12221,67.896713 C1561.52468,66.6818314 1561.3562,65.491984 1560.9042,64.3262309 C1560.87829,64.2595017 1560.76574,64.1973008 1560.68569,64.1853391 C1560.15364,64.1058793 1559.65196,64.2559986 1559.18533,64.4761793 C1558.42904,64.8332361 1557.69764,65.242668 1556.9487,65.6159585 C1556.82229,65.6790137 1556.64782,65.7219904 1556.51706,65.6889249 C1554.16941,65.0964789 1551.82595,65.097077 1549.47805,65.6883268 C1549.34078,65.7228448 1549.14638,65.677134 1549.02331,65.5987849 C1548.07109,64.9919849 1547.06446,64.5120644 1545.97001,64.2236166 C1545.9511,64.218661 1545.93272,64.2115694 1545.91364,64.2077246 C1545.22551,64.0670892 1545.09971,64.1456947 1544.9036,64.8108506 C1544.58682,65.884755 1544.5296,66.9550708 1544.90668,68.0296587 C1544.93627,68.1139033 1544.90129,68.2616303 1544.8404,68.3306664 C1543.60397,69.7341156 1543.31096,71.3989279 1543.46559,73.1936101 C1543.55933,74.2817831 1543.81162,75.3262104 1544.29869,76.3083514 C1544.97176,77.6654063 1546.11181,78.4952066 1547.4926,78.982475 C1548.35956,79.2884382 1549.27852,79.4473579 1550.18824,79.6758264 C1550.19526,79.6319098 1550.20056,79.6666842 1550.18568,79.6820635 C1549.71726,80.1697591 1549.45556,80.755028 1549.34531,81.4170227 C1549.33137,81.5007546 1549.27365,81.6203716 1549.20685,81.6454912 C1548.16482,82.0372369 1547.11706,82.2433199 1546.08683,81.6149888 C1545.61867,81.3295314 1545.27683,80.9169382 1545.00101,80.4479541 C1544.56852,79.712395 1543.95864,79.179074 1543.13923,78.9361661 C1542.84434,78.8487602 1542.50823,78.8709748 1542.19359,78.8892591 C1541.97909,78.9018189 1541.90862,79.062362 1542.05256,79.2422147 C1542.18529,79.4077988 1542.32025,79.5950849 1542.4978,79.6971865 C1543.28625,80.1507913 1543.72798,80.8753286 1544.08881,81.6641173 C1544.30382,82.1341266 1544.48812,82.6140471 1544.88675,82.9753759 C1545.52169,83.5510755 1546.29115,83.7682658 1547.11612,83.8044072 C1547.81434,83.834995 1548.51496,83.8107298 1549.24722,83.8107298 C1549.24611,83.8009041 1549.26073,83.8742123 1549.26167,83.9476058 C1549.27211,84.7377616 1549.2828,85.5279173 1549.28844,86.3180731 C1549.294,87.0913115 1548.82935,87.4109452 1548.0952,87.1563319 C1544.28705,85.8355039 1541.4928,83.3342269 1539.62819,79.7992882 C1538.22405,77.1372118 1537.78027,74.2780237 1538.09739,71.2935795 C1538.4294,68.1688416 1539.66702,65.4337134 1541.73193,63.0872551 C1543.89022,60.6347648 1546.57714,59.0045559 1549.78825,58.3523869 C1554.45335,57.4048494 1558.71409,58.3562318 1562.44442,61.3515269 C1565.27245,63.6222848 1567.02271,66.5767393 1567.72914,70.1361141 C1567.83314,70.6605492 1567.87265,71.197715 1567.94398,71.7286436 C1567.95792,71.832625 1567.9811,71.9354102 1568,72.0387934 L1568,73.7951128 Z" id="GitHub"></path>
            </g>
        </g>
    </g>
</svg>

      <div>
        GitHub
      </div>
    </a>
  </div>
</div>

<script script type="text/javascript">
  $(".mobile_nav_container").on("click", ".hamburger_icon", (e) => {
    e.stopPropagation();
    $(".mobile_nav").addClass("open");
  });

  $('body').on("click", ".mobile_nav .go_back_button", () => {
    $(".mobile_nav").removeClass("open");
  });
</script>


    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><a href="https://vowpalwabbit.org/docs/">
  latest
</a>

<i class="fas fa-angle-down"></i>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Tutorials
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="cmd_first_steps.html">
     Command line tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cmd_linear_regression.html">
     Linear Regression Tutorial
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="off_policy_evaluation.html">
     Offline policy evaluation using the VW command line
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Simulating a smart thermostat using CATS: a Contextual Bandit algorithm with a continuous action space
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_classification.html">
     Classification with Vowpal Wabbit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_Contextual_bandits_and_Vowpal_Wabbit.html">
     Contextual bandits and Vowpal Wabbit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_Simulating_a_news_personalization_scenario_using_Contextual_Bandits.html">
     Simulating a news personalization scenario using Contextual Bandits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_first_steps.html">
     Basics with Python
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="python_slates.html">
     Slates
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="DFtoVW_tutorial.html">
     Using DFtoVW and exploring VW output
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../examples/index.html">
   Examples
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/basics.html">
     Python Basics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/contextual_bandit.html">
     Contextual Bandits
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/mini_vw.html">
     Mini VW
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/poisson_regression.html">
     Poisson Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/predict.html">
     Predict comparison
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/search_covington.html">
     Search - Covington
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/search_sequence_ldf.html">
     Search - Sequence LDF
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/search_sequence.html">
     Search - Sequence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../examples/search_speech_tagger.html">
     Search - Speech Tagger
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../reference/index.html">
   API Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/vowpalwabbit.pyvw.html">
     vowpalwabbit.pyvw
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/vowpalwabbit.sklearn.html">
     vowpalwabbit.sklearn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/vowpalwabbit.DFtoVW.html">
     vowpalwabbit.DFtoVW
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../reference/vowpalwabbit.pyvw.pylibvw.html">
     vowpalwabbit.pyvw.pylibvw
    </a>
   </li>
  </ul>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-reward">
   Simulate reward
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#getting-a-decision">
   Getting a decision
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulation-set-up">
   Simulation set up
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scenario-1">
   Scenario 1
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#with-learning">
     With Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#without-learning">
     Without Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parameter-sweep">
   Parameter sweep
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     With Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Without Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scenario-2">
   Scenario 2
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#living-room">
     Living Room
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#bedroom">
     Bedroom
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     With Learning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Without Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#scenario-3">
   Scenario 3
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#better-cost-function">
     Better cost function
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                

<div class="tocsection editthispage">
    <a href="https://github.com/VowpalWabbit/vowpal_wabbit/edit/master/python/docs/source/tutorials/python_cats.ipynb">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
    
    
    <button title="Activate interactive cells" class="thebelab-button thebe-launch-button" onclick="initThebe()">
        Make live
    </button>
    <a class="binder-button" href="https://mybinder.org/v2/gh/VowpalWabbit/vowpal_wabbit/master?filepath=python/docs/source/tutorials/python_cats.ipynb">
        <img class="binder-button-logo" src="https://mybinder.org/badge_logo.svg" alt="Binder">
    </a>
    

              <div>
                
  <div class="section" id="simulating-a-smart-thermostat-using-cats-a-contextual-bandit-algorithm-with-a-continuous-action-space">
<h1>Simulating a smart thermostat using CATS: a Contextual Bandit algorithm with a continuous action space<a class="headerlink" href="#simulating-a-smart-thermostat-using-cats-a-contextual-bandit-algorithm-with-a-continuous-action-space" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial we will simulate the scenario of personalizing a thermostat for a household with two rooms using Contextual Bandits in a continuous action space. The goal is to maximize user satisfaction with the thermostat quantified by measuring thermostat accuracy or reward (TR). The thermostat proposes a temperature and the user will either accept the temperature or adjust it to fit their needs.</p>
<p>Let’s recall that in a CB setting, a data point has four components,</p>
<ul class="simple">
<li><p>Context</p></li>
<li><p>Chosen Action</p></li>
<li><p>Probability of chosen action</p></li>
<li><p>Reward/cost for chosen action</p></li>
</ul>
<p>In our simulator we will need to generate a context, get an action/decision for the given context, and also simulate generating a reward.</p>
<p>The goal of the learning agent is to maximize the reward or to minimize the loss.</p>
<p>The thermostat tracks two rooms: ‘Living Room’ and ‘Bedroom’.
Each room will need temperature adjustment either in the morning or in the afternoon.
The context is therefore (room, time_of_day).</p>
<p>In a continuous range we can’t specify actions since there are infinite actions we can take across the continuous range. We do however provide the minimum value and the maximum value of the range. Here we will range between 0 degrees Celsius and 32 degrees Celsius using 1 degree increments which gives us a continuous range of 33 degrees.</p>
<p>The reward is measured using the absolute difference between the proposed temperature and the one that was actually set by the people living in the house.</p>
<p>Let’s first start with importing the necessary packages:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">vowpalwabbit</span> <span class="kn">import</span> <span class="n">pyvw</span>
<span class="kn">import</span> <span class="nn">pylibvw</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">json</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># VW minimizes loss/cost, therefore we will pass cost as -reward</span>
<span class="n">USER_LIKED_TEMPERATURE</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
<span class="n">USER_DISLIKED_TEMPERATURE</span> <span class="o">=</span> <span class="mf">0.0</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="simulate-reward">
<h2>Simulate reward<a class="headerlink" href="#simulate-reward" title="Permalink to this headline">¶</a></h2>
<p>In the real world we will have to learn the room temperature preferences as we observe the interactions between the proposed temperature for each room and the one selected by the people living in the house. Since this is a simulation we will have to define the preference profile for each room. The reward that we provide to the learner will follow this preference profile. Our hope is to see if the learner can take better and better decisions as we see more samples which in turn means we are maximizing the reward.</p>
<p>We will also modify the reward function in a few different ways and see if the CB learner picks up the changes. We will compare the TR with and without learning.</p>
<p>VW minimizes the cost, which is defined as -reward. Therefore, we will pass the cost associated to each chosen action to VW.</p>
<p>The reward function below specifies that we want the living room to be cold in the morning but warm in the afternoon. In reverse, we prefer the bedroom to be warm in the morning and cold in the afternoon. It looks dense but we are just simulating our hypothetical world in the format of the feedback the learner understands: cost. If the learner recommends a temperature that aligns with the reward function, we give a positive reward. Max reward is -1.0, min reward is 0 since VW learns in terms of cost, so we return a negative reward. In our simulated world this is the difference between the temperature recommended and the temperature chosen. If the difference is smaller than 5 degrees then we give a reward to the thermostat. This is a steep cost function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_cost</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">):</span>
    <span class="nb">range</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">max_value</span> <span class="o">-</span> <span class="n">min_value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Living Room&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">29</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Bedroom&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">29</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This function modifies (context, temperature (i.e. action), cost, probability) to VW friendly json format</span>
<span class="k">def</span> <span class="nf">to_vw_example_format</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cats_label</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">example_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">cats_label</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">chosen_temp</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">pdf_value</span> <span class="o">=</span> <span class="n">cats_label</span>
        <span class="n">example_dict</span><span class="p">[</span><span class="s1">&#39;_label_ca&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;action&#39;</span> <span class="p">:</span> <span class="n">chosen_temp</span><span class="p">,</span> <span class="s1">&#39;cost&#39;</span><span class="p">:</span> <span class="n">cost</span><span class="p">,</span> <span class="s1">&#39;pdf_value&#39;</span><span class="p">:</span> <span class="n">pdf_value</span><span class="p">}</span>
    <span class="n">example_dict</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;room=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]):</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;time_of_day=</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">])</span> <span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">example_dict</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="getting-a-decision">
<h2>Getting a decision<a class="headerlink" href="#getting-a-decision" title="Permalink to this headline">¶</a></h2>
<p>We call VW and get a predicted temperature and the value of the probability density function at that temperature. Since we are predicting over a continuous range VW will sample a pdf before returning the predicted value and the density of the pdf at that point. We are incorporating exploration into our strategy so the pdf will be more dense around the value that VW chooses to predict, and less dense in the rest of the continuous range. So it is more likely that VW will choose an action around the predicted value.</p>
<p>We have all of the information we need to choose a temperature for a specific room and time of day. To use VW to achieve this, we will do the following:</p>
<p>We convert our context into the json format we need.
We pass this example to VW and get the chosen action and the probability of chosing that action.
Finally we return the chosen temperature and the probability of choosing it (we are going to need the probability when we learn form this example)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict_temperature</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">context</span><span class="p">):</span>
    <span class="n">vw_text_example</span> <span class="o">=</span> <span class="n">to_vw_example_format</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">vw</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">vw_text_example</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="simulation-set-up">
<h2>Simulation set up<a class="headerlink" href="#simulation-set-up" title="Permalink to this headline">¶</a></h2>
<p>Now that we have done all of the setup work and know how to interact with VW, let’s simulate the world of our two rooms. The scenario is that the thermostat it turned on in each room and it has to propose a temperature. Remember that the reward function allows us to define the worlds reaction to what VW recommends.</p>
<p>We will choose between ‘Living Room’ and ‘Bedroom’ uniformly at random and also choose the time of day uniformly at random. We can think of this as tossing a coin to choose between the rooms (‘Living Room’ if heads and ‘Bedroom’ if tails) and another coin toss for choosing time of day.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rooms</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Living Room&#39;</span><span class="p">,</span> <span class="s1">&#39;Bedroom&#39;</span><span class="p">]</span>
<span class="n">times_of_day</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;morning&#39;</span><span class="p">,</span> <span class="s1">&#39;afternoon&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">choose_room</span><span class="p">(</span><span class="n">rooms</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">rooms</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">choose_time_of_day</span><span class="p">(</span><span class="n">times_of_day</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">times_of_day</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will instantiate a CB learner in VW and then simulate the thermostat interaction num_iterations number of times. In each interaction, we:</p>
<ol class="simple">
<li><p>Decide between ‘Living Room’ and ‘Bedroom’</p></li>
<li><p>Decide time of day</p></li>
<li><p>Pass context i.e. (room, time of day) to learner to get a temperature i.e. a value between min (0 degrees) and max (32 degrees) and probability of choosing that temperature</p></li>
<li><p>Receive reward i.e. see if the proposed temperature was adjusted or not, and by how much. Remember that cost is just negative reward.</p></li>
<li><p>Format context, action (temperature), probability, and reward into VW format</p></li>
<li><p>Learn from the example</p></li>
</ol>
<p>The above steps are repeatedly executed during our simulations, so we define the process in the run_simulation function. The cost function must be supplied as this is essentially us simulating how the world works.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">cost_function</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="n">reward_rate</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">hits</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">cost_sum</span> <span class="o">=</span> <span class="mf">0.</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="c1"># 1. In each simulation choose a room</span>
        <span class="n">room</span> <span class="o">=</span> <span class="n">choose_room</span><span class="p">(</span><span class="n">rooms</span><span class="p">)</span>
        <span class="c1"># 2. Choose time of day for a given room</span>
        <span class="n">time_of_day</span> <span class="o">=</span> <span class="n">choose_time_of_day</span><span class="p">(</span><span class="n">times_of_day</span><span class="p">)</span>
        <span class="c1"># 3. Pass context to vw to get a temperature</span>
        <span class="n">context</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;room&#39;</span><span class="p">:</span> <span class="n">room</span><span class="p">,</span> <span class="s1">&#39;time_of_day&#39;</span><span class="p">:</span> <span class="n">time_of_day</span><span class="p">}</span>
        <span class="n">temperature</span><span class="p">,</span> <span class="n">pdf_value</span> <span class="o">=</span> <span class="n">predict_temperature</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
        
        <span class="c1"># 4. Get cost of the action we chose</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">cost_function</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">cost</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="mf">0.75</span><span class="p">:</span> <span class="c1"># count something as a hit only if it has a high reward</span>
            <span class="n">hits</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">cost_sum</span> <span class="o">+=</span> <span class="n">cost</span>

        <span class="k">if</span> <span class="n">do_learn</span><span class="p">:</span>
            <span class="c1"># 5. Inform VW of what happened so we can learn from it</span>
            <span class="n">txt_ex</span> <span class="o">=</span> <span class="n">to_vw_example_format</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cats_label</span><span class="o">=</span><span class="p">(</span><span class="n">temperature</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">pdf_value</span><span class="p">))</span>
            <span class="n">vw_format</span> <span class="o">=</span> <span class="n">vw</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">txt_ex</span><span class="p">,</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="o">.</span><span class="n">lContinuous</span><span class="p">)</span>
            <span class="c1"># 6. Learn</span>
            <span class="n">vw</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">vw_format</span><span class="p">)</span>
            <span class="c1"># 7. Let VW know you&#39;re done with these objects</span>
            <span class="n">vw</span><span class="o">.</span><span class="n">finish_example</span><span class="p">(</span><span class="n">vw_format</span><span class="p">)</span>

        <span class="c1"># We negate this so that on the plot instead of minimizing cost, we are maximizing reward</span>
        <span class="n">reward_rate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">cost_sum</span><span class="o">/</span><span class="n">i</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">reward_rate</span><span class="p">,</span> <span class="n">hits</span>
</pre></div>
</div>
</div>
</div>
<p>We want to be able to visualize what is occurring, so we are going to plot the reward rate over each iteration of the simulation. If VW is showing temperatures the that are close to what the simulated world wants, the reward will be higher. Below is a little utility function to make showing the plot easier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_reward_rate</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">reward_rate</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">reward_rate</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;num_iterations&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;reward rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="scenario-1">
<h2>Scenario 1<a class="headerlink" href="#scenario-1" title="Permalink to this headline">¶</a></h2>
<p>We will use the first reward function get_cost and assume that the preferences for room temperatures do not change over time and see what happens to the smart thermostat as we learn. We will also see what happens when there is no learning. We will use the “no learning” case as our baseline to compare to.</p>
<p>We will be using the CATS algorithm which does tree based learning with smoothing. That means that we need to provide the number of actions (buckets/tree leaves) that the continuous range will be discretized into, and then we need to define the bandwidth which is the radius around the chosen discreet action that the algorithm will sample a temperature from with higher probability.</p>
<p>For example, in our current range of 32 degrees celsius if we select the number of actions to be 8 that means that the algorithm will initially predict an action from the centre of one of 8 buckets:</p>
<p><code class="docutils literal notranslate"><span class="pre">(0</span> <span class="pre">-</span> <span class="pre">2</span> <span class="pre">-</span> <span class="pre">4),</span> <span class="pre">(4</span> <span class="pre">-</span> <span class="pre">6</span> <span class="pre">-</span> <span class="pre">8),</span> <span class="pre">(8</span> <span class="pre">-</span> <span class="pre">10</span> <span class="pre">-</span> <span class="pre">12),</span> <span class="pre">(12</span> <span class="pre">-</span> <span class="pre">14</span> <span class="pre">-</span> <span class="pre">16),</span> <span class="pre">(16</span> <span class="pre">-</span> <span class="pre">18</span> <span class="pre">-</span> <span class="pre">20),</span> <span class="pre">(20</span> <span class="pre">-</span> <span class="pre">22</span> <span class="pre">-</span> <span class="pre">24),</span> <span class="pre">(24</span> <span class="pre">-</span> <span class="pre">26</span> <span class="pre">-</span> <span class="pre">28),</span> <span class="pre">(28</span> <span class="pre">-</span> <span class="pre">30</span> <span class="pre">-</span> <span class="pre">32)</span></code></p>
<p>Let’s say that for a given context, it selects the third bucket that starts from 8 degrees celsius, goes until 12 degrees celsius, and has a center of 10 degrees celsius. For a smoothing radius (bandwidth) of 1 the resulting probability density function (pdf) that VW will have to sample from will have a higher density around</p>
<p><code class="docutils literal notranslate"><span class="pre">[bucket_centre</span> <span class="pre">-</span> <span class="pre">bandwidth,</span> <span class="pre">bucket_centre</span> <span class="pre">+</span> <span class="pre">bandwidth]</span></code></p>
<p>i.e. [9, 11]. If bandwidth was bigger, for example 5 then we would have higher density (and therefore higher probability of selecting an action) in the range [5, 15], providing a smoothing range that spans the discretized buckets. The bandwidth is defined in terms of the continuous range (max_value - min_value)</p>
<div class="section" id="with-learning">
<h3>With Learning<a class="headerlink" href="#with-learning" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="n">num_actions</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Instantiate VW learner</span>
<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidth</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
<span class="n">ctr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
<span class="n">plot_reward_rate</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">ctr</span><span class="p">,</span> <span class="s1">&#39;reward rate with num_actions = 32 and bandwidth = 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.611352,0.40625        6
0.000000 0.000000            4            4.0 {0.582045,0,0.40625} 2.23432,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.40591,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.566242,0,0.40625} 1.71644,0.40625        6
0.000000 0.000000           64           64.0 {2.1114,0,0.40625} 1.27354,0.40625        6
0.000000 0.000000          128          128.0 {0.78028,0,0.40625} 1.52519,0.40625        6
0.000000 0.000000          256          256.0 {2.05619,0,0.40625} 1.59455,0.40625        6
0.000000 0.000000          512          512.0 {0.819399,0,0.40625} 0.837536,0.40625        6
-0.144231 -0.288462         1024         1024.0 {13.2202,-1,0.40625} 13.2589,0.40625        6
-0.431090 -0.717949         2048         2048.0 {16.7282,-1,0.40625} 17.5315,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.546675 -0.662260         4096         4096.0 {20.0623,0,0.40625} 20.7373,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.758914 -0.971154         8192         8192.0 {26.6951,-1,0.40625} 27.1497,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.780472
total feature number = 60000
</pre></div>
</div>
<img alt="../_images/python_cats_15_3.png" src="../_images/python_cats_15_3.png" />
</div>
</div>
</div>
<div class="section" id="without-learning">
<h3>Without Learning<a class="headerlink" href="#without-learning" title="Permalink to this headline">¶</a></h3>
<p>Let’s do the same but without learning. The reward rate never improves and just hovers around 0.5</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="n">num_actions</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Instantiate VW learner</span>
<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidth</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
<span class="n">ctr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
<span class="n">plot_reward_rate</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">ctr</span><span class="p">,</span> <span class="s1">&#39;click through rate with num_actions = 32 and bandwidth = 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3409; id=1, #l=485; id=2, #l=3329; id=3, #l=0; id=4, #l=381; id=5, #l=777; id=6, #l=1739; id=7, #l=0; id=8, #l=0; id=9, #l=133; id=10, #l=352; id=11, #l=1018; id=12, #l=891; id=13, #l=422; id=14, #l=249; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.611352,0.40625        6
    n.a.     n.a.            4            4.0  unknown 2.23432,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.71644,0.40625        6
    n.a.     n.a.           64           64.0  unknown 1.27354,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.52519,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.59455,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.837536,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.42812,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.77766,0.40625        6
    n.a.     n.a.         4096         4096.0  unknown 2.02957,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
</pre></div>
</div>
<img alt="../_images/python_cats_17_2.png" src="../_images/python_cats_17_2.png" />
</div>
</div>
</div>
</div>
<div class="section" id="parameter-sweep">
<h2>Parameter sweep<a class="headerlink" href="#parameter-sweep" title="Permalink to this headline">¶</a></h2>
<p>Next let’s do a parameter sweep for different values of <code class="docutils literal notranslate"><span class="pre">num_actions</span></code> and <code class="docutils literal notranslate"><span class="pre">bandwidth</span></code>. We will use the below function to help us plot the reward rates for different combinations of <code class="docutils literal notranslate"><span class="pre">num_actions</span></code> and <code class="docutils literal notranslate"><span class="pre">bandwidths</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_reward_sweep</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">actions</span><span class="p">,</span> <span class="n">bandwidths</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="n">n_actions</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span>
    <span class="n">n_bandwidths</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">bandwidths</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">n_bandwidths</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">bandwidths</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">bandwidths</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;NA&#39;</span><span class="p">)</span>
                <span class="k">continue</span>
            <span class="n">reward_rate</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="p">])][</span><span class="nb">str</span><span class="p">(</span><span class="n">bandwidths</span><span class="p">[</span><span class="n">j</span><span class="p">])]</span>
            <span class="n">hits_percentage</span> <span class="o">=</span> <span class="p">(</span><span class="n">hits</span><span class="o">/</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">))</span><span class="o">*</span><span class="mi">100</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_iterations</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">reward_rate</span><span class="p">)</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;hits </span><span class="si">{:.2f}</span><span class="s1">% TR </span><span class="si">{:.2f}</span><span class="s1">%&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">hits_percentage</span><span class="p">,</span> <span class="n">reward_rate</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
            <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;b: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidths</span><span class="p">[</span><span class="n">j</span><span class="o">%</span><span class="k">len</span>(bandwidths)]), fontsize=14)
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;k: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="o">%</span><span class="k">len</span>(actions)]), fontsize=14)

    <span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> <span class="s1">&#39;num_iterations&#39;</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.04</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;reward_rate&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="s1">&#39;vertical&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_figheight</span><span class="p">(</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">set_figwidth</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;#examples </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">))</span>

    <span class="c1"># Hide x labels and tick labels for top plots and y ticks for right plots.</span>
    <span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axs</span><span class="o">.</span><span class="n">flat</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">label_outer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="id1">
<h3>With Learning<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>We will try all the number of actions as powers of 2 from 8 until 2048. Since our continuous range stays the same (0-32) we are creating smaller range buckets as the number of actions grows. The number of actions needs to be a power of 2 as it represents the number of leaves that the internal binary tree will have. Small number of actions might result in coarser discretizaton leading to results similar to uniform random. On the other hand really large number of actions could mean that we need a lot more data in order to train all of the buckets.</p>
<p>We will also try all the combinaitons of the above action numbers with bandwidths ranging from 0 to 25. The smaller the bandwidth the smaller the smoothing range around the selected continuous value. Really large bandwidths will result in large smoothing ranges and could lead to results similar to uniform random.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># do parameter sweeping</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">]</span>
<span class="n">bandwidths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span>

<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="k">for</span> <span class="n">actions</span> <span class="ow">in</span> <span class="n">num_actions</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="n">bandwidths</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">bd</span> <span class="o">&gt;=</span> <span class="n">actions</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting simulation for: --cats </span><span class="si">{}</span><span class="s2"> --bandwidth </span><span class="si">{}</span><span class="s2"> --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
        <span class="n">rr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done with simulation for num_actions: </span><span class="si">{}</span><span class="s2"> and bandwidth: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)][</span><span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">rr</span><span class="p">,</span> <span class="n">hits</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Plotting...&quot;</span><span class="p">)</span>
<span class="n">plot_reward_sweep</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">bandwidths</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
0.000000 0.000000            2            2.0 {3.64167e-05,0,0.20625} 0.234482,0.20625        6
0.000000 0.000000            4            4.0 {0.176755,0,0.20625} 3.43124,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.76921,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.145629,0,0.20625} 2.41116,0.20625        6
0.000000 0.000000           64           64.0 {3.18912,0,0.20625} 1.53879,0.20625        6
0.000000 0.000000          128          128.0 {0.567218,0,0.20625} 2.03446,0.20625        6
0.000000 0.000000          256          256.0 {3.08037,0,0.20625} 2.17109,0.20625        6
0.000000 0.000000          512          512.0 {20.0382,0,0.20625} 20.0739,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting simulation for: --cats 8 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         1024         1024.0 {27.0095,-1,0.20625} 27.0857,0.20625        6
0.000000 0.000000         2048         2048.0 {24.2222,-1,0.20625} 25.8045,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {17.2135,-1,0.20625} 18.5431,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {18.6419,-1,0.20625} 19.5373,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3832; id=1, #l=1231; id=2, #l=2645; id=3, #l=0; id=4, #l=1243; id=5, #l=745; id=6, #l=1979; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 1.10366,0.40625        6
0.000000 0.000000            4            4.0 {1.07435,0,0.40625} 2.72663,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.89821,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {4.80576,0,0.00625} 21.9011,0.40625        6
-0.153846 -0.307692           64           64.0 {22.296,0,0.40625} 21.4582,0.40625        6
-0.307692 -0.461538          128          128.0 {18.7182,-1,0.00625} 21.7098,0.40625        6
-0.394231 -0.480769          256          256.0 {22.2408,0,0.40625} 21.7792,0.40625        6
-0.461538 -0.528846          512          512.0 {21.004,0,0.40625} 21.0222,0.40625        6
-0.627404 -0.793269         1024         1024.0 {30.451,-1,0.40625} 30.4897,0.40625        6
-0.688702 -0.750000         2048         2048.0 {29.0359,-1,0.40625} 29.8392,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 0

Starting simulation for: --cats 8 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.748197 -0.807692         4096         4096.0 {25.4776,-1,0.40625} 26.1526,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.830529 -0.912861         8192         8192.0 {18.3259,-1,0.40625} 18.7805,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.837169
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3943; id=1, #l=272; id=2, #l=3711; id=3, #l=0; id=4, #l=280; id=5, #l=2375; id=6, #l=1405; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
0.000000 0.000000            2            2.0 {3.64167e-05,0,0.20625} 0.234482,0.20625        6
0.000000 0.000000            4            4.0 {0.176755,0,0.20625} 3.43124,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.76921,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.145629,0,0.20625} 2.41116,0.20625        6
0.000000 0.000000           64           64.0 {3.18912,0,0.20625} 1.53879,0.20625        6
0.000000 0.000000          128          128.0 {0.567218,0,0.20625} 2.03446,0.20625        6
-0.312500 -0.625000          256          256.0 {3.08037,0,0.20625} 2.17109,0.20625        6
-0.397727 -0.482955          512          512.0 {21.261,-1,0.00625} 22.4398,0.00625        6
-0.383523 -0.369318         1024         1024.0 {23.1307,0,0.20625} 23.2069,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 1

Starting simulation for: --cats 8 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.477036 -0.570549         2048         2048.0 {12.5858,0,0.20625} 14.1681,0.20625        6
-0.625000 -0.772964         4096         4096.0 {13.3347,-1,0.20625} 14.6643,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.675308 -0.725616         8192         8192.0 {26.3994,-1,0.20625} 27.2949,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.695273
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3280; id=1, #l=1540; id=2, #l=1787; id=3, #l=0; id=4, #l=1551; id=5, #l=1058; id=6, #l=815; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 3.21214,0.139583        6
0.000000 0.000000            4            4.0 {3.12685,0,0.139583} 7.93571,0.139583        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {8.4351,0,0.139583} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {3.08085,0,0.139583} 6.42844,0.139583        6
0.000000 0.000000           64           64.0 {7.57796,0,0.139583} 5.13941,0.139583        6
-0.018657 -0.037313          128          128.0 {15.1665,-1,0.139583} 17.3345,0.139583        6
-0.218284 -0.417910          256          256.0 {26.5217,0,0.139583} 25.1782,0.139583        6
-0.492226 -0.766169          512          512.0 {21.261,-1,0.00625} 22.4398,0.00625        6
-0.591573 -0.690920         1024         1024.0 {27.4917,-1,0.139583} 27.6042,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 2

Starting simulation for: --cats 8 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.641325 -0.691076         2048         2048.0 {23.3731,-1,0.139583} 25.7111,0.139583        6
-0.692359 -0.743392         4096         4096.0 {24.4797,-1,0.139583} 26.4443,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.701046 -0.709733         8192         8192.0 {26.5902,-1,0.139583} 27.9133,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.715176
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2373; id=1, #l=1744; id=2, #l=2094; id=3, #l=0; id=4, #l=1388; id=5, #l=1774; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 9.31589e-06,0.80625        6
0.000000 0.000000            2            2.0 {9.31589e-06,0,0.80625} 0.0599837,0.80625        6
0.000000 0.000000            4            4.0 {0.0452164,0,0.80625} 0.877758,0.80625        6
0.000000 0.000000            8            8.0 {10.3501,-1,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.964217,0,0.80625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0372539,0,0.80625} 0.616809,0.80625        6
0.000000 0.000000           64           64.0 {0.815822,0,0.80625} 0.393645,0.80625        6
0.000000 0.000000          128          128.0 {0.145102,0,0.80625} 0.520443,0.80625        6
0.000000 0.000000          256          256.0 {0.788003,0,0.80625} 0.555395,0.80625        6
0.000000 0.000000          512          512.0 {0.164814,0,0.80625} 0.173952,0.80625        6
0.000000 0.000000         1024         1024.0 {28.7389,0,0.80625} 28.7584,0.80625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         2048         2048.0 {28.0258,-1,0.80625} 28.4306,0.80625        6
0.000000 0.000000         4096         4096.0 {14.3259,-1,0.80625} 14.6661,0.80625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {21.6371,-1,0.80625} 21.8661,0.80625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3460; id=1, #l=1051; id=2, #l=2418; id=3, #l=0; id=4, #l=1057; id=5, #l=1026; id=6, #l=1429; id=7, #l=0; id=8, #l=0; id=9, #l=7; id=10, #l=1073; id=11, #l=713; id=12, #l=344; id=13, #l=1114; id=14, #l=342; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.611352,0.40625        6
0.000000 0.000000            4            4.0 {0.582045,0,0.40625} 2.23432,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.40591,0,0.40625} 9.58582,0.00625        6
-0.076923 -0.153846           32           32.0 {4.80576,0,0.00625} 20.4241,0.40625        6
-0.192308 -0.307692           64           64.0 {20.8191,-1,0.40625} 19.9812,0.40625        6
-0.307692 -0.423077          128          128.0 {18.7182,0,0.00625} 20.2329,0.40625        6
-0.317308 -0.326923          256          256.0 {20.7639,-1,0.40625} 20.3022,0.40625        6
-0.336538 -0.355769          512          512.0 {19.5271,-1,0.40625} 19.5452,0.40625        6
-0.413462 -0.490385         1024         1024.0 {25.0356,-1,0.40625} 25.0743,0.40625        6
-0.574519 -0.735577         2048         2048.0 {19.682,-1,0.40625} 20.4854,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 0

Starting simulation for: --cats 32 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.644231 -0.713942         4096         4096.0 {17.1084,-1,0.40625} 17.7834,0.40625        6
-0.707933 -0.771635         8192         8192.0 {24.7259,-1,0.40625} 25.1805,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.744123
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3736; id=1, #l=404; id=2, #l=2718; id=3, #l=0; id=4, #l=365; id=5, #l=2111; id=6, #l=1882; id=7, #l=0; id=8, #l=0; id=9, #l=62; id=10, #l=222; id=11, #l=782; id=12, #l=1543; id=13, #l=1117; id=14, #l=99; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.71933,0.20625        6
0.000000 0.000000            4            4.0 {0.661603,0,0.20625} 3.91608,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {4.25406,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.630478,0,0.20625} 2.89601,0.20625        6
-0.037879 -0.075758           64           64.0 {21.1285,0,0.20625} 19.4782,0.20625        6
-0.284091 -0.530303          128          128.0 {18.5066,0,0.20625} 19.9739,0.20625        6
-0.587121 -0.890152          256          256.0 {21.9895,0,0.20625} 21.0802,0.20625        6
-0.473485 -0.359848          512          512.0 {20.5231,0,0.20625} 20.5588,0.20625        6
-0.490463 -0.507440         1024         1024.0 {30.4035,-1,0.20625} 30.4796,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 1

Starting simulation for: --cats 32 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.706406 -0.922349         2048         2048.0 {27.6161,-1,0.20625} 29.1984,0.20625        6
-0.721692 -0.736979         4096         4096.0 {21.5772,-1,0.20625} 22.9067,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.739634 -0.757576         8192         8192.0 {16.2176,-1,0.20625} 17.113,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.733666
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3626; id=1, #l=1472; id=2, #l=1513; id=3, #l=0; id=4, #l=1040; id=5, #l=1394; id=6, #l=1110; id=7, #l=0; id=8, #l=0; id=9, #l=412; id=10, #l=350; id=11, #l=1353; id=12, #l=661; id=13, #l=692; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.19857e-05,0.234821        6
0.000000 0.000000            2            2.0 {3.19857e-05,0,0.234821} 0.205952,0.234821        6
0.000000 0.000000            4            4.0 {0.155249,0,0.234821} 3.01375,0.234821        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.3106,0,0.234821} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.12791,0,0.234821} 2.11779,0.234821        6
0.000000 0.000000           64           64.0 {2.80109,0,0.234821} 1.35156,0.234821        6
0.000000 0.000000          128          128.0 {0.498203,0,0.234821} 1.78692,0.234821        6
0.000000 0.000000          256          256.0 {2.70558,0,0.234821} 1.90693,0.234821        6
-0.080381 -0.160763          512          512.0 {21.261,0,0.00625} 22.4398,0.00625        6
-0.328310 -0.576238         1024         1024.0 {27.9693,-1,0.139583} 28.0818,0.139583        6
-0.505629 -0.682949         2048         2048.0 {11.4328,0,0.139583} 13.7708,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 2

Starting simulation for: --cats 32 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.622310 -0.738990         4096         4096.0 {17.3155,-1,0.139583} 19.2801,0.139583        6
-0.660611 -0.698913 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>        8192         8192.0 {17.5156,-1,0.139583} 18.8387,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.667158
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2049; id=1, #l=1700; id=2, #l=2533; id=3, #l=5; id=4, #l=0; id=5, #l=1882; id=6, #l=522; id=7, #l=0; id=8, #l=0; id=9, #l=413; id=10, #l=588; id=11, #l=734; id=12, #l=1011; id=13, #l=459; id=14, #l=458; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000199639,0.0376226        6
0.000000 0.000000            2            2.0 {0.000199639,0,0.0376226} 1.28545,0.0376226        6
0.000000 0.000000            4            4.0 {0.968985,0,0.0376226} 18.8103,0.0376226        6
-0.210951 -0.421902            8            8.0 {22.9832,-1,0.0376226} 25.017,0.0376226        6
-0.520785 -0.830619           16           16.0 {20.6631,-1,0.0376226} 22.8563,0.0376226        6
-0.474422 -0.428060           32           32.0 {0.798351,0,0.0376226} 13.2182,0.0376226        6
-0.556231 -0.638039           64           64.0 {17.483,-1,0.0376226} 8.4358,0.0376226        6
-0.496866 -0.437502          128          128.0 {3.74364,0,0.03125} 13.4274,0.03125        6
-0.458247 -0.419627          256          256.0 {20.3305,0,0.03125} 14.3292,0.03125        6
-0.403721 -0.349195          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.364121 -0.324521         1024         1024.0 {24.6628,0,0.03125} 25.1656,0.03125        6
-0.336946 -0.309771         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.325465 -0.313983         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
-0.335443 -0.345420         8192         8192.0 {20.6363,0,0.03125} 26.546,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.333630
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=2; id=2, #l=0; id=3, #l=167; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=133; id=8, #l=38; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=82; 
    n.a.     n.a.            1            1.0  unknown 4.67607e-06,1.60625        6
0.000000 0.000000            2            2.0 {4.67607e-06,0,1.60625} 0.0301085,1.60625        6
0.000000 0.000000            4            4.0 {0.0226962,0,1.60625} 0.440587,1.60625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.483984,0,1.60625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0186995,0,1.60625} 0.309605,1.60625        6
0.000000 0.000000           64           64.0 {0.409498,0,1.60625} 0.197588,1.60625        6
0.000000 0.000000          128          128.0 {0.0728334,0,1.60625} 0.261234,1.60625        6
0.000000 0.000000          256          256.0 {0.395535,0,1.60625} 0.278778,1.60625        6
0.000000 0.000000          512          512.0 {0.0827275,0,1.60625} 0.0873145,1.60625        6
0.000000 0.000000         1024         1024.0 {0.479821,0,1.60625} 0.489602,1.60625        6
0.000000 0.000000         2048         2048.0 {0.121917,0,1.60625} 0.32509,1.60625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 25

Starting simulation for: --cats 64 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {17.1519,-1,1.60625} 17.3227,1.60625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {23.312,-1,1.60625} 23.427,1.60625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2211; id=1, #l=469; id=2, #l=1755; id=3, #l=0; id=4, #l=474; id=5, #l=1741; id=6, #l=24; id=7, #l=0; id=8, #l=0; id=9, #l=4; id=10, #l=474; id=11, #l=242; id=12, #l=1513; id=13, #l=26; id=14, #l=13; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.365198,0.40625        6
0.000000 0.000000            4            4.0 {0.335891,0,0.40625} 1.98817,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.15975,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.320089,0,0.40625} 1.47028,0.40625        6
0.000000 0.000000           64           64.0 {1.86525,0,0.40625} 1.02739,0.40625        6
0.000000 0.000000          128          128.0 {0.534126,0,0.40625} 1.27903,0.40625        6
0.000000 0.000000          256          256.0 {1.81004,0,0.40625} 1.3484,0.40625        6
-0.355769 -0.711538          512          512.0 {21.2502,0,0.40625} 21.2683,0.40625        6
-0.403846 -0.451923         1024         1024.0 {24.7894,-1,0.40625} 24.8281,0.40625        6
-0.460337 -0.516827         2048         2048.0 {21.8974,0,0.40625} 22.7007,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 0

Starting simulation for: --cats 64 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.513221 -0.566106         4096         4096.0 {25.7238,-1,0.40625} 26.3988,0.40625        6
-0.586839 -0.660457         8192         8192.0 {21.5259,0,0.40625} 21.9805,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.557785
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2725; id=1, #l=338; id=2, #l=2560; id=3, #l=0; id=4, #l=354; id=5, #l=1796; id=6, #l=941; id=7, #l=0; id=8, #l=0; id=9, #l=15; id=10, #l=343; id=11, #l=651; id=12, #l=1048; id=13, #l=339; id=14, #l=62; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.476906,0.20625        6
0.000000 0.000000            4            4.0 {0.419179,0,0.20625} 3.67366,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {4.01163,0,0.20625} 9.58583,0.00625        6
0.000000 0.000000           32           32.0 {4.80576,0,0.00625} 20.1081,0.20625        6
-0.189394 -0.378788           64           64.0 {20.8861,-1,0.20625} 19.2358,0.20625        6
-0.284091 -0.378788          128          128.0 {18.2642,-1,0.20625} 19.7314,0.20625        6
-0.303030 -0.321970          256          256.0 {20.7773,-1,0.20625} 19.8681,0.20625        6
-0.336174 -0.369318          512          512.0 {18.3412,0,0.20625} 18.377,0.20625        6
-0.381155 -0.426136         1024         1024.0 {28.2216,-1,0.20625} 28.2978,0.20625        6
-0.615496 -0.849836         2048         2048.0 {14.2828,-1,0.20625} 15.8651,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 1

Starting simulation for: --cats 64 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.670188 -0.724881         4096         4096.0 {13.5772,-1,0.20625} 14.9067,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.741516 -0.812843         8192         8192.0 {29.0661,-1,0.20625} 29.9615,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.752508
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3274; id=1, #l=1728; id=2, #l=2804; id=3, #l=0; id=4, #l=1391; id=5, #l=1253; id=6, #l=410; id=7, #l=0; id=8, #l=0; id=9, #l=367; id=10, #l=624; id=11, #l=787; id=12, #l=396; id=13, #l=720; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.97576e-05,0.252404        6
0.000000 0.000000            2            2.0 {2.97576e-05,0,0.252404} 0.191605,0.252404        6
0.000000 0.000000            4            4.0 {0.144434,0,0.252404} 2.80381,0.252404        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.07998,0,0.252404} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.119,0,0.252404} 1.97027,0.252404        6
-0.111940 -0.223881           64           64.0 {21.1899,-1,0.139583} 18.7514,0.139583        6
-0.223881 -0.335821          128          128.0 {17.3157,0,0.139583} 19.4838,0.139583        6
-0.469527 -0.715174          256          256.0 {20.5516,0,0.139583} 19.208,0.139583        6
-0.444652 -0.419776          512          512.0 {19.34,0,0.139583} 19.3928,0.139583        6
-0.500135 -0.555618         1024         1024.0 {27.7305,-1,0.139583} 27.843,0.139583        6
-0.709656 -0.919176         2048         2048.0 {15.4925,-1,0.139583} 17.8305,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 2

Starting simulation for: --cats 64 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.740990 -0.772325         4096         4096.0 {13.7334,-1,0.139583} 15.698,0.139583        6
-0.746796 -0.752602         8192         8192.0 {23.9634,-1,0.139583} 25.2864,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.727994
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2620; id=1, #l=1573; id=2, #l=1940; id=3, #l=0; id=4, #l=0; id=5, #l=1856; id=6, #l=1119; id=7, #l=0; id=8, #l=0; id=9, #l=458; id=10, #l=384; id=11, #l=837; id=12, #l=875; id=13, #l=480; id=14, #l=304; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000198004,0.0379332        6
0.000000 0.000000            2            2.0 {0.000198004,0,0.0379332} 1.27492,0.0379332        6
0.000000 0.000000            4            4.0 {0.961051,0,0.0379332} 18.6563,0.0379332        6
0.000000 0.000000            8            8.0 {22.795,0,0.0379332} 24.8121,0.0379332        6
-0.830954 -1.661909           16           16.0 {20.4939,-1,0.0379332} 22.6691,0.0379332        6
-0.518454 -0.205954           32           32.0 {0.791813,0,0.0379332} 13.11,0.0379332        6
-0.636227 -0.753999           64           64.0 {17.3399,-1,0.0379332} 8.36672,0.0379332        6
-0.409982 -0.183738          128          128.0 {3.08407,0,0.0379332} 11.0618,0.0379332        6
-0.380212 -0.350441          256          256.0 {18.9083,-1,0.0336004} 13.3268,0.0336004        6
-0.379381 -0.378550          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.358965 -0.338550         1024         1024.0 {24.6628,0,0.03125} 25.1656,0.03125        6
-0.350093 -0.341222         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 3

Starting simulation for: --cats 64 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.330093 -0.310092         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
-0.328347 -0.326600         8192         8192.0 {20.6363,-1,0.03125} 26.546,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.323023
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=147; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=129; id=8, #l=38; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=85; 
    n.a.     n.a.            1            1.0  unknown 2.34259e-06,3.20625        6
0.000000 0.000000            2            2.0 {2.34259e-06,0,3.20625} 0.0150836,3.20625        6
0.000000 0.000000            4            4.0 {0.0113702,0,3.20625} 0.220723,3.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.242464,0,3.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00936795,0,3.20625} 0.155104,3.20625        6
0.000000 0.000000           64           64.0 {0.205148,0,3.20625} 0.0989867,3.20625        6
0.000000 0.000000          128          128.0 {0.0364877,0,3.20625} 0.130872,3.20625        6
0.000000 0.000000          256          256.0 {0.198153,0,3.20625} 0.139661,3.20625        6
0.000000 0.000000          512          512.0 {0.0414444,0,3.20625} 0.0437424,3.20625        6
0.000000 0.000000         1024         1024.0 {0.240378,0,3.20625} 0.245278,3.20625        6
0.000000 0.000000         2048         2048.0 {0.0610771,0,3.20625} 0.162862,3.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 25

Starting simulation for: --cats 128 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {22.3159,-1,3.20625} 22.4014,3.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {30.1427,0,3.20625} 30.2003,3.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1948; id=1, #l=653; id=2, #l=1304; id=3, #l=0; id=4, #l=654; id=5, #l=789; id=6, #l=525; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=660; id=11, #l=356; id=12, #l=440; id=13, #l=7; id=14, #l=525; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.242121,0.40625        6
0.000000 0.000000            4            4.0 {0.212814,0,0.40625} 1.86509,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.03668,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.197012,0,0.40625} 1.34721,0.40625        6
0.000000 0.000000           64           64.0 {1.74217,0,0.40625} 0.904311,0.40625        6
0.000000 0.000000          128          128.0 {0.411049,0,0.40625} 1.15596,0.40625        6
0.000000 0.000000          256          256.0 {1.68696,0,0.40625} 1.22532,0.40625        6
-0.711538 -1.423077          512          512.0 {13.2502,0,0.40625} 13.2683,0.40625        6
-0.677885 -0.644231         1024         1024.0 {24.6664,-1,0.40625} 24.705,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 0

Starting simulation for: --cats 128 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.753606 -0.829327         2048         2048.0 {22.759,-1,0.40625} 23.5623,0.40625        6
-0.725361 -0.697115         4096         4096.0 {21.4161,0,0.40625} 22.0911,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.733774 -0.742188         8192         8192.0 {22.1413,0,0.40625} 22.5958,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.704985
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3395; id=1, #l=589; id=2, #l=2299; id=3, #l=0; id=4, #l=561; id=5, #l=2682; id=6, #l=721; id=7, #l=0; id=8, #l=0; id=9, #l=43; id=10, #l=163; id=11, #l=1015; id=12, #l=1166; id=13, #l=660; id=14, #l=25; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.355694,0.20625        6
0.000000 0.000000            4            4.0 {0.297967,0,0.20625} 3.55245,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.89042,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.266841,0,0.20625} 2.53238,0.20625        6
0.000000 0.000000           64           64.0 {3.31033,0,0.20625} 1.66001,0.20625        6
-0.018939 -0.037879          128          128.0 {18.143,-1,0.20625} 19.6102,0.20625        6
-0.189394 -0.359848          256          256.0 {20.6561,0,0.20625} 19.7468,0.20625        6
-0.506629 -0.823864          512          512.0 {21.261,-1,0.00625} 22.4398,0.00625        6
-0.506705 -0.506782         1024         1024.0 {21.3125,-1,0.20625} 21.3887,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 1

Starting simulation for: --cats 128 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.652782 -0.798859         2048         2048.0 {12.4646,-1,0.20625} 14.0469,0.20625        6
-0.731568 -0.810353         4096         4096.0 {14.9105,-1,0.20625} 16.2401,0.20625        6
-0.808492 -0.885417         8192         8192.0 {18.5207,-1,0.20625} 19.4161,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.806842
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3369; id=1, #l=798; id=2, #l=2877; id=3, #l=0; id=4, #l=656; id=5, #l=1542; id=6, #l=764; id=7, #l=0; id=8, #l=0; id=9, #l=186; id=10, #l=470; id=11, #l=838; id=12, #l=1081; id=13, #l=1144; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.86404e-05,0.26225        6
0.000000 0.000000            2            2.0 {2.86404e-05,0,0.26225} 0.184411,0.26225        6
0.000000 0.000000            4            4.0 {0.139011,0,0.26225} 2.69854,0.26225        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.96435,0,0.26225} 9.58582,0.00625        6
-0.074627 -0.149254           32           32.0 {4.80576,0,0.00625} 19.921,0.139583        6
-0.261194 -0.447761           64           64.0 {21.0705,-1,0.139583} 18.6319,0.139583        6
-0.317164 -0.373134          128          128.0 {17.1963,-1,0.139583} 19.3644,0.139583        6
-0.544154 -0.771144          256          256.0 {20.9098,0,0.139583} 19.5662,0.139583        6
-0.509950 -0.475746          512          512.0 {11.34,-1,0.139583} 11.3928,0.139583        6
-0.548601 -0.587252         1024         1024.0 {24.9842,-1,0.139583} 25.0968,0.139583        6
-0.629914 -0.711228         2048         2048.0 {15.8507,-1,0.139583} 18.1887,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 2

Starting simulation for: --cats 128 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.647344 -0.664774         4096         4096.0 {17.9125,-1,0.139583} 19.8771,0.139583        6
-0.670616 -0.693887         8192         8192.0 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{23.1275,-1,0.139583} 24.4506,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.690584
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3083; id=1, #l=1306; id=2, #l=2000; id=3, #l=9; id=4, #l=0; id=5, #l=1159; id=6, #l=769; id=7, #l=0; id=8, #l=0; id=9, #l=378; id=10, #l=516; id=11, #l=818; id=12, #l=905; id=13, #l=861; id=14, #l=385; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000197185,0.0380908        6
0.000000 0.000000            2            2.0 {0.000197185,0,0.0380908} 1.26965,0.0380908        6
0.000000 0.000000            4            4.0 {0.957074,0,0.0380908} 18.5791,0.0380908        6
-0.205102 -0.410204            8            8.0 {22.7007,-1,0.0380908} 24.7095,0.0380908        6
-0.830102 -1.455102           16           16.0 {20.4091,0,0.0380908} 22.5753,0.0380908        6
-0.575428 -0.320754           32           32.0 {0.788537,0,0.0380908} 13.0557,0.0380908        6
-0.567497 -0.559567           64           64.0 {19.5077,0,0.0337178} 9.41272,0.0337178        6
-0.556636 -0.545775          128          128.0 {3.74364,0,0.03125} 13.4274,0.03125        6
-0.427998 -0.299360          256          256.0 {20.3305,-1,0.03125} 14.3292,0.03125        6
-0.361611 -0.295223          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.357619 -0.353628         1024         1024.0 {24.6628,-1,0.03125} 25.1656,0.03125        6
-0.344830 -0.332041         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 3

Starting simulation for: --cats 128 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.327965 -0.311100         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
-0.326430 -0.324894         8192         8192.0 {20.6363,0,0.03125} 26.546,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.326476
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=165; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=132; id=8, #l=34; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=83; 
    n.a.     n.a.            1            1.0  unknown 1.17244e-06,6.40625        6
0.000000 0.000000            2            2.0 {1.17244e-06,0,6.40625} 0.00754917,6.40625        6
0.000000 0.000000            4            4.0 {0.00569065,0,6.40625} 0.110469,6.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.12135,0,6.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00468855,0,6.40625} 0.0776277,6.40625        6
0.000000 0.000000           64           64.0 {0.102674,0,6.40625} 0.0495416,6.40625        6
0.000000 0.000000          128          128.0 {0.0182616,0,6.40625} 0.0654997,6.40625        6
0.000000 0.000000          256          256.0 {0.099173,0,6.40625} 0.0698985,6.40625        6
0.000000 0.000000          512          512.0 {0.0207424,0,6.40625} 0.0218925,6.40625        6
0.000000 0.000000         1024         1024.0 {0.120306,0,6.40625} 0.122759,6.40625        6
0.000000 0.000000         2048         2048.0 {0.0305684,0,6.40625} 0.0815103,6.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 25

Starting simulation for: --cats 256 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {0.0546794,0,6.40625} 0.0974849,6.40625        6
0.000000 0.000000         8192         8192.0 {0.100665,0,6.40625} 4.73022,0.00625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=1; id=3, #l=0; id=4, #l=1; id=5, #l=2; id=6, #l=3; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=2; id=11, #l=3; id=12, #l=1; id=13, #l=2; id=14, #l=3; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.180583,0.40625        6
0.000000 0.000000            4            4.0 {0.151276,0,0.40625} 1.80355,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {1.97514,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.135473,0,0.40625} 1.28567,0.40625        6
0.000000 0.000000           64           64.0 {1.68063,0,0.40625} 0.842772,0.40625        6
0.000000 0.000000          128          128.0 {0.349511,0,0.40625} 1.09442,0.40625        6
-0.057692 -0.115385          256          256.0 {24.2716,-1,0.40625} 23.8099,0.40625        6
-0.197115 -0.336538          512          512.0 {21.261,0,0.00625} 22.4398,0.00625        6
-0.497596 -0.798077         1024         1024.0 {29.5279,0,0.40625} 29.5666,0.40625        6
-0.609375 -0.721154         2048         2048.0 {23.1897,-1,0.40625} 23.993,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 0

Starting simulation for: --cats 256 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.570313 -0.531250         4096         4096.0 {18.7699,-1,0.40625} 19.445,0.40625        6
-0.603666 -0.637019         8192         8192.0 {23.4336,-1,0.40625} 23.8882,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.581169
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3214; id=1, #l=336; id=2, #l=2857; id=3, #l=0; id=4, #l=353; id=5, #l=1890; id=6, #l=546; id=7, #l=0; id=8, #l=0; id=9, #l=27; id=10, #l=49; id=11, #l=999; id=12, #l=1417; id=13, #l=468; id=14, #l=207; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.295088,0.20625        6
0.000000 0.000000            4            4.0 {0.237361,0,0.20625} 3.49184,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.82982,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.206235,0,0.20625} 2.47177,0.20625        6
0.000000 0.000000           64           64.0 {3.24973,0,0.20625} 1.5994,0.20625        6
0.000000 0.000000          128          128.0 {0.627824,0,0.20625} 2.09507,0.20625        6
0.000000 0.000000          256          256.0 {3.14098,0,0.20625} 2.2317,0.20625        6
-0.132576 -0.265152          512          512.0 {21.261,0,0.00625} 22.4398,0.00625        6
-0.355114 -0.577652         1024         1024.0 {23.1913,-1,0.20625} 23.2675,0.20625        6
-0.507813 -0.660511         2048         2048.0 {20.2828,-1,0.20625} 21.8651,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 1

Starting simulation for: --cats 256 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.536813 -0.565814         4096         4096.0 {21.0317,0,0.20625} 22.3613,0.20625        6
-0.641898 -0.746983         8192         8192.0 {14.2176,-1,0.20625} 15.113,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.657685
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3120; id=1, #l=930; id=2, #l=1970; id=3, #l=0; id=4, #l=592; id=5, #l=1136; id=6, #l=758; id=7, #l=0; id=8, #l=0; id=9, #l=354; id=10, #l=269; id=11, #l=902; id=12, #l=874; id=13, #l=661; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.80809e-05,0.267474        6
0.000000 0.000000            2            2.0 {2.80809e-05,0,0.267474} 0.180809,0.267474        6
0.000000 0.000000            4            4.0 {0.136296,0,0.267474} 2.64583,0.267474        6
0.000000 0.000000            8            8.0 {10.35,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.90644,0,0.267474} 9.58581,0.00625        6
0.000000 0.000000           32           32.0 {4.80576,0,0.00625} 19.8613,0.139583        6
-0.186567 -0.373134           64           64.0 {21.0108,0,0.139583} 18.5722,0.139583        6
-0.354478 -0.522388          128          128.0 {17.1366,-1,0.139583} 19.3047,0.139583        6
-0.374302 -0.394127          256          256.0 {20.8501,-1,0.139583} 19.5065,0.139583        6
-0.417912 -0.461522          512          512.0 {21.261,0,0.00625} 22.4398,0.00625        6
-0.473307 -0.528703         1024         1024.0 {28.029,-1,0.139583} 28.1415,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 2

Starting simulation for: --cats 256 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.562034 -0.650761         2048         2048.0 {17.7015,-1,0.139583} 20.0395,0.139583        6
-0.613960 -0.665886         4096         4096.0 {12.9573,0,0.139583} 14.9219,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.676956 -0.739952         8192         8192.0 {27.9634,-1,0.139583} 29.2864,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.702358
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3116; id=1, #l=1628; id=2, #l=2029; id=3, #l=0; id=4, #l=0; id=5, #l=1677; id=6, #l=671; id=7, #l=0; id=8, #l=0; id=9, #l=577; id=10, #l=289; id=11, #l=621; id=12, #l=879; id=13, #l=613; id=14, #l=553; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196775,0.0381702        6
0.000000 0.000000            2            2.0 {0.000196775,0,0.0381702} 1.26701,0.0381702        6
0.000000 0.000000            4            4.0 {0.955083,0,0.0381702} 18.5404,0.0381702        6
-0.204675 -0.409351            8            8.0 {22.6535,-1,0.0381702} 24.6581,0.0381702        6
-0.307013 -0.409351           16           16.0 {20.3667,-1,0.0381702} 22.5283,0.0381702        6
-0.416015 -0.525017           32           32.0 {0.786897,0,0.0381702} 13.0286,0.0381702        6
-0.285855 -0.155695           64           64.0 {17.2322,0,0.0381702} 8.31476,0.0381702        6
-0.259685 -0.233515          128          128.0 {3.06492,0,0.0381702} 10.9931,0.0381702        6
-0.271818 -0.283952          256          256.0 {16.6446,0,0.0381702} 11.7313,0.0381702        6
-0.249244 -0.226669          512          512.0 {3.48128,0,0.0381702} 3.67431,0.0381702        6
-0.280039 -0.310834         1024         1024.0 {22.8177,0,0.0337769} 23.2829,0.0337769        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 3

Starting simulation for: --cats 256 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.305245 -0.330450         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.297064 -0.288883         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.302349 -0.307634         8192         8192.0 {20.6363,-1,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.308641
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=134; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=127; id=8, #l=37; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=86; 
    n.a.     n.a.            1            1.0  unknown 5.86506e-07,12.8063        6
0.000000 0.000000            2            2.0 {5.86506e-07,0,12.8063} 0.00377643,12.8063        6
0.000000 0.000000            4            4.0 {0.00284671,0,12.8063} 0.0552615,12.8063        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0607047,0,12.8063} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00234542,0,12.8063} 0.0388328,12.8063        6
0.000000 0.000000           64           64.0 {0.0513621,0,12.8063} 0.0247829,12.8063        6
0.000000 0.000000          128          128.0 {0.00913528,0,12.8063} 0.0327658,12.8063        6
0.000000 0.000000          256          256.0 {0.0496107,0,12.8063} 0.0349663,12.8063        6
0.000000 0.000000          512          512.0 {0.0103763,0,12.8063} 0.0109516,12.8063        6
0.000000 0.000000         1024         1024.0 {0.0601825,0,12.8063} 0.0614093,12.8063        6
0.000000 0.000000         2048         2048.0 {0.0152916,0,12.8063} 0.040775,12.8063        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 25

Starting simulation for: --cats 512 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {0.027353,0,12.8063} 0.0487662,12.8063        6
0.000000 0.000000         8192         8192.0 {0.0503571,0,12.8063} 4.73021,0.00625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 0

Starting simulation for: --cats 512 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=1; id=6, #l=3; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=1; id=12, #l=2; id=13, #l=2; id=14, #l=3; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.149814,0.40625        6
0.000000 0.000000            4            4.0 {0.120506,0,0.40625} 1.77278,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {1.94437,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.104704,0,0.40625} 1.2549,0.40625        6
0.000000 0.000000           64           64.0 {1.64986,0,0.40625} 0.812003,0.40625        6
-0.019231 -0.038462          128          128.0 {18.7182,0,0.00625} 20.756,0.40625        6
-0.134615 -0.250000          256          256.0 {21.287,0,0.40625} 20.8253,0.40625        6
-0.923077 -1.711538          512          512.0 {15.1271,-1,0.40625} 15.1452,0.40625        6
-0.668269 -0.413462         1024         1024.0 {21.6202,0,0.40625} 21.6589,0.40625        6
-0.608173 -0.548077         2048         2048.0 {14.482,-1,0.40625} 15.2854,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.674279 -0.740385         4096         4096.0 {14.2469,-1,0.40625} 14.9219,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.780048 -0.885817         8192         8192.0 {18.1105,-1,0.40625} 18.5651,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.809600
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3357; id=1, #l=435; id=2, #l=3087; id=3, #l=0; id=4, #l=462; id=5, #l=1326; id=6, #l=1456; id=7, #l=0; id=8, #l=0; id=9, #l=22; id=10, #l=413; id=11, #l=1108; id=12, #l=744; id=13, #l=190; id=14, #l=817; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.264785,0.20625        6
0.000000 0.000000            4            4.0 {0.207058,0,0.20625} 3.46154,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.79951,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.175932,0,0.20625} 2.44147,0.20625        6
0.000000 0.000000           64           64.0 {3.21943,0,0.20625} 1.5691,0.20625        6
-0.018939 -0.037879          128          128.0 {18.0521,0,0.20625} 19.5193,0.20625        6
-0.104167 -0.189394          256          256.0 {21.0501,0,0.20625} 20.1408,0.20625        6
-0.440341 -0.776515          512          512.0 {20.0685,0,0.20625} 20.1042,0.20625        6
-0.442708 -0.445076         1024         1024.0 {21.7065,0,0.20625} 21.7827,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 1

Starting simulation for: --cats 512 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.654368 -0.866028         2048         2048.0 {18.6161,-1,0.20625} 20.1984,0.20625        6
-0.638500 -0.622633         4096         4096.0 {21.1226,0,0.20625} 22.4522,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.665190 -0.691880         8192         8192.0 {20.854,-1,0.20625} 21.7494,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.674424
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3283; id=1, #l=677; id=2, #l=2880; id=3, #l=0; id=4, #l=353; id=5, #l=484; id=6, #l=314; id=7, #l=0; id=8, #l=0; id=9, #l=296; id=10, #l=237; id=11, #l=874; id=12, #l=567; id=13, #l=852; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7801e-05,0.270168        6
0.000000 0.000000            2            2.0 {2.7801e-05,0,0.270168} 0.179007,0.270168        6
0.000000 0.000000            4            4.0 {0.134937,0,0.270168} 2.61946,0.270168        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.87747,0,0.270168} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.111175,0,0.270168} 1.84072,0.270168        6
0.000000 0.000000           64           64.0 {2.43462,0,0.270168} 1.17474,0.270168        6
0.000000 0.000000          128          128.0 {0.433023,0,0.270168} 1.55314,0.270168        6
-0.055970 -0.111940          256          256.0 {13.1785,-1,0.139583} 11.8349,0.139583        6
-0.365916 -0.675862          512          512.0 {11.4893,0,0.139583} 11.5421,0.139583        6
-0.574724 -0.783532         1024         1024.0 {16.0588,-1,0.139583} 16.1714,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 2

Starting simulation for: --cats 512 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.598540 -0.622356         2048         2048.0 {20.4776,0,0.139583} 22.8156,0.139583        6
-0.613880 -0.629220         4096         4096.0 {25.9424,-1,0.139583} 27.907,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.725574 -0.837267         8192         8192.0 {28.1126,-1,0.139583} 29.4357,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.748167
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2764; id=1, #l=1675; id=2, #l=2205; id=3, #l=0; id=4, #l=0; id=5, #l=1744; id=6, #l=682; id=7, #l=0; id=8, #l=0; id=9, #l=554; id=10, #l=483; id=11, #l=923; id=12, #l=1062; id=13, #l=707; id=14, #l=439; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00019657,0.0382101        6
0.000000 0.000000            2            2.0 {0.00019657,0,0.0382101} 1.26568,0.0382101        6
0.000000 0.000000            4            4.0 {0.954087,0,0.0382101} 18.5211,0.0382101        6
-0.204462 -0.408924            8            8.0 {22.6299,-1,0.0382101} 24.6323,0.0382101        6
-0.408924 -0.613386           16           16.0 {20.3454,-1,0.0382101} 22.5049,0.0382101        6
-0.204462 0.000000           32           32.0 {0.786076,0,0.0382101} 13.015,0.0382101        6
-0.127789 -0.051115           64           64.0 {17.2142,0,0.0382101} 8.30609,0.0382101        6
-0.186719 -0.245648          128          128.0 {3.06173,0,0.0382101} 10.9816,0.0382101        6
-0.294864 -0.403009          256          256.0 {18.793,-1,0.0338065} 13.2456,0.0338065        6
-0.281704 -0.268545          512          512.0 {3.93063,0,0.0338065} 4.14858,0.0338065        6
-0.322927 -0.364149         1024         1024.0 {24.6628,0,0.03125} 25.1656,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 3

Starting simulation for: --cats 512 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.328876 -0.334826         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.328510 -0.328144         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.320426 -0.312341         8192         8192.0 {20.6363,-1,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.325336
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=137; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=157; id=8, #l=27; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=89; 
    n.a.     n.a.            1            1.0  unknown 2.93324e-07,25.6063        6
0.000000 0.000000            2            2.0 {2.93324e-07,0,25.6063} 0.00188867,25.6063        6
0.000000 0.000000            4            4.0 {0.0014237,0,25.6063} 0.0276375,25.6063        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0303598,0,25.6063} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00117299,0,25.6063} 0.0194211,25.6063        6
0.000000 0.000000           64           64.0 {0.0256873,0,25.6063} 0.0123945,25.6063        6
0.000000 0.000000          128          128.0 {0.00456875,0,25.6063} 0.0163869,25.6063        6
0.000000 0.000000          256          256.0 {0.0248114,0,25.6063} 0.0174874,25.6063        6
0.000000 0.000000          512          512.0 {0.0051894,0,25.6063} 0.00547714,25.6063        6
0.000000 0.000000         1024         1024.0 {0.0300986,0,25.6063} 0.0307122,25.6063        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 25

Starting simulation for: --cats 1024 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         2048         2048.0 {0.00764769,0,25.6063} 0.0203925,25.6063        6
0.000000 0.000000         4096         4096.0 {0.0136799,0,25.6063} 0.0243891,25.6063        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {0.0251847,0,25.6063} 4.73021,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=1; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=1; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.134429,0.40625        6
0.000000 0.000000            4            4.0 {0.105122,0,0.40625} 1.7574,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {1.92898,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0893194,0,0.40625} 1.23951,0.40625        6
0.000000 0.000000           64           64.0 {1.63448,0,0.40625} 0.796618,0.40625        6
0.000000 0.000000          128          128.0 {0.303357,0,0.40625} 1.04826,0.40625        6
0.000000 0.000000          256          256.0 {1.57927,0,0.40625} 1.11763,0.40625        6
-0.644231 -1.288462          512          512.0 {21.261,-1,0.00625} 22.4398,0.00625        6
-0.487981 -0.331731         1024         1024.0 {14.7125,-1,0.40625} 14.7512,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 0

Starting simulation for: --cats 1024 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.546875 -0.605769         2048         2048.0 {13.2974,-1,0.40625} 14.1007,0.40625        6
-0.740986 -0.935096         4096         4096.0 {20.0776,-1,0.40625} 20.7526,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.771034 -0.801082         8192         8192.0 {20.8951,-1,0.40625} 21.3497,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.759877
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3208; id=1, #l=461; id=2, #l=2778; id=3, #l=0; id=4, #l=475; id=5, #l=1068; id=6, #l=1079; id=7, #l=0; id=8, #l=0; id=9, #l=19; id=10, #l=122; id=11, #l=834; id=12, #l=1208; id=13, #l=770; id=14, #l=376; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.249633,0.20625        6
0.000000 0.000000            4            4.0 {0.191906,0,0.20625} 3.44639,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.78436,0,0.20625} 9.58583,0.00625        6
0.000000 0.000000           32           32.0 {0.160781,0,0.20625} 2.42632,0.20625        6
-0.037879 -0.075758           64           64.0 {24.5376,-1,0.20625} 22.8873,0.20625        6
-0.189394 -0.340909          128          128.0 {18.7182,-1,0.00625} 21.4436,0.20625        6
-0.246212 -0.303030          256          256.0 {18.3683,-1,0.20625} 17.459,0.20625        6
-0.539773 -0.833333          512          512.0 {21.261,-1,0.00625} 22.4398,0.00625        6
-0.615530 -0.691288         1024         1024.0 {23.2671,0,0.20625} 23.3433,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 1

Starting simulation for: --cats 1024 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.596591 -0.577652         2048         2048.0 {21.3283,0,0.20625} 22.9105,0.20625        6
-0.597775 -0.598958         4096         4096.0 {19.6529,-1,0.20625} 20.9825,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.637133 -0.676491         8192         8192.0 {21.0813,-1,0.20625} 21.9767,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.664727
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3306; id=1, #l=253; id=2, #l=2513; id=3, #l=0; id=4, #l=171; id=5, #l=1239; id=6, #l=919; id=7, #l=0; id=8, #l=0; id=9, #l=97; id=10, #l=66; id=11, #l=1050; id=12, #l=1321; id=13, #l=536; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7661e-05,0.271535        6
0.000000 0.000000            2            2.0 {2.7661e-05,0,0.271535} 0.178105,0.271535        6
0.000000 0.000000            4            4.0 {0.134258,0,0.271535} 2.60627,0.271535        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.86298,0,0.271535} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.110616,0,0.271535} 1.83145,0.271535        6
0.000000 0.000000           64           64.0 {2.42236,0,0.271535} 1.16882,0.271535        6
0.000000 0.000000          128          128.0 {0.430842,0,0.271535} 1.54532,0.271535        6
0.000000 0.000000          256          256.0 {2.33976,0,0.271535} 1.6491,0.271535        6
-0.104596 -0.209192          512          512.0 {20.3102,0,0.139583} 20.363,0.139583        6
-0.375155 -0.645715         1024         1024.0 {25.0588,-1,0.139583} 25.1714,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 2

Starting simulation for: --cats 1024 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.517393 -0.659631         2048         2048.0 {13.4776,-1,0.139583} 15.8156,0.139583        6
-0.568208 -0.619022         4096         4096.0 {20.6439,0,0.139583} 22.6084,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.597763 -0.627318         8192         8192.0 {22.7544,-1,0.139583} 24.0775,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.611281
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2790; id=1, #l=991; id=2, #l=2423; id=3, #l=8; id=4, #l=0; id=5, #l=1439; id=6, #l=812; id=7, #l=0; id=8, #l=0; id=9, #l=319; id=10, #l=329; id=11, #l=630; id=12, #l=902; id=13, #l=1011; id=14, #l=417; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196467,0.03823        6
0.000000 0.000000            2            2.0 {0.000196467,0,0.03823} 1.26502,0.03823        6
0.000000 0.000000            4            4.0 {0.953589,0,0.03823} 18.5114,0.03823        6
0.000000 0.000000            8            8.0 {22.618,0,0.03823} 24.6195,0.03823        6
-0.727178 -1.454355           16           16.0 {20.3348,-1,0.03823} 22.4931,0.03823        6
-0.465766 -0.204355           32           32.0 {0.785665,0,0.03823} 13.0082,0.03823        6
-0.506324 -0.546881           64           64.0 {19.448,0,0.0338214} 9.3839,0.0338214        6
-0.473052 -0.439780          128          128.0 {3.74364,0,0.03125} 13.4274,0.03125        6
-0.352611 -0.232171          256          256.0 {20.3305,0,0.03125} 14.3292,0.03125        6
-0.356500 -0.360389          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.335335 -0.314170         1024         1024.0 {24.6628,-1,0.03125} 25.1656,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 3

Starting simulation for: --cats 1024 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.337149 -0.338962         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.321483 -0.305817         4096         4096.0 {11.2093,0,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.322387 -0.323292         8192         8192.0 {20.6363,-1,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.321007
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=174; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=137; id=8, #l=52; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=71; 
    n.a.     n.a.            1            1.0  unknown 1.4668e-07,51.2062        6
0.000000 0.000000            2            2.0 {1.4668e-07,0,51.2062} 0.000944452,51.2062        6
0.000000 0.000000            4            4.0 {0.000711939,0,51.2062} 0.0138204,51.2062        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0151817,0,51.2062} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.000586569,0,51.2062} 0.00971176,51.2062        6
0.000000 0.000000           64           64.0 {0.0128452,0,51.2062} 0.006198,51.2062        6
0.000000 0.000000          128          128.0 {0.00228466,0,51.2062} 0.00819446,51.2062        6
0.000000 0.000000          256          256.0 {0.0124072,0,51.2062} 0.00874478,51.2062        6
0.000000 0.000000          512          512.0 {0.00259502,0,51.2062} 0.0027389,51.2062        6
0.000000 0.000000         1024         1024.0 {0.0150511,0,51.2062} 0.015358,51.2062        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 25

Starting simulation for: --cats 2048 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         2048         2048.0 {0.00382431,0,51.2062} 0.0101975,51.2062        6
0.000000 0.000000         4096         4096.0 {0.00684076,0,51.2062} 0.012196,51.2062        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {0.0125939,0,51.2062} 4.73022,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=1; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.126737,0.40625        6
0.000000 0.000000            4            4.0 {0.0974294,0,0.40625} 1.7497,0.40625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {1.92129,0,0.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0816271,0,0.40625} 1.23182,0.40625        6
0.000000 0.000000           64           64.0 {1.62679,0,0.40625} 0.788926,0.40625        6
0.000000 0.000000          128          128.0 {0.295664,0,0.40625} 1.04057,0.40625        6
0.000000 0.000000          256          256.0 {1.57158,0,0.40625} 1.10994,0.40625        6
-0.677885 -1.355769          512          512.0 {12.8886,-1,0.40625} 12.9068,0.40625        6
-0.507212 -0.336538         1024         1024.0 {14.7048,-1,0.40625} 14.7435,0.40625        6
-0.457933 -0.408654         2048         2048.0 {17.2282,-1,0.40625} 18.0315,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 0

Starting simulation for: --cats 2048 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.531851 -0.605769         4096         4096.0 {18.8392,-1,0.40625} 19.5142,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.643362 -0.754873         8192         8192.0 {27.072,-1,0.40625} 27.5266,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.674981
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3391; id=1, #l=1026; id=2, #l=2386; id=3, #l=0; id=4, #l=1017; id=5, #l=657; id=6, #l=1436; id=7, #l=0; id=8, #l=0; id=9, #l=36; id=10, #l=325; id=11, #l=666; id=12, #l=438; id=13, #l=533; id=14, #l=577; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.242057,0.20625        6
0.000000 0.000000            4            4.0 {0.184331,0,0.20625} 3.43881,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,-1,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.77679,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.153205,0,0.20625} 2.41874,0.20625        6
0.000000 0.000000           64           64.0 {3.1967,0,0.20625} 1.54637,0.20625        6
0.000000 0.000000          128          128.0 {0.574794,0,0.20625} 2.04204,0.20625        6
0.000000 0.000000          256          256.0 {3.08795,0,0.20625} 2.17867,0.20625        6
-0.009470 -0.018939          512          512.0 {10.3488,0,0.20625} 10.3845,0.20625        6
-0.227273 -0.445076         1024         1024.0 {24.5928,-1,0.20625} 24.669,0.20625        6
-0.404830 -0.582386         2048         2048.0 {20.351,-1,0.20625} 21.9333,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 1

Starting simulation for: --cats 2048 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.543916 -0.683002         4096         4096.0 {22.5544,-1,0.20625} 23.884,0.20625        6
-0.651929 -0.759943         8192         8192.0 {15.2555,-1,0.20625} 16.1509,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.657002
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3131; id=1, #l=1696; id=2, #l=1249; id=3, #l=0; id=4, #l=833; id=5, #l=1937; id=6, #l=902; id=7, #l=0; id=8, #l=0; id=9, #l=794; id=10, #l=223; id=11, #l=788; id=12, #l=745; id=13, #l=577; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7591e-05,0.272224        6
0.000000 0.000000            2            2.0 {2.7591e-05,0,0.272224} 0.177655,0.272224        6
0.000000 0.000000            4            4.0 {0.133918,0,0.272224} 2.59967,0.272224        6
0.000000 0.000000            8            8.0 {10.35,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {2.85573,0,0.272224} 9.58581,0.00625        6
0.000000 0.000000           32           32.0 {0.110336,0,0.272224} 1.82681,0.272224        6
0.000000 0.000000           64           64.0 {2.41623,0,0.272224} 1.16586,0.272224        6
-0.037313 -0.074627          128          128.0 {18.7182,-1,0.00625} 23.0733,0.139583        6
-0.192040 -0.346767          256          256.0 {22.2307,0,0.139583} 20.8871,0.139583        6
-0.484553 -0.777065          512          512.0 {21.261,-1,0.00625} 22.4398,0.00625        6
-0.452164 -0.419776         1024         1024.0 {18.4245,-1,0.139583} 18.5371,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 2

Starting simulation for: --cats 2048 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.547522 -0.642879         2048         2048.0 {19.5298,0,0.139583} 21.8678,0.139583        6
-0.617355 -0.687189         4096         4096.0 {22.0991,-1,0.139583} 24.0637,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.642750 -0.668144         8192         8192.0 {17.2395,-1,0.139583} 18.5625,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.676552
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2500; id=1, #l=1408; id=2, #l=1996; id=3, #l=0; id=4, #l=0; id=5, #l=2021; id=6, #l=935; id=7, #l=0; id=8, #l=0; id=9, #l=466; id=10, #l=369; id=11, #l=855; id=12, #l=961; id=13, #l=870; id=14, #l=327; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196416,0.03824        6
0.000000 0.000000            2            2.0 {0.000196416,0,0.03824} 1.26469,0.03824        6
0.000000 0.000000            4            4.0 {0.953339,0,0.03824} 18.5066,0.03824        6
-0.408604 -0.817207            8            8.0 {22.6121,-1,0.03824} 24.613,0.03824        6
-0.306453 -0.204302           16           16.0 {20.3295,-1,0.03824} 22.4872,0.03824        6
-0.262045 -0.217638           32           32.0 {0.78546,0,0.03824} 13.0048,0.03824        6
-0.344770 -0.427494           64           64.0 {17.2007,-1,0.03824} 8.29959,0.03824        6
-0.351316 -0.357863          128          128.0 {3.74364,0,0.03125} 13.4274,0.03125        6
-0.334588 -0.317859          256          256.0 {20.3305,-1,0.03125} 14.3292,0.03125        6
-0.328176 -0.321764          512          512.0 {4.25219,0,0.03125} 4.48797,0.03125        6
-0.336257 -0.344338         1024         1024.0 {24.6628,-1,0.03125} 25.1656,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 3

Starting simulation for: --cats 2048 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.342518 -0.348779         2048         2048.0 {6.26651,0,0.03125} 16.7096,0.03125        6
-0.325491 -0.308464         4096         4096.0 {11.2093,-1,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.325161 -0.324830         8192         8192.0 {20.6363,0,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.325435
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 25

Plotting...
</pre></div>
</div>
<img alt="../_images/python_cats_21_121.png" src="../_images/python_cats_21_121.png" />
</div>
</div>
</div>
<div class="section" id="id2">
<h3>Without Learning<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># do parameter sweeping</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">]</span>
<span class="n">bandwidths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span>

<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="k">for</span> <span class="n">actions</span> <span class="ow">in</span> <span class="n">num_actions</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="n">bandwidths</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">bd</span> <span class="o">&gt;=</span> <span class="n">actions</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting simulation for: --cats </span><span class="si">{}</span><span class="s2"> --bandwidth </span><span class="si">{}</span><span class="s2"> --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
        <span class="n">rr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done with simulation for num_actions: </span><span class="si">{}</span><span class="s2"> and bandwidth: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)][</span><span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">rr</span><span class="p">,</span> <span class="n">hits</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Plotting...&quot;</span><span class="p">)</span>
<span class="n">plot_reward_sweep</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">bandwidths</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting simulation for: --cats 8 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=156; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=144; id=8, #l=43; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=82; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
    n.a.     n.a.            2            2.0  unknown 0.234482,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.43124,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.41116,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.53879,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.03446,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.17109,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.679995,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.81296,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.53176,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.02794,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 1.10366,0.40625        6
    n.a.     n.a.            4            4.0  unknown 2.72663,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.20875,0.40625        6
    n.a.     n.a.           64           64.0  unknown 1.76585,0.40625        6
    n.a.     n.a.          128          128.0  unknown 2.0175,0.40625        6
    n.a.     n.a.          256          256.0  unknown 2.08686,0.40625        6
    n.a.     n.a.          512          512.0  unknown 1.32984,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.92043,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 2.26997,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 2.52188,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
    n.a.     n.a.            2            2.0  unknown 0.234482,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.43124,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.41116,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.53879,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.03446,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.17109,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.679995,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.81296,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.53176,0.20625        6
    n.a.     n.a.         4096         4096.0  unknown 3.02794,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 0

Starting simulation for: --cats 8 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
Done with simulation for num_actions: 8 and bandwidth: 1

Starting simulation for: --cats 8 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 2

Starting simulation for: --cats 8 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 3.21214,0.139583        6
    n.a.     n.a.            4            4.0  unknown 7.93571,0.139583        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 6.42844,0.139583        6
    n.a.     n.a.           64           64.0  unknown 5.13941,0.139583        6
    n.a.     n.a.          128          128.0  unknown 5.87181,0.139583        6
    n.a.     n.a.          256          256.0  unknown 6.0737,0.139583        6
    n.a.     n.a.          512          512.0  unknown 3.87044,0.139583        6
    n.a.     n.a.         1024         1024.0  unknown 8.49975,0.139583        6
    n.a.     n.a.         2048         2048.0  unknown 6.60663,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 7.33979,0.139583        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 9.31589e-06,0.80625        6
    n.a.     n.a.            2            2.0  unknown 0.0599837,0.80625        6
    n.a.     n.a.            4            4.0  unknown 0.877758,0.80625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.616809,0.80625        6
    n.a.     n.a.           64           64.0  unknown 0.393645,0.80625        6
    n.a.     n.a.          128          128.0  unknown 0.520443,0.80625        6
    n.a.     n.a.          256          256.0  unknown 0.555395,0.80625        6
    n.a.     n.a.          512          512.0  unknown 0.173952,0.80625        6
    n.a.     n.a.         1024         1024.0  unknown 0.975409,0.80625        6
    n.a.     n.a.         2048         2048.0  unknown 0.647659,0.80625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 0.774589,0.80625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.611352,0.40625        6
    n.a.     n.a.            4            4.0  unknown 2.23432,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.71644,0.40625        6
    n.a.     n.a.           64           64.0  unknown 1.27354,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.52519,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.59455,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.837536,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.42812,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.77766,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 0

Starting simulation for: --cats 32 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 2.02957,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.71933,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.91608,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.89601,0.20625        6
    n.a.     n.a.           64           64.0  unknown 2.02364,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.51931,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.65594,0.20625        6
    n.a.     n.a.          512          512.0  unknown 1.16484,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 4.29781,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 3.01661,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 1

Starting simulation for: --cats 32 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 3.51279,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.19857e-05,0.234821        6
    n.a.     n.a.            2            2.0  unknown 0.205952,0.234821        6
    n.a.     n.a.            4            4.0  unknown 3.01375,0.234821        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.11779,0.234821        6
    n.a.     n.a.           64           64.0  unknown 1.35156,0.234821        6
    n.a.     n.a.          128          128.0  unknown 1.78692,0.234821        6
    n.a.     n.a.          256          256.0  unknown 1.90693,0.234821        6
    n.a.     n.a.          512          512.0  unknown 0.597258,0.234821        6
    n.a.     n.a.         1024         1024.0  unknown 3.34903,0.234821        6
    n.a.     n.a.         2048         2048.0  unknown 2.22371,0.234821        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 2

Starting simulation for: --cats 32 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 2.65952,0.234821        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000199639,0.0376226        6
    n.a.     n.a.            2            2.0  unknown 1.28545,0.0376226        6
    n.a.     n.a.            4            4.0  unknown 18.8103,0.0376226        6
    n.a.     n.a.            8            8.0  unknown 25.017,0.0376226        6
    n.a.     n.a.           16           16.0  unknown 22.8563,0.0376226        6
    n.a.     n.a.           32           32.0  unknown 13.2182,0.0376226        6
    n.a.     n.a.           64           64.0  unknown 8.4358,0.0376226        6
    n.a.     n.a.          128          128.0  unknown 11.1531,0.0376226        6
    n.a.     n.a.          256          256.0  unknown 11.9021,0.0376226        6
    n.a.     n.a.          512          512.0  unknown 3.72779,0.0376226        6
    n.a.     n.a.         1024         1024.0  unknown 20.903,0.0376226        6
    n.a.     n.a.         2048         2048.0  unknown 13.8793,0.0376226        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 16.5994,0.0376226        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 4.67607e-06,1.60625        6
    n.a.     n.a.            2            2.0  unknown 0.0301085,1.60625        6
    n.a.     n.a.            4            4.0  unknown 0.440587,1.60625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.309605,1.60625        6
    n.a.     n.a.           64           64.0  unknown 0.197588,1.60625        6
    n.a.     n.a.          128          128.0  unknown 0.261234,1.60625        6
    n.a.     n.a.          256          256.0  unknown 0.278778,1.60625        6
    n.a.     n.a.          512          512.0  unknown 0.0873145,1.60625        6
    n.a.     n.a.         1024         1024.0  unknown 0.489602,1.60625        6
    n.a.     n.a.         2048         2048.0  unknown 0.32509,1.60625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 25

Starting simulation for: --cats 64 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 0.388802,1.60625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.365198,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.98817,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.47028,0.40625        6
    n.a.     n.a.           64           64.0  unknown 1.02739,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.27903,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.3484,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.591382,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.18197,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.53151,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 0

Starting simulation for: --cats 64 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 1.78342,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.476906,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.67366,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58583,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.65359,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.78122,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.27689,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.41351,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.922419,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 4.05539,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.77418,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 1

Starting simulation for: --cats 64 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 3.27036,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.97576e-05,0.252404        6
    n.a.     n.a.            2            2.0  unknown 0.191605,0.252404        6
    n.a.     n.a.            4            4.0  unknown 2.80381,0.252404        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.97027,0.252404        6
    n.a.     n.a.           64           64.0  unknown 1.25741,0.252404        6
    n.a.     n.a.          128          128.0  unknown 1.66244,0.252404        6
    n.a.     n.a.          256          256.0  unknown 1.77409,0.252404        6
    n.a.     n.a.          512          512.0  unknown 0.555653,0.252404        6
    n.a.     n.a.         1024         1024.0  unknown 3.11573,0.252404        6
    n.a.     n.a.         2048         2048.0  unknown 2.06881,0.252404        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 2

Starting simulation for: --cats 64 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 2.47426,0.252404        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000198004,0.0379332        6
    n.a.     n.a.            2            2.0  unknown 1.27492,0.0379332        6
    n.a.     n.a.            4            4.0  unknown 18.6563,0.0379332        6
    n.a.     n.a.            8            8.0  unknown 24.8121,0.0379332        6
    n.a.     n.a.           16           16.0  unknown 22.6691,0.0379332        6
    n.a.     n.a.           32           32.0  unknown 13.11,0.0379332        6
    n.a.     n.a.           64           64.0  unknown 8.36672,0.0379332        6
    n.a.     n.a.          128          128.0  unknown 11.0618,0.0379332        6
    n.a.     n.a.          256          256.0  unknown 11.8046,0.0379332        6
    n.a.     n.a.          512          512.0  unknown 3.69726,0.0379332        6
    n.a.     n.a.         1024         1024.0  unknown 20.7318,0.0379332        6
    n.a.     n.a.         2048         2048.0  unknown 13.7657,0.0379332        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 3

Starting simulation for: --cats 64 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 16.4635,0.0379332        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.34259e-06,3.20625        6
    n.a.     n.a.            2            2.0  unknown 0.0150836,3.20625        6
    n.a.     n.a.            4            4.0  unknown 0.220723,3.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.155104,3.20625        6
    n.a.     n.a.           64           64.0  unknown 0.0989867,3.20625        6
    n.a.     n.a.          128          128.0  unknown 0.130872,3.20625        6
    n.a.     n.a.          256          256.0  unknown 0.139661,3.20625        6
    n.a.     n.a.          512          512.0  unknown 0.0437424,3.20625        6
    n.a.     n.a.         1024         1024.0  unknown 0.245278,3.20625        6
    n.a.     n.a.         2048         2048.0  unknown 0.162862,3.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 25

Starting simulation for: --cats 128 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 0.19478,3.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.242121,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.86509,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.34721,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.904311,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.15596,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.22532,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.468305,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 2.05889,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.40843,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 0

Starting simulation for: --cats 128 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 1.66034,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.355694,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.55245,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.53238,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.66001,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.15567,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.2923,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.801207,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.93417,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.65297,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 1

Starting simulation for: --cats 128 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 3.14915,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.86404e-05,0.26225        6
    n.a.     n.a.            2            2.0  unknown 0.184411,0.26225        6
    n.a.     n.a.            4            4.0  unknown 2.69854,0.26225        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.89629,0.26225        6
    n.a.     n.a.           64           64.0  unknown 1.2102,0.26225        6
    n.a.     n.a.          128          128.0  unknown 1.60003,0.26225        6
    n.a.     n.a.          256          256.0  unknown 1.70748,0.26225        6
    n.a.     n.a.          512          512.0  unknown 0.534791,0.26225        6
    n.a.     n.a.         1024         1024.0  unknown 2.99875,0.26225        6
    n.a.     n.a.         2048         2048.0  unknown 1.99114,0.26225        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 2

Starting simulation for: --cats 128 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 2.38136,0.26225        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000197185,0.0380908        6
    n.a.     n.a.            2            2.0  unknown 1.26965,0.0380908        6
    n.a.     n.a.            4            4.0  unknown 18.5791,0.0380908        6
    n.a.     n.a.            8            8.0  unknown 24.7095,0.0380908        6
    n.a.     n.a.           16           16.0  unknown 22.5753,0.0380908        6
    n.a.     n.a.           32           32.0  unknown 13.0557,0.0380908        6
    n.a.     n.a.           64           64.0  unknown 8.3321,0.0380908        6
    n.a.     n.a.          128          128.0  unknown 11.016,0.0380908        6
    n.a.     n.a.          256          256.0  unknown 11.7558,0.0380908        6
    n.a.     n.a.          512          512.0  unknown 3.68196,0.0380908        6
    n.a.     n.a.         1024         1024.0  unknown 20.646,0.0380908        6
    n.a.     n.a.         2048         2048.0  unknown 13.7087,0.0380908        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 3

Starting simulation for: --cats 128 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 16.3954,0.0380908        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 1.17244e-06,6.40625        6
    n.a.     n.a.            2            2.0  unknown 0.00754917,6.40625        6
    n.a.     n.a.            4            4.0  unknown 0.110469,6.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.0776277,6.40625        6
    n.a.     n.a.           64           64.0  unknown 0.0495416,6.40625        6
    n.a.     n.a.          128          128.0  unknown 0.0654997,6.40625        6
    n.a.     n.a.          256          256.0  unknown 0.0698985,6.40625        6
    n.a.     n.a.          512          512.0  unknown 0.0218925,6.40625        6
    n.a.     n.a.         1024         1024.0  unknown 0.122759,6.40625        6
    n.a.     n.a.         2048         2048.0  unknown 0.0815103,6.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 25

Starting simulation for: --cats 256 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 0.0974849,6.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.180583,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.80355,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.28567,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.842772,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.09442,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.16378,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.406767,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 1.99735,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.34689,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 0

Starting simulation for: --cats 256 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 1.5988,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.295088,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.49184,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.47177,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.5994,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.09507,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.2317,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.740601,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.87357,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.59236,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 1

Starting simulation for: --cats 256 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 3.08855,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.80809e-05,0.267474        6
    n.a.     n.a.            2            2.0  unknown 0.180809,0.267474        6
    n.a.     n.a.            4            4.0  unknown 2.64583,0.267474        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58581,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.85925,0.267474        6
    n.a.     n.a.           64           64.0  unknown 1.18657,0.267474        6
    n.a.     n.a.          128          128.0  unknown 1.56878,0.267474        6
    n.a.     n.a.          256          256.0  unknown 1.67413,0.267474        6
    n.a.     n.a.          512          512.0  unknown 0.524345,0.267474        6
    n.a.     n.a.         1024         1024.0  unknown 2.94018,0.267474        6
    n.a.     n.a.         2048         2048.0  unknown 1.95224,0.267474        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 2

Starting simulation for: --cats 256 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 2.33485,0.267474        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196775,0.0381702        6
    n.a.     n.a.            2            2.0  unknown 1.26701,0.0381702        6
    n.a.     n.a.            4            4.0  unknown 18.5404,0.0381702        6
    n.a.     n.a.            8            8.0  unknown 24.6581,0.0381702        6
    n.a.     n.a.           16           16.0  unknown 22.5283,0.0381702        6
    n.a.     n.a.           32           32.0  unknown 13.0286,0.0381702        6
    n.a.     n.a.           64           64.0  unknown 8.31476,0.0381702        6
    n.a.     n.a.          128          128.0  unknown 10.9931,0.0381702        6
    n.a.     n.a.          256          256.0  unknown 11.7313,0.0381702        6
    n.a.     n.a.          512          512.0  unknown 3.67431,0.0381702        6
    n.a.     n.a.         1024         1024.0  unknown 20.6031,0.0381702        6
    n.a.     n.a.         2048         2048.0  unknown 13.6802,0.0381702        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 3

Starting simulation for: --cats 256 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 16.3613,0.0381702        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 5.86506e-07,12.8063        6
    n.a.     n.a.            2            2.0  unknown 0.00377643,12.8063        6
    n.a.     n.a.            4            4.0  unknown 0.0552615,12.8063        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.0388328,12.8063        6
    n.a.     n.a.           64           64.0  unknown 0.0247829,12.8063        6
    n.a.     n.a.          128          128.0  unknown 0.0327658,12.8063        6
    n.a.     n.a.          256          256.0  unknown 0.0349663,12.8063        6
    n.a.     n.a.          512          512.0  unknown 0.0109516,12.8063        6
    n.a.     n.a.         1024         1024.0  unknown 0.0614093,12.8063        6
    n.a.     n.a.         2048         2048.0  unknown 0.040775,12.8063        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 25

Starting simulation for: --cats 512 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 0.0487662,12.8063        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.149814,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.77278,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.2549,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.812003,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.06365,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.13301,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.375997,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 1.96658,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.31612,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 0

Starting simulation for: --cats 512 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 1.56803,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.264785,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.46154,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.44147,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.5691,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.06476,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.20139,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.710298,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.84327,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.56206,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 1

Starting simulation for: --cats 512 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 3.05824,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7801e-05,0.270168        6
    n.a.     n.a.            2            2.0  unknown 0.179007,0.270168        6
    n.a.     n.a.            4            4.0  unknown 2.61946,0.270168        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.84072,0.270168        6
    n.a.     n.a.           64           64.0  unknown 1.17474,0.270168        6
    n.a.     n.a.          128          128.0  unknown 1.55314,0.270168        6
    n.a.     n.a.          256          256.0  unknown 1.65744,0.270168        6
    n.a.     n.a.          512          512.0  unknown 0.519119,0.270168        6
    n.a.     n.a.         1024         1024.0  unknown 2.91087,0.270168        6
    n.a.     n.a.         2048         2048.0  unknown 1.93278,0.270168        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 2

Starting simulation for: --cats 512 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 2.31157,0.270168        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00019657,0.0382101        6
    n.a.     n.a.            2            2.0  unknown 1.26568,0.0382101        6
    n.a.     n.a.            4            4.0  unknown 18.5211,0.0382101        6
    n.a.     n.a.            8            8.0  unknown 24.6323,0.0382101        6
    n.a.     n.a.           16           16.0  unknown 22.5049,0.0382101        6
    n.a.     n.a.           32           32.0  unknown 13.015,0.0382101        6
    n.a.     n.a.           64           64.0  unknown 8.30609,0.0382101        6
    n.a.     n.a.          128          128.0  unknown 10.9816,0.0382101        6
    n.a.     n.a.          256          256.0  unknown 11.7191,0.0382101        6
    n.a.     n.a.          512          512.0  unknown 3.67047,0.0382101        6
    n.a.     n.a.         1024         1024.0  unknown 20.5816,0.0382101        6
    n.a.     n.a.         2048         2048.0  unknown 13.6659,0.0382101        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 3

Starting simulation for: --cats 512 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 16.3442,0.0382101        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.93324e-07,25.6063        6
    n.a.     n.a.            2            2.0  unknown 0.00188867,25.6063        6
    n.a.     n.a.            4            4.0  unknown 0.0276375,25.6063        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.0194211,25.6063        6
    n.a.     n.a.           64           64.0  unknown 0.0123945,25.6063        6
    n.a.     n.a.          128          128.0  unknown 0.0163869,25.6063        6
    n.a.     n.a.          256          256.0  unknown 0.0174874,25.6063        6
    n.a.     n.a.          512          512.0  unknown 0.00547714,25.6063        6
    n.a.     n.a.         1024         1024.0  unknown 0.0307122,25.6063        6
    n.a.     n.a.         2048         2048.0  unknown 0.0203925,25.6063        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 25

Starting simulation for: --cats 1024 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 0.0243891,25.6063        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.134429,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.7574,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.23951,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.796618,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.04826,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.11763,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.360613,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 1.9512,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.30074,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 0

Starting simulation for: --cats 1024 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 1.55265,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.249633,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.44639,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58583,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.42632,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.55395,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.04961,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.18624,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.695147,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.82811,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.54691,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 1

Starting simulation for: --cats 1024 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 3.04309,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7661e-05,0.271535        6
    n.a.     n.a.            2            2.0  unknown 0.178105,0.271535        6
    n.a.     n.a.            4            4.0  unknown 2.60627,0.271535        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.83145,0.271535        6
    n.a.     n.a.           64           64.0  unknown 1.16882,0.271535        6
    n.a.     n.a.          128          128.0  unknown 1.54532,0.271535        6
    n.a.     n.a.          256          256.0  unknown 1.6491,0.271535        6
    n.a.     n.a.          512          512.0  unknown 0.516504,0.271535        6
    n.a.     n.a.         1024         1024.0  unknown 2.89621,0.271535        6
    n.a.     n.a.         2048         2048.0  unknown 1.92305,0.271535        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 2

Starting simulation for: --cats 1024 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 2.29993,0.271535        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196467,0.03823        6
    n.a.     n.a.            2            2.0  unknown 1.26502,0.03823        6
    n.a.     n.a.            4            4.0  unknown 18.5114,0.03823        6
    n.a.     n.a.            8            8.0  unknown 24.6195,0.03823        6
    n.a.     n.a.           16           16.0  unknown 22.4931,0.03823        6
    n.a.     n.a.           32           32.0  unknown 13.0082,0.03823        6
    n.a.     n.a.           64           64.0  unknown 8.30175,0.03823        6
    n.a.     n.a.          128          128.0  unknown 10.9759,0.03823        6
    n.a.     n.a.          256          256.0  unknown 11.713,0.03823        6
    n.a.     n.a.          512          512.0  unknown 3.66856,0.03823        6
    n.a.     n.a.         1024         1024.0  unknown 20.5708,0.03823        6
    n.a.     n.a.         2048         2048.0  unknown 13.6588,0.03823        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 3

Starting simulation for: --cats 1024 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 16.3357,0.03823        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 1.4668e-07,51.2062        6
    n.a.     n.a.            2            2.0  unknown 0.000944452,51.2062        6
    n.a.     n.a.            4            4.0  unknown 0.0138204,51.2062        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 0.00971176,51.2062        6
    n.a.     n.a.           64           64.0  unknown 0.006198,51.2062        6
    n.a.     n.a.          128          128.0  unknown 0.00819446,51.2062        6
    n.a.     n.a.          256          256.0  unknown 0.00874478,51.2062        6
    n.a.     n.a.          512          512.0  unknown 0.0027389,51.2062        6
    n.a.     n.a.         1024         1024.0  unknown 0.015358,51.2062        6
    n.a.     n.a.         2048         2048.0  unknown 0.0101975,51.2062        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 25

Starting simulation for: --cats 2048 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 0.012196,51.2062        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.126737,0.40625        6
    n.a.     n.a.            4            4.0  unknown 1.7497,0.40625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.23182,0.40625        6
    n.a.     n.a.           64           64.0  unknown 0.788926,0.40625        6
    n.a.     n.a.          128          128.0  unknown 1.04057,0.40625        6
    n.a.     n.a.          256          256.0  unknown 1.10994,0.40625        6
    n.a.     n.a.          512          512.0  unknown 0.352921,0.40625        6
    n.a.     n.a.         1024         1024.0  unknown 1.9435,0.40625        6
    n.a.     n.a.         2048         2048.0  unknown 1.29305,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 0

Starting simulation for: --cats 2048 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 1.54495,0.40625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.242057,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.43881,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.41874,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.54637,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.04204,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.17867,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.687571,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.82054,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.53933,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 1

Starting simulation for: --cats 2048 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 3.03551,0.20625        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 2.7591e-05,0.272224        6
    n.a.     n.a.            2            2.0  unknown 0.177655,0.272224        6
    n.a.     n.a.            4            4.0  unknown 2.59967,0.272224        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58581,0.00625        6
    n.a.     n.a.           32           32.0  unknown 1.82681,0.272224        6
    n.a.     n.a.           64           64.0  unknown 1.16586,0.272224        6
    n.a.     n.a.          128          128.0  unknown 1.54141,0.272224        6
    n.a.     n.a.          256          256.0  unknown 1.64492,0.272224        6
    n.a.     n.a.          512          512.0  unknown 0.515197,0.272224        6
    n.a.     n.a.         1024         1024.0  unknown 2.88888,0.272224        6
    n.a.     n.a.         2048         2048.0  unknown 1.91818,0.272224        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 2

Starting simulation for: --cats 2048 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 2.29411,0.272224        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.000196416,0.03824        6
    n.a.     n.a.            2            2.0  unknown 1.26469,0.03824        6
    n.a.     n.a.            4            4.0  unknown 18.5066,0.03824        6
    n.a.     n.a.            8            8.0  unknown 24.613,0.03824        6
    n.a.     n.a.           16           16.0  unknown 22.4872,0.03824        6
    n.a.     n.a.           32           32.0  unknown 13.0048,0.03824        6
    n.a.     n.a.           64           64.0  unknown 8.29959,0.03824        6
    n.a.     n.a.          128          128.0  unknown 10.973,0.03824        6
    n.a.     n.a.          256          256.0  unknown 11.7099,0.03824        6
    n.a.     n.a.          512          512.0  unknown 3.6676,0.03824        6
    n.a.     n.a.         1024         1024.0  unknown 20.5655,0.03824        6
    n.a.     n.a.         2048         2048.0  unknown 13.6552,0.03824        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 3

Starting simulation for: --cats 2048 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 16.3314,0.03824        6

finished run
number of examples = 5000
weighted example sum = 5000.000000
weighted label sum = 5000.000000
average loss = n.a.
total feature number = 30000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 25

Plotting...
</pre></div>
</div>
<img alt="../_images/python_cats_23_79.png" src="../_images/python_cats_23_79.png" />
</div>
</div>
</div>
</div>
<div class="section" id="scenario-2">
<h2>Scenario 2<a class="headerlink" href="#scenario-2" title="Permalink to this headline">¶</a></h2>
<p>In the real world peoples preferences change as e.g. the seasons change. So now in the simulation we are going to incorporate two different cost functions, and swap over to the second one halfway through. Below is a a table of the new cost function we are going to use, get_cost_1:</p>
<div class="section" id="living-room">
<h3>Living Room<a class="headerlink" href="#living-room" title="Permalink to this headline">¶</a></h3>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p></p></th>
<th class="text-align:center head"><p>get_cost</p></th>
<th class="text-align:center head"><p>get_cost_1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><strong>Morning</strong></p></td>
<td class="text-align:center"><p>Cold</p></td>
<td class="text-align:center"><p>Hot</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><strong>Afternoon</strong></p></td>
<td class="text-align:center"><p>Hot</p></td>
<td class="text-align:center"><p>Cold</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="bedroom">
<h3>Bedroom<a class="headerlink" href="#bedroom" title="Permalink to this headline">¶</a></h3>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p></p></th>
<th class="text-align:center head"><p>get_cost</p></th>
<th class="text-align:center head"><p>get_cost_1</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p><strong>Morning</strong></p></td>
<td class="text-align:center"><p>Hot</p></td>
<td class="text-align:center"><p>Cold</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p><strong>Afternoon</strong></p></td>
<td class="text-align:center"><p>Cold</p></td>
<td class="text-align:center"><p>Cold</p></td>
</tr>
</tbody>
</table>
<p>Below we define the new cost function</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_cost_1</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">):</span>
    <span class="nb">range</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">max_value</span> <span class="o">-</span> <span class="n">min_value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Living Room&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">29</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Bedroom&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="k">if</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">5.0</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_LIKED_TEMPERATURE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
</pre></div>
</div>
</div>
</div>
<p>To make it easy to show the effect of the cost function changing we are going to modify the run_simulation function. It is a little less readable now, but it supports accepting a list of cost functions and it will operate over each cost function in turn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_simulation_multiple_cost_functions</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">cost_functions</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="n">reward_rate</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">hits</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">cost_sum</span> <span class="o">=</span> <span class="mf">0.</span>

    <span class="n">start_counter</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">end_counter</span> <span class="o">=</span> <span class="n">start_counter</span> <span class="o">+</span> <span class="n">num_iterations</span>
    <span class="k">for</span> <span class="n">cost_function</span> <span class="ow">in</span> <span class="n">cost_functions</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_counter</span><span class="p">,</span> <span class="n">end_counter</span><span class="p">):</span>
            <span class="c1"># 1. In each simulation choose a room</span>
            <span class="n">room</span> <span class="o">=</span> <span class="n">choose_room</span><span class="p">(</span><span class="n">rooms</span><span class="p">)</span>
            <span class="c1"># 2. Choose time of day for a given room</span>
            <span class="n">time_of_day</span> <span class="o">=</span> <span class="n">choose_time_of_day</span><span class="p">(</span><span class="n">times_of_day</span><span class="p">)</span>
            <span class="c1"># 3. Pass context to vw to get a temperature</span>
            <span class="n">context</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;room&#39;</span><span class="p">:</span> <span class="n">room</span><span class="p">,</span> <span class="s1">&#39;time_of_day&#39;</span><span class="p">:</span> <span class="n">time_of_day</span><span class="p">}</span>
            <span class="n">temperature</span><span class="p">,</span> <span class="n">pdf_value</span> <span class="o">=</span> <span class="n">predict_temperature</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">context</span><span class="p">)</span>
            
            <span class="c1"># 4. Get cost of the action we chose</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="n">cost_function</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">cost</span> <span class="o">&lt;=</span> <span class="o">-</span><span class="mf">0.75</span><span class="p">:</span> <span class="c1"># count something as a hit only if it has a high reward</span>
                <span class="n">hits</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">cost_sum</span> <span class="o">+=</span> <span class="n">cost</span>

            <span class="k">if</span> <span class="n">do_learn</span><span class="p">:</span>
                <span class="c1"># 5. Inform VW of what happened so we can learn from it</span>
                <span class="n">txt_ex</span> <span class="o">=</span> <span class="n">to_vw_example_format</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">cats_label</span><span class="o">=</span><span class="p">(</span><span class="n">temperature</span><span class="p">,</span> <span class="n">cost</span><span class="p">,</span> <span class="n">pdf_value</span><span class="p">))</span>
                <span class="n">vw_format</span> <span class="o">=</span> <span class="n">vw</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">txt_ex</span><span class="p">,</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="o">.</span><span class="n">lContinuous</span><span class="p">)</span>
                <span class="c1"># 6. Learn</span>
                <span class="n">vw</span><span class="o">.</span><span class="n">learn</span><span class="p">(</span><span class="n">vw_format</span><span class="p">)</span>
                <span class="c1"># 7. Let VW know you&#39;re done with these objects</span>
                <span class="n">vw</span><span class="o">.</span><span class="n">finish_example</span><span class="p">(</span><span class="n">vw_format</span><span class="p">)</span>

            <span class="c1"># We negate this so that on the plot instead of minimizing cost, we are maximizing reward</span>
            <span class="n">reward_rate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">cost_sum</span><span class="o">/</span><span class="n">i</span><span class="p">)</span>
        
        <span class="n">start_counter</span> <span class="o">=</span> <span class="n">end_counter</span>
        <span class="n">end_counter</span> <span class="o">=</span> <span class="n">start_counter</span> <span class="o">+</span> <span class="n">num_iterations</span>

    <span class="k">return</span> <span class="n">reward_rate</span><span class="p">,</span> <span class="n">hits</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id3">
<h3>With Learning<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>Now that we have run a parameter sweep we can better pick the values of num_actions and bandwidth. For the next scenario we will pick <code class="docutils literal notranslate"><span class="pre">num_actions</span> <span class="pre">128</span></code> and <code class="docutils literal notranslate"><span class="pre">bandwidth</span> <span class="pre">2</span></code>.</p>
<p>Let us now switch to the second cost function after a few samples (running the first cost function). Recall that this cost function changes the preferences of the room temperatures but it is still working with the same continuous action space as before. We should see the learner pick up these changes and optimize towards the new preferences.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># use first reward function initially and then switch to second reward function</span>

<span class="c1"># Instantiate learner in VW</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Instantiate VW learner</span>
<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidth</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>

<span class="n">num_iterations_per_cost_func</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">cost_functions</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_cost</span><span class="p">,</span> <span class="n">get_cost_1</span><span class="p">]</span>
<span class="n">total_iterations</span> <span class="o">=</span> <span class="n">num_iterations_per_cost_func</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">cost_functions</span><span class="p">)</span>

<span class="n">ctr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation_multiple_cost_functions</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations_per_cost_func</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">cost_functions</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
<span class="n">plot_reward_rate</span><span class="p">(</span><span class="n">total_iterations</span><span class="p">,</span> <span class="n">ctr</span><span class="p">,</span> <span class="s1">&#39;reward rate with num_actions = 32 and bandwidth = 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,0,0.00625} 0.355694,0.20625        6
0.000000 0.000000            4            4.0 {0.297967,0,0.20625} 3.55245,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,0,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.89042,0,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.266841,0,0.20625} 2.53238,0.20625        6
0.000000 0.000000           64           64.0 {3.31033,0,0.20625} 1.66001,0.20625        6
0.000000 0.000000          128          128.0 {0.68843,0,0.20625} 2.15567,0.20625        6
0.000000 0.000000          256          256.0 {3.20159,0,0.20625} 2.2923,0.20625        6
-0.109054 -0.218109          512          512.0 {17.7352,-1,0.20625} 17.7709,0.20625        6
-0.464092 -0.819129         1024         1024.0 {21.3125,-1,0.20625} 21.3887,0.20625        6
-0.591894 -0.719697         2048         2048.0 {24.101,-1,0.20625} 25.6833,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.612590 -0.633286         4096         4096.0 {22.4256,-1,0.20625} 23.7552,0.20625        6
-0.736279 -0.859967         8192         8192.0 {21.1873,-1,0.20625} 22.0827,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.610948 -0.485618        16384        16384.0 {13.6048,-1,0.20625} 9.50664,0.00625        6

finished run
number of examples = 20000
weighted example sum = 20000.000000
weighted label sum = 20000.000000
average loss = -0.643883
total feature number = 120000
</pre></div>
</div>
<img alt="../_images/python_cats_29_3.png" src="../_images/python_cats_29_3.png" />
</div>
</div>
</div>
<div class="section" id="id4">
<h3>Without Learning<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># use first reward function initially and then switch to second reward function</span>

<span class="c1"># Instantiate learner in VW</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">bandwidth</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Instantiate VW learner</span>
<span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bandwidth</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>

<span class="n">num_iterations_per_cost_func</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">cost_functions</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_cost</span><span class="p">,</span> <span class="n">get_cost_1</span><span class="p">]</span>
<span class="n">total_iterations</span> <span class="o">=</span> <span class="n">num_iterations_per_cost_func</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">cost_functions</span><span class="p">)</span>

<span class="n">ctr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation_multiple_cost_functions</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations_per_cost_func</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">cost_functions</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>
<span class="n">plot_reward_rate</span><span class="p">(</span><span class="n">total_iterations</span><span class="p">,</span> <span class="n">ctr</span><span class="p">,</span> <span class="s1">&#39;reward rate with num_actions = 32 and bandwidth = 1&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=6096; id=1, #l=3262; id=2, #l=2235; id=3, #l=0; id=4, #l=2239; id=5, #l=2080; id=6, #l=1354; id=7, #l=0; id=8, #l=0; id=9, #l=1070; id=10, #l=808; id=11, #l=1880; id=12, #l=1518; id=13, #l=464; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
    n.a.     n.a.            2            2.0  unknown 0.355694,0.20625        6
    n.a.     n.a.            4            4.0  unknown 3.55245,0.20625        6
    n.a.     n.a.            8            8.0  unknown 22.5925,0.00625        6
    n.a.     n.a.           16           16.0  unknown 9.58582,0.00625        6
    n.a.     n.a.           32           32.0  unknown 2.53238,0.20625        6
    n.a.     n.a.           64           64.0  unknown 1.66001,0.20625        6
    n.a.     n.a.          128          128.0  unknown 2.15567,0.20625        6
    n.a.     n.a.          256          256.0  unknown 2.2923,0.20625        6
    n.a.     n.a.          512          512.0  unknown 0.801207,0.20625        6
    n.a.     n.a.         1024         1024.0  unknown 3.93417,0.20625        6
    n.a.     n.a.         2048         2048.0  unknown 2.65297,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>    n.a.     n.a.         4096         4096.0  unknown 3.14915,0.20625        6
    n.a.     n.a.         8192         8192.0  unknown 4.73022,0.00625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = n.a.
total feature number = 60000
</pre></div>
</div>
<img alt="../_images/python_cats_31_3.png" src="../_images/python_cats_31_3.png" />
</div>
</div>
</div>
</div>
<div class="section" id="scenario-3">
<h2>Scenario 3<a class="headerlink" href="#scenario-3" title="Permalink to this headline">¶</a></h2>
<div class="section" id="better-cost-function">
<h3>Better cost function<a class="headerlink" href="#better-cost-function" title="Permalink to this headline">¶</a></h3>
<p>The cost function we have been using until now has been a bit too simplistic but has served us well enough to showcase the differences in learning and also in showing CB pickup the new cost cost function and adjust to it.</p>
<p>A slightly better cost function for our simulated world could be the difference between the temperature recommended and the temperature chosen. The smaller the difference the better the thermostat is doing. We are going to model that by taking the absolute cost: <code class="docutils literal notranslate"><span class="pre">1.0</span> <span class="pre">-</span> <span class="pre">|selected_temperature</span> <span class="pre">-</span> <span class="pre">predicted_temerature|</span> <span class="pre">/</span> <span class="pre">range</span></code> and the transforming that cost into a reward by multiplying it with <code class="docutils literal notranslate"><span class="pre">-1</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_smooth_cost</span><span class="p">(</span><span class="n">context</span><span class="p">,</span> <span class="n">temperature</span><span class="p">,</span> <span class="n">min_value</span><span class="p">,</span> <span class="n">max_value</span><span class="p">):</span>
    <span class="nb">range</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">max_value</span> <span class="o">-</span> <span class="n">min_value</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Living Room&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">29</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">/</span> <span class="nb">range</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">cost</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">/</span> <span class="nb">range</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">cost</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;room&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Bedroom&quot;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;morning&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">/</span> <span class="nb">range</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">cost</span>
        <span class="k">elif</span> <span class="n">context</span><span class="p">[</span><span class="s1">&#39;time_of_day&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;afternoon&quot;</span><span class="p">:</span>
            <span class="c1"># randomly pick a temperature in this range</span>
            <span class="n">selected_temperature</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">18</span><span class="p">)</span>
            <span class="c1"># the absolute difference between selected temperature and proposed temperature</span>
            <span class="n">cost</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">math</span><span class="o">.</span><span class="n">fabs</span><span class="p">(</span><span class="n">selected_temperature</span> <span class="o">-</span> <span class="n">temperature</span><span class="p">)</span> <span class="o">/</span> <span class="nb">range</span>
            <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">cost</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">USER_DISLIKED_TEMPERATURE</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s try the original paramter sweep with the new cost function <code class="docutils literal notranslate"><span class="pre">get_smooth_cost</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># do parameter sweeping</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">num_actions</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">2048</span><span class="p">]</span>
<span class="n">bandwidths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span>

<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="k">for</span> <span class="n">actions</span> <span class="ow">in</span> <span class="n">num_actions</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">bd</span> <span class="ow">in</span> <span class="n">bandwidths</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
            <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">bd</span> <span class="o">&gt;=</span> <span class="n">actions</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting simulation for: --cats </span><span class="si">{}</span><span class="s2"> --bandwidth </span><span class="si">{}</span><span class="s2"> --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="n">vw</span> <span class="o">=</span> <span class="n">pyvw</span><span class="o">.</span><span class="n">vw</span><span class="p">(</span><span class="s2">&quot;--cats &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;  --bandwidth &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: &quot;</span><span class="p">)</span>
        <span class="n">rr</span><span class="p">,</span> <span class="n">hits</span> <span class="o">=</span> <span class="n">run_simulation</span><span class="p">(</span><span class="n">vw</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">rooms</span><span class="p">,</span> <span class="n">times_of_day</span><span class="p">,</span> <span class="n">get_smooth_cost</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">do_learn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">vw</span><span class="o">.</span><span class="n">finish</span><span class="p">()</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done with simulation for num_actions: </span><span class="si">{}</span><span class="s2"> and bandwidth: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">actions</span><span class="p">,</span> <span class="n">bd</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">()</span>
        <span class="n">data</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">actions</span><span class="p">)][</span><span class="nb">str</span><span class="p">(</span><span class="n">bd</span><span class="p">)]</span> <span class="o">=</span> <span class="p">(</span><span class="n">rr</span><span class="p">,</span> <span class="n">hits</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Plotting...&quot;</span><span class="p">)</span>
<span class="n">plot_reward_sweep</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">bandwidths</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Starting simulation for: --cats 8 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=0; id=1, #l=0; id=2, #l=0; id=3, #l=0; id=4, #l=0; id=5, #l=0; id=6, #l=0; id=7, #l=0; id=8, #l=0; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=0; id=14, #l=0; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
0.000000 0.000000            2            2.0 {3.64167e-05,-0.467507,0.20625} 0.234482,0.20625        6
0.000000 0.000000            4            4.0 {0.176755,-0.494209,0.20625} 3.43124,0.20625        6
0.000000 0.000000            8            8.0 {10.3501,-0.85348,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {3.76921,-0.578627,0.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {4.02442,-0.638642,0.20625} 6.28995,0.20625        6
0.000000 0.000000           64           64.0 {22.5831,-0.772208,0.20625} 20.9327,0.20625        6
0.000000 0.000000          128          128.0 {12.2036,-0.8852,0.20625} 13.6708,0.20625        6
0.000000 0.000000          256          256.0 {14.7167,-0.986124,0.20625} 13.8075,0.20625        6
0.000000 0.000000          512          512.0 {12.2806,-0.545132,0.20625} 12.3164,0.20625        6
0.000000 0.000000         1024         1024.0 {27.0095,-0.956366,0.20625} 27.0857,0.20625        6
0.000000 0.000000         2048         2048.0 {12.5858,-0.87792,0.20625} 14.1681,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {17.2135,-0.983965,0.20625} 18.5431,0.20625        6
0.000000 0.000000         8192         8192.0 {14.7631,-0.984212,0.20625} 15.6585,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4246; id=1, #l=1053; id=2, #l=3440; id=3, #l=286; id=4, #l=1024; id=5, #l=3315; id=6, #l=375; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
0.000000 0.000000            2            2.0 {0.00120175,-0.48631,0.00625} 1.10366,0.40625        6
-0.106417 -0.212834            4            4.0 {1.07435,-0.172928,0.40625} 2.72663,0.40625        6
-0.053209 0.000000            8            8.0 {10.3501,-0.795329,0.00625} 22.5925,0.00625        6
-0.118564 -0.183919           16           16.0 {2.89821,-0.544736,0.40625} 9.58582,0.00625        6
-0.204220 -0.289875           32           32.0 {4.80576,-0.649183,0.00625} 6.14721,0.40625        6
-0.291929 -0.379639           64           64.0 {6.54217,-0.687142,0.40625} 5.70431,0.40625        6
-0.415585 -0.539241          128          128.0 {18.7182,-0.680177,0.00625} 21.7098,0.40625        6
-1.030218 -1.644850          256          256.0 {22.2408,-0.84088,0.40625} 21.7792,0.40625        6
-1.118452 -1.206686          512          512.0 {5.25017,-0.611076,0.40625} 5.26831,0.40625        6
-1.044827 -0.971202         1024         1024.0 {18.6356,-0.975543,0.40625} 18.6743,0.40625        6
-0.927238 -0.809648         2048         2048.0 {25.0974,-0.73521,0.40625} 25.9007,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 0

Starting simulation for: --cats 8 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.940836 -0.954435         4096         4096.0 {13.6623,-0.881274,0.40625} 14.3373,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.904835 -0.868833         8192         8192.0 {22.2643,-0.901962,0.40625} 22.7189,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.902945
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4257; id=1, #l=2306; id=2, #l=2191; id=3, #l=394; id=4, #l=2164; id=5, #l=1561; id=6, #l=881; 
    n.a.     n.a.            1            1.0  unknown 3.64167e-05,0.20625        6
-0.134636 -0.134636            2            2.0 {3.64167e-05,-0.111075,0.20625} 0.234482,0.20625        6
-0.344493 -0.554349            4            4.0 {0.176755,-0.457338,0.20625} 3.43124,0.20625        6
-0.172246 0.000000            8            8.0 {10.3501,-0.774624,0.00625} 22.5925,0.00625        6
-0.307043 -0.441839           16           16.0 {11.5268,-0.874776,0.20625} 11.9268,0.20625        6
-0.367945 -0.428846           32           32.0 {0.145629,-0.153881,0.20625} 2.41116,0.20625        6
-0.469102 -0.570259           64           64.0 {22.5831,-0.843373,0.20625} 20.9327,0.20625        6
-0.434617 -0.400132          128          128.0 {18.7182,-0.931089,0.00625} 21.4284,0.20625        6
-0.483433 -0.532249          256          256.0 {14.7167,-0.949164,0.20625} 13.8075,0.20625        6
-0.594729 -0.706026          512          512.0 {12.2806,-0.912724,0.20625} 12.3164,0.20625        6
-0.669311 -0.743893         1024         1024.0 {19.2519,-0.946967,0.20625} 19.3281,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 1

Starting simulation for: --cats 8 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.730999 -0.792687         2048         2048.0 {20.3434,-0.84311,0.20625} 21.9257,0.20625        6
-0.779773 -0.828548         4096         4096.0 {21.0923,-0.864271,0.20625} 22.4219,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.789406 -0.799038         8192         8192.0 {14.7631,-0.965889,0.20625} 15.6585,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.809504
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4263; id=1, #l=785; id=2, #l=3711; id=3, #l=281; id=4, #l=747; id=5, #l=3721; id=6, #l=251; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-14.154194 -14.154194            2            2.0 {0.00120175,-0.442319,0.00625} 3.21214,0.139583        6
-7.246363 -0.338531            4            4.0 {3.12685,-0.28352,0.139583} 7.93571,0.139583        6
-3.623181 0.000000            8            8.0 {10.3501,-0.439288,0.00625} 22.5925,0.00625        6
-2.175304 -0.727428           16           16.0 {8.4351,-0.77077,0.139583} 9.58582,0.00625        6
-1.292437 -0.409569           32           32.0 {4.80576,-0.660373,0.00625} 25.5329,0.139583        6
-0.854886 -0.417336           64           64.0 {26.6824,-0.642433,0.139583} 24.2439,0.139583        6
-0.681740 -0.508594          128          128.0 {18.7182,-0.962196,0.00625} 24.9763,0.139583        6
-0.578066 -0.474393          256          256.0 {18.88,-0.962127,0.139583} 17.5364,0.139583        6
-0.680238 -0.782409          512          512.0 {7.63855,-0.718165,0.139583} 7.69134,0.139583        6
-0.698249 -0.716261         1024         1024.0 {27.4917,-0.954722,0.139583} 27.6042,0.139583        6
-0.840739 -0.983228         2048         2048.0 {15.7313,-0.951531,0.139583} 18.0693,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 2

Starting simulation for: --cats 8 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.833877 -0.827016         4096         4096.0 {16.8379,-0.988947,0.139583} 18.8025,0.139583        6
-0.859032 -0.884186         8192         8192.0 {18.9484,-0.930184,0.139583} 20.2715,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.849497
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=2098; id=1, #l=2808; id=2, #l=2957; id=3, #l=0; id=4, #l=2081; id=5, #l=1407; id=6, #l=0; 
    n.a.     n.a.            1            1.0  unknown 9.31589e-06,0.80625        6
0.000000 0.000000            2            2.0 {9.31589e-06,-0.487631,0.80625} 0.0599837,0.80625        6
0.000000 0.000000            4            4.0 {0.0452164,-0.482098,0.80625} 0.877758,0.80625        6
0.000000 0.000000            8            8.0 {10.3501,-0.849581,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.964217,-0.47434,0.80625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {4.00625,-0.620944,0.80625} 4.5858,0.80625        6
0.000000 0.000000           64           64.0 {20.6608,-0.90223,0.80625} 20.2386,0.80625        6
0.000000 0.000000          128          128.0 {5.10634,-0.612356,0.80625} 5.48168,0.80625        6
0.000000 0.000000          256          256.0 {5.74924,-0.340635,0.80625} 5.51664,0.80625        6
0.000000 0.000000          512          512.0 {21.002,-0.854846,0.80625} 21.0112,0.80625        6
0.000000 0.000000         1024         1024.0 {28.7389,-0.994487,0.80625} 28.7584,0.80625        6
0.000000 0.000000         2048         2048.0 {24.0568,-0.732916,0.80625} 24.4616,0.80625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 8 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {20.2794,-0.889099,0.80625} 20.6196,0.80625        6
0.000000 0.000000         8192         8192.0 {21.6371,-0.864286,0.80625} 21.8661,0.80625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4087; id=1, #l=315; id=2, #l=3841; id=3, #l=209; id=4, #l=180; id=5, #l=2915; id=6, #l=977; id=7, #l=87; id=8, #l=179; id=9, #l=64; id=10, #l=184; id=11, #l=83; id=12, #l=2893; id=13, #l=845; id=14, #l=184; id=15, #l=69; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-52.041496 -52.041496            2            2.0 {0.00120175,-0.487889,0.00625} 0.611352,0.40625        6
-26.020748 0.000000            4            4.0 {0.582045,-0.474467,0.40625} 2.23432,0.40625        6
-13.010374 0.000000            8            8.0 {10.3501,-0.780447,0.00625} 22.5925,0.00625        6
-6.587758 -0.165141           16           16.0 {2.40591,-0.581159,0.40625} 9.58582,0.00625        6
-3.394075 -0.200393           32           32.0 {0.566242,-0.505516,0.40625} 1.71644,0.40625        6
-1.862002 -0.329928           64           64.0 {5.06525,-0.307995,0.40625} 4.22739,0.40625        6
-1.137090 -0.412177          128          128.0 {0.78028,-0.513137,0.40625} 1.52519,0.40625        6
-0.766608 -0.396126          256          256.0 {12.887,-0.840591,0.40625} 12.4253,0.40625        6
-0.883791 -1.000974          512          512.0 {11.6502,-0.820079,0.40625} 11.6683,0.40625        6
-0.953234 -1.022677         1024         1024.0 {17.1587,-0.968596,0.40625} 17.1973,0.40625        6
-0.983843 -1.014452         2048         2048.0 {21.6513,-0.849716,0.40625} 22.4546,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 0

Starting simulation for: --cats 32 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.848809 -0.713776         4096         4096.0 {21.0469,-0.850054,0.40625} 21.7219,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.816024 -0.783238         8192         8192.0 {21.772,-0.877426,0.40625} 22.2266,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.838382
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4079; id=1, #l=826; id=2, #l=3232; id=3, #l=219; id=4, #l=651; id=5, #l=3554; id=6, #l=642; id=7, #l=125; id=8, #l=146; id=9, #l=207; id=10, #l=325; id=11, #l=869; id=12, #l=1164; id=13, #l=612; id=14, #l=126; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-13.537899 -13.537899            2            2.0 {0.00120175,-0.21153,0.00625} 0.71933,0.20625        6
-6.768950 0.000000            4            4.0 {0.661603,-0.46074,0.20625} 3.91608,0.20625        6
-3.384475 0.000000            8            8.0 {10.3501,-0.84166,0.00625} 22.5925,0.00625        6
-1.896302 -0.408129           16           16.0 {10.0722,-0.762438,0.20625} 10.4723,0.20625        6
-1.006425 -0.116549           32           32.0 {4.80576,-0.6529,0.00625} 8.7142,0.20625        6
-0.728468 -0.450511           64           64.0 {21.1285,-0.864523,0.20625} 19.4782,0.20625        6
-0.639278 -0.550087          128          128.0 {18.5066,-0.903443,0.20625} 19.9739,0.20625        6
-0.527782 -0.416287          256          256.0 {13.2622,-0.921115,0.20625} 12.3529,0.20625        6
-0.660239 -0.792695          512          512.0 {5.00791,-0.608717,0.20625} 5.04363,0.20625        6
-0.787466 -0.914693         1024         1024.0 {23.6156,-0.916859,0.20625} 23.6917,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 1

Starting simulation for: --cats 32 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.866420 -0.945375         2048         2048.0 {21.798,-0.822439,0.20625} 23.3802,0.20625        6
-0.844373 -0.822326         4096         4096.0 {21.5772,-0.872776,0.20625} 22.9067,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.793368 -0.742363         8192         8192.0 {15.2479,-0.919014,0.20625} 16.1433,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.797426
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4167; id=1, #l=855; id=2, #l=2817; id=3, #l=269; id=4, #l=566; id=5, #l=2698; id=6, #l=1368; id=7, #l=0; id=8, #l=172; id=9, #l=319; id=10, #l=222; id=11, #l=1587; id=12, #l=1516; id=13, #l=1186; id=14, #l=0; id=15, #l=53; 
    n.a.     n.a.            1            1.0  unknown 3.19857e-05,0.234821        6
-0.583677 -0.583677            2            2.0 {3.19857e-05,-0.479709,0.234821} 0.205952,0.234821        6
-0.291838 0.000000            4            4.0 {0.155249,-0.46021,0.234821} 3.01375,0.234821        6
-0.145919 0.000000            8            8.0 {10.3501,-0.796864,0.00625} 22.5925,0.00625        6
-0.288387 -0.430854           16           16.0 {14.6441,-0.956714,0.139583} 15.2352,0.139583        6
-0.337744 -0.387101           32           32.0 {4.80576,-0.676821,0.00625} 24.1001,0.139583        6
-1.185781 -2.033818           64           64.0 {19.5183,-0.867616,0.139583} 17.0797,0.139583        6
-0.873937 -0.562092          128          128.0 {0.771161,-0.51152,0.151705} 2.76595,0.151705        6
-0.861946 -0.849955          256          256.0 {21.268,-0.891826,0.139583} 19.9244,0.139583        6
-0.807728 -0.753509          512          512.0 {18.6236,-0.911245,0.139583} 18.6764,0.139583        6
-0.745145 -0.682563         1024         1024.0 {20.3275,-0.836072,0.139583} 20.44,0.139583        6
-0.799303 -0.853461         2048         2048.0 {10.4776,-0.832515,0.139583} 12.8156,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 2

Starting simulation for: --cats 32 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.878644 -0.957985         4096         4096.0 {16.3603,-0.981492,0.139583} 18.3249,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.880696 -0.882748         8192         8192.0 {15.6052,-0.999715,0.139583} 16.9282,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.880924
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3191; id=1, #l=2647; id=2, #l=2714; id=3, #l=431; id=4, #l=0; id=5, #l=1939; id=6, #l=503; id=7, #l=59; id=8, #l=0; id=9, #l=935; id=10, #l=832; id=11, #l=884; id=12, #l=754; id=13, #l=558; id=14, #l=306; id=15, #l=35; 
    n.a.     n.a.            1            1.0  unknown 0.000199639,0.0376226        6
-0.485583 -0.485583            2            2.0 {0.000199639,-0.484126,0.0376226} 1.28545,0.0376226        6
-0.438069 -0.390554            4            4.0 {0.968985,-0.470196,0.0376226} 18.8103,0.0376226        6
-0.581824 -0.725580            8            8.0 {22.9832,-0.837581,0.0376226} 25.017,0.0376226        6
-0.625420 -0.669016           16           16.0 {20.6631,-0.850065,0.0376226} 22.8563,0.0376226        6
-0.621694 -0.617968           32           32.0 {0.798351,-0.135042,0.0376226} 13.2182,0.0376226        6
-0.708754 -0.795814           64           64.0 {17.483,-0.74233,0.0376226} 8.4358,0.0376226        6
-0.714072 -0.719389          128          128.0 {3.74364,-0.61671,0.03125} 13.4274,0.03125        6
-0.728562 -0.743052          256          256.0 {20.3305,-0.893436,0.03125} 14.3292,0.03125        6
-0.743042 -0.757522          512          512.0 {4.25219,-0.592576,0.03125} 4.48797,0.03125        6
-0.743492 -0.743942         1024         1024.0 {24.6628,-0.906152,0.03125} 25.1656,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 3

Starting simulation for: --cats 32 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.738684 -0.733876         2048         2048.0 {6.26651,-0.659281,0.03125} 16.7096,0.03125        6
-0.733720 -0.728755         4096         4096.0 {11.2093,-0.832081,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.734671 -0.735622         8192         8192.0 {20.6363,-0.875785,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.736308
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=2; id=2, #l=0; id=3, #l=459; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=301; id=8, #l=146; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=281; id=15, #l=161; 
    n.a.     n.a.            1            1.0  unknown 4.67607e-06,1.60625        6
0.000000 0.000000            2            2.0 {4.67607e-06,-0.193297,1.60625} 0.0301085,1.60625        6
0.000000 0.000000            4            4.0 {0.0226962,-0.152842,1.60625} 0.440587,1.60625        6
0.000000 0.000000            8            8.0 {10.3501,-0.768697,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.483984,-0.532164,1.60625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.0186995,-0.181635,1.60625} 0.309605,1.60625        6
0.000000 0.000000           64           64.0 {0.409498,-0.144448,1.60625} 0.197588,1.60625        6
0.000000 0.000000          128          128.0 {0.0728334,-0.126985,1.60625} 0.261234,1.60625        6
0.000000 0.000000          256          256.0 {0.395535,-0.505755,1.60625} 0.278778,1.60625        6
0.000000 0.000000          512          512.0 {12.5341,-0.857128,1.60625} 12.5387,1.60625        6
0.000000 0.000000         1024         1024.0 {12.9312,-0.928992,1.60625} 12.941,1.60625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 32 and bandwidth: 25

Starting simulation for: --cats 64 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         2048         2048.0 {13.5694,-0.887745,1.60625} 13.7726,1.60625        6
0.000000 0.000000         4096         4096.0 {20.1403,-0.894506,1.60625} 20.311,1.60625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {29.7867,-0.93909,1.60625} 29.9017,1.60625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4056; id=1, #l=2578; id=2, #l=1511; id=3, #l=292; id=4, #l=2328; id=5, #l=467; id=6, #l=1070; id=7, #l=206; id=8, #l=113; id=9, #l=32; id=10, #l=2324; id=11, #l=16; id=12, #l=479; id=13, #l=26; id=14, #l=1073; id=15, #l=195; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-60.055557 -60.055557            2            2.0 {0.00120175,-0.469184,0.00625} 0.365198,0.40625        6
-30.027779 0.000000            4            4.0 {0.335891,-0.53099,0.40625} 1.98817,0.40625        6
-15.013889 0.000000            8            8.0 {10.3501,-0.534874,0.00625} 22.5925,0.00625        6
-7.587668 -0.161447           16           16.0 {2.15975,-0.527756,0.40625} 9.58582,0.00625        6
-3.833575 -0.079483           32           32.0 {0.320089,-0.516638,0.40625} 1.47028,0.40625        6
-2.127482 -0.421389           64           64.0 {1.86525,-0.583741,0.40625} 1.02739,0.40625        6
-2.109040 -2.090597          128          128.0 {18.7182,-0.695304,0.00625} 20.9713,0.40625        6
-1.245653 -0.382266          256          256.0 {22.487,-0.897459,0.40625} 22.0253,0.40625        6
-1.125585 -1.005518          512          512.0 {15.3425,-0.993735,0.40625} 15.3606,0.40625        6
-1.024650 -0.923714         1024         1024.0 {22.8202,-0.838912,0.40625} 22.8589,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 0

Starting simulation for: --cats 64 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.803275 -0.581900         2048         2048.0 {22.3897,-0.797543,0.40625} 23.193,0.40625        6
-0.777592 -0.751909         4096         4096.0 {23.7546,-0.774272,0.40625} 24.4296,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.817056 -0.856520         8192         8192.0 {19.5566,-0.897149,0.40625} 20.0112,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.837928
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4118; id=1, #l=809; id=2, #l=2221; id=3, #l=505; id=4, #l=533; id=5, #l=2497; id=6, #l=1843; id=7, #l=178; id=8, #l=402; id=9, #l=233; id=10, #l=298; id=11, #l=1129; id=12, #l=2365; id=13, #l=1512; id=14, #l=87; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-33.341614 -33.341614            2            2.0 {0.00120175,-0.468866,0.00625} 0.476906,0.20625        6
-16.670807 0.000000            4            4.0 {0.419179,-0.21652,0.20625} 3.67366,0.20625        6
-8.335403 0.000000            8            8.0 {10.3501,-0.424255,0.00625} 22.5925,0.00625        6
-4.167702 0.000000           16           16.0 {4.01163,-0.648402,0.20625} 9.58583,0.00625        6
-2.164742 -0.161782           32           32.0 {2.32745,-0.571713,0.20625} 4.59298,0.20625        6
-1.336217 -0.507692           64           64.0 {20.8861,-0.831783,0.20625} 19.2358,0.20625        6
-0.890511 -0.444805          128          128.0 {18.2642,-0.935692,0.20625} 19.7314,0.20625        6
-0.677104 -0.463697          256          256.0 {20.7773,-0.823215,0.20625} 19.8681,0.20625        6
-0.654477 -0.631849          512          512.0 {18.3412,-0.720496,0.20625} 18.377,0.20625        6
-0.568271 -0.482065         1024         1024.0 {13.6762,-0.891093,0.20625} 13.7524,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 1

Starting simulation for: --cats 64 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.706982 -0.845693         2048         2048.0 {10.8889,-0.794646,0.20625} 12.4712,0.20625        6
-0.816147 -0.925311         4096         4096.0 {28.6075,-0.993295,0.20625} 29.937,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.801654 -0.787162         8192         8192.0 {22.7631,-0.787748,0.20625} 23.6585,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.838749
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4002; id=1, #l=2167; id=2, #l=1951; id=3, #l=289; id=4, #l=1089; id=5, #l=1977; id=6, #l=1494; id=7, #l=0; id=8, #l=198; id=9, #l=985; id=10, #l=1258; id=11, #l=749; id=12, #l=560; id=13, #l=1092; id=14, #l=0; id=15, #l=67; 
    n.a.     n.a.            1            1.0  unknown 2.97576e-05,0.252404        6
-0.641325 -0.641325            2            2.0 {2.97576e-05,-0.526087,0.252404} 0.191605,0.252404        6
-0.390194 -0.139063            4            4.0 {0.144434,-0.201825,0.252404} 2.80381,0.252404        6
-0.195097 0.000000            8            8.0 {10.3501,-0.828759,0.00625} 22.5925,0.00625        6
-0.163294 -0.131491           16           16.0 {3.07998,-0.28946,0.252404} 9.58582,0.00625        6
-0.199194 -0.235094           32           32.0 {4.80576,-0.619207,0.00625} 23.8613,0.139583        6
-0.289934 -0.380674           64           64.0 {13.5481,-0.588168,0.139583} 11.1096,0.139583        6
-0.402922 -0.515910          128          128.0 {2.03216,-0.573169,0.139583} 4.20017,0.139583        6
-0.415428 -0.427934          256          256.0 {20.5516,-0.799475,0.139583} 19.208,0.139583        6
-0.670536 -0.925645          512          512.0 {21.261,-0.849858,0.00625} 22.4398,0.00625        6
-0.639480 -0.608424         1024         1024.0 {30.6873,-0.541265,0.174671} 30.7773,0.174671        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 2

Starting simulation for: --cats 64 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.775841 -0.912202         2048         2048.0 {24.0895,-0.881799,0.139583} 26.4275,0.139583        6
-0.841708 -0.907575         4096         4096.0 {14.6886,-0.946533,0.139583} 16.6532,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.837516 -0.833323         8192         8192.0 {23.4857,-0.876611,0.139583} 24.8088,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.829202
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3192; id=1, #l=2535; id=2, #l=1833; id=3, #l=333; id=4, #l=0; id=5, #l=1527; id=6, #l=1017; id=7, #l=80; id=8, #l=0; id=9, #l=853; id=10, #l=1326; id=11, #l=1329; id=12, #l=711; id=13, #l=801; id=14, #l=175; id=15, #l=37; 
    n.a.     n.a.            1            1.0  unknown 0.000198004,0.0379332        6
-0.501820 -0.501820            2            2.0 {0.000198004,-0.499685,0.0379332} 1.27492,0.0379332        6
-0.455657 -0.409494            4            4.0 {0.961051,-0.497069,0.0379332} 18.6563,0.0379332        6
-0.535552 -0.615447            8            8.0 {22.795,-0.782575,0.0379332} 24.8121,0.0379332        6
-0.943153 -1.350755           16           16.0 {20.4939,-0.852739,0.0379332} 22.6691,0.0379332        6
-0.802593 -0.662033           32           32.0 {0.791813,-0.510361,0.0379332} 13.11,0.0379332        6
-0.810381 -0.818168           64           64.0 {17.3399,-0.996813,0.0379332} 8.36672,0.0379332        6
-0.790103 -0.769825          128          128.0 {3.74364,-0.555134,0.03125} 13.4274,0.03125        6
-0.772225 -0.754346          256          256.0 {20.3305,-0.88372,0.03125} 14.3292,0.03125        6
-0.751160 -0.730095          512          512.0 {4.25219,-0.268966,0.03125} 4.48797,0.03125        6
-0.744296 -0.737433         1024         1024.0 {24.6628,-0.720295,0.03125} 25.1656,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 3

Starting simulation for: --cats 64 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.748881 -0.753466         2048         2048.0 {6.26651,-0.702624,0.03125} 16.7096,0.03125        6
-0.745903 -0.742925         4096         4096.0 {11.2093,-0.879843,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.741851 -0.737799         8192         8192.0 {20.6363,-0.832669,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.742357
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=459; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=301; id=8, #l=146; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=281; id=15, #l=161; 
    n.a.     n.a.            1            1.0  unknown 2.34259e-06,3.20625        6
0.000000 0.000000            2            2.0 {2.34259e-06,-0.456128,3.20625} 0.0150836,3.20625        6
0.000000 0.000000            4            4.0 {0.0113702,-0.520878,3.20625} 0.220723,3.20625        6
0.000000 0.000000            8            8.0 {10.3501,-0.837662,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.242464,-0.175664,3.20625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00936795,-0.529474,3.20625} 0.155104,3.20625        6
0.000000 0.000000           64           64.0 {0.205148,-0.16021,3.20625} 0.0989867,3.20625        6
0.000000 0.000000          128          128.0 {0.0364877,-0.5235,3.20625} 0.130872,3.20625        6
0.000000 0.000000          256          256.0 {0.198153,-0.491759,3.20625} 0.139661,3.20625        6
0.000000 0.000000          512          512.0 {0.0414444,-0.47453,3.20625} 0.0437424,3.20625        6
0.000000 0.000000         1024         1024.0 {13.7141,-0.870796,3.20625} 13.719,3.20625        6
0.000000 0.000000         2048         2048.0 {13.5348,-0.920335,3.20625} 13.6365,3.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 64 and bandwidth: 25

Starting simulation for: --cats 128 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         4096         4096.0 {5.34902,-0.608446,3.20625} 5.43455,3.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {24.4039,-0.871524,3.20625} 24.4615,3.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4064; id=1, #l=1691; id=2, #l=2389; id=3, #l=830; id=4, #l=889; id=5, #l=663; id=6, #l=1739; id=7, #l=384; id=8, #l=459; id=9, #l=104; id=10, #l=799; id=11, #l=664; id=12, #l=13; id=13, #l=1741; id=14, #l=14; id=15, #l=382; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-69.828712 -69.828712            2            2.0 {0.00120175,-0.490983,0.00625} 0.242121,0.40625        6
-34.914356 0.000000            4            4.0 {0.212814,-0.529576,0.40625} 1.86509,0.40625        6
-17.457178 0.000000            8            8.0 {10.3501,-0.452845,0.00625} 22.5925,0.00625        6
-8.728589 0.000000           16           16.0 {2.03668,-0.248841,0.40625} 9.58582,0.00625        6
-4.405796 -0.083003           32           32.0 {3.15086,-0.286187,0.40625} 4.30105,0.40625        6
-2.434387 -0.462979           64           64.0 {4.20371,-0.616058,0.40625} 3.36585,0.40625        6
-1.843490 -1.252594          128          128.0 {18.7182,-0.707535,0.00625} 20.8483,0.40625        6
-1.121108 -0.398726          256          256.0 {12.5177,-0.891986,0.40625} 12.0561,0.40625        6
-1.339913 -1.558719          512          512.0 {20.1425,-0.885205,0.40625} 20.1606,0.40625        6
-1.177781 -1.015648         1024         1024.0 {21.9587,-0.855713,0.40625} 21.9974,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 0

Starting simulation for: --cats 128 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-1.159239 -1.140698         2048         2048.0 {24.2359,-0.788468,0.40625} 25.0392,0.40625        6
-1.067625 -0.976011         4096         4096.0 {20.1853,-0.881302,0.40625} 20.8603,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.993956 -0.920287         8192         8192.0 {22.3874,-0.811771,0.40625} 22.842,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.959198
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4102; id=1, #l=1684; id=2, #l=2522; id=3, #l=221; id=4, #l=1462; id=5, #l=2080; id=6, #l=291; id=7, #l=177; id=8, #l=122; id=9, #l=219; id=10, #l=600; id=11, #l=686; id=12, #l=1601; id=13, #l=201; id=14, #l=67; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-33.275902 -33.275902            2            2.0 {0.00120175,-0.493939,0.00625} 0.355694,0.20625        6
-16.637951 0.000000            4            4.0 {0.297967,-0.513591,0.20625} 3.55245,0.20625        6
-8.318975 0.000000            8            8.0 {10.3501,-0.853373,0.00625} 22.5925,0.00625        6
-4.159488 0.000000           16           16.0 {3.89042,-0.576012,0.20625} 9.58582,0.00625        6
-2.165940 -0.172393           32           32.0 {0.266841,-0.511274,0.20625} 2.53238,0.20625        6
-1.283225 -0.400509           64           64.0 {5.24973,-0.619404,0.20625} 3.5994,0.20625        6
-0.894332 -0.505440          128          128.0 {18.143,-0.945576,0.20625} 19.6102,0.20625        6
-0.698279 -0.502226          256          256.0 {28.4137,-0.998472,0.20625} 27.5044,0.20625        6
-1.034415 -1.370551          512          512.0 {21.261,-0.828431,0.00625} 22.4398,0.00625        6
-0.834631 -0.634847         1024         1024.0 {14.2822,-0.892261,0.20625} 14.3584,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 1

Starting simulation for: --cats 128 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.851825 -0.869018         2048         2048.0 {18.2828,-0.912184,0.20625} 19.8651,0.20625        6
-0.928698 -1.005572         4096         4096.0 {21.6984,-0.875866,0.20625} 23.0279,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.927495 -0.926292         8192         8192.0 {20.4601,-0.904934,0.20625} 21.3555,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.905724
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4058; id=1, #l=1448; id=2, #l=2437; id=3, #l=287; id=4, #l=1034; id=5, #l=2439; id=6, #l=1147; id=7, #l=0; id=8, #l=158; id=9, #l=405; id=10, #l=653; id=11, #l=1645; id=12, #l=1505; id=13, #l=568; id=14, #l=0; id=15, #l=52; 
    n.a.     n.a.            1            1.0  unknown 2.86404e-05,0.26225        6
-0.224247 -0.224247            2            2.0 {2.86404e-05,-0.183777,0.26225} 0.184411,0.26225        6
-0.292049 -0.359851            4            4.0 {0.139011,-0.530836,0.26225} 2.69854,0.26225        6
-0.146024 0.000000            8            8.0 {10.3501,-0.766977,0.00625} 22.5925,0.00625        6
-0.277714 -0.409404           16           16.0 {14.2858,-0.967381,0.139583} 14.877,0.139583        6
-0.337799 -0.397884           32           32.0 {0.114532,-0.475569,0.26225} 1.89629,0.26225        6
-0.876997 -1.416195           64           64.0 {13.4287,-0.94635,0.139583} 10.9902,0.139583        6
-0.710976 -0.544956          128          128.0 {16.7187,-0.678106,0.139583} 18.8867,0.139583        6
-0.768082 -0.825189          256          256.0 {21.3874,-0.866981,0.139583} 20.0438,0.139583        6
-0.773398 -0.778714          512          512.0 {15.3997,-0.939069,0.139583} 15.4525,0.139583        6
-0.666968 -0.560538         1024         1024.0 {17.1036,-0.996183,0.139583} 17.2162,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 2

Starting simulation for: --cats 128 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.765768 -0.864569         2048         2048.0 {17.7612,-0.934949,0.139583} 20.0992,0.139583        6
-0.789129 -0.812490         4096         4096.0 {18.8677,-0.971843,0.139583} 20.8323,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.822352 -0.855576         8192         8192.0 {15.4857,-0.925751,0.139583} 16.8088,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.834295
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3988; id=1, #l=992; id=2, #l=1939; id=3, #l=249; id=4, #l=0; id=5, #l=1565; id=6, #l=1861; id=7, #l=65; id=8, #l=0; id=9, #l=277; id=10, #l=524; id=11, #l=1725; id=12, #l=1190; id=13, #l=1353; id=14, #l=251; id=15, #l=30; 
    n.a.     n.a.            1            1.0  unknown 0.000197185,0.0380908        6
-0.525713 -0.525713            2            2.0 {0.000197185,-0.528155,0.0380908} 1.26965,0.0380908        6
-0.456971 -0.388229            4            4.0 {0.957074,-0.473214,0.0380908} 18.5791,0.0380908        6
-0.595050 -0.733130            8            8.0 {22.7007,-0.851948,0.0380908} 24.7095,0.0380908        6
-1.000442 -1.405833           16           16.0 {20.4091,-0.920842,0.0380908} 22.5753,0.0380908        6
-0.821522 -0.642603           32           32.0 {0.788537,-0.496652,0.0380908} 13.0557,0.0380908        6
-0.837492 -0.853462           64           64.0 {19.5077,-0.860497,0.0337178} 9.41272,0.0337178        6
-0.798826 -0.760160          128          128.0 {3.74364,-0.645602,0.03125} 13.4274,0.03125        6
-0.772464 -0.746101          256          256.0 {20.3305,-0.848563,0.03125} 14.3292,0.03125        6
-0.764415 -0.756367          512          512.0 {4.25219,-0.589113,0.03125} 4.48797,0.03125        6
-0.746380 -0.728346         1024         1024.0 {24.6628,-0.752151,0.03125} 25.1656,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 3

Starting simulation for: --cats 128 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.740769 -0.735158         2048         2048.0 {6.26651,-0.649313,0.03125} 16.7096,0.03125        6
-0.738978 -0.737187         4096         4096.0 {11.2093,-0.798949,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.737250 -0.735522         8192         8192.0 {20.6363,-0.851724,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.737487
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=460; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=302; id=8, #l=147; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=280; id=15, #l=162; 
    n.a.     n.a.            1            1.0  unknown 1.17244e-06,6.40625        6
0.000000 0.000000            2            2.0 {1.17244e-06,-0.145708,6.40625} 0.00754917,6.40625        6
0.000000 0.000000            4            4.0 {0.00569065,-0.506001,6.40625} 0.110469,6.40625        6
0.000000 0.000000            8            8.0 {10.3501,-0.773975,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.12135,-0.207719,6.40625} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00468855,-0.446073,6.40625} 0.0776277,6.40625        6
0.000000 0.000000           64           64.0 {0.102674,-0.524905,6.40625} 0.0495416,6.40625        6
0.000000 0.000000          128          128.0 {0.0182616,-0.471386,6.40625} 0.0654997,6.40625        6
0.000000 0.000000          256          256.0 {0.099173,-0.50695,6.40625} 0.0698985,6.40625        6
0.000000 0.000000          512          512.0 {0.0207424,-0.516491,6.40625} 0.0218925,6.40625        6
0.000000 0.000000         1024         1024.0 {0.120306,-0.463184,6.40625} 0.122759,6.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 128 and bandwidth: 25

Starting simulation for: --cats 256 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         2048         2048.0 {0.654959,-0.530172,6.40625} 0.705901,6.40625        6
0.000000 0.000000         4096         4096.0 {25.4049,-0.698551,6.40625} 25.4477,6.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {25.4509,-0.710776,6.40625} 25.4797,6.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4026; id=1, #l=2041; id=2, #l=1995; id=3, #l=1667; id=4, #l=384; id=5, #l=7; id=6, #l=1998; id=7, #l=1638; id=8, #l=35; id=9, #l=7; id=10, #l=385; id=11, #l=6; id=12, #l=8; id=13, #l=1968; id=14, #l=33; id=15, #l=1634; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-59.965824 -59.965824            2            2.0 {0.00120175,-0.445059,0.00625} 0.180583,0.40625        6
-29.982912 0.000000            4            4.0 {0.151276,-0.492276,0.40625} 1.80355,0.40625        6
-14.991456 0.000000            8            8.0 {10.3501,-0.762299,0.00625} 22.5925,0.00625        6
-7.577822 -0.164188           16           16.0 {1.97514,-0.525492,0.40625} 9.58582,0.00625        6
-3.885782 -0.193742           32           32.0 {0.135473,-0.465237,0.40625} 1.28567,0.40625        6
-3.595820 -3.305858           64           64.0 {22.3576,-0.839472,0.40625} 21.5197,0.40625        6
-2.036533 -0.477246          128          128.0 {18.7182,-0.701603,0.00625} 20.7867,0.40625        6
-1.261900 -0.487267          256          256.0 {5.56388,-0.670838,0.40625} 5.10225,0.40625        6
-0.850063 -0.438225          512          512.0 {13.1886,-0.908663,0.40625} 13.2068,0.40625        6
-0.636037 -0.422010         1024         1024.0 {5.89714,-0.647316,0.40625} 5.93581,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 0

Starting simulation for: --cats 256 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.619799 -0.603561         2048         2048.0 {13.8359,-0.940287,0.40625} 14.6392,0.40625        6
-0.759285 -0.898771         4096         4096.0 {21.4776,-0.834083,0.40625} 22.1526,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.749297 -0.739310         8192         8192.0 {13.0951,-0.93592,0.40625} 13.5497,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.780156
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4094; id=1, #l=2682; id=2, #l=1504; id=3, #l=242; id=4, #l=2291; id=5, #l=1060; id=6, #l=634; id=7, #l=205; id=8, #l=167; id=9, #l=300; id=10, #l=926; id=11, #l=199; id=12, #l=434; id=13, #l=302; id=14, #l=139; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-30.461412 -30.461412            2            2.0 {0.00120175,-0.440263,0.00625} 0.295088,0.20625        6
-15.230706 0.000000            4            4.0 {0.237361,-0.178842,0.20625} 3.49184,0.20625        6
-7.615353 0.000000            8            8.0 {10.3501,-0.775214,0.00625} 22.5925,0.00625        6
-3.903141 -0.190930           16           16.0 {3.82982,-0.566525,0.20625} 9.58582,0.00625        6
-1.969531 -0.035920           32           32.0 {1.29714,-0.558503,0.20625} 3.56268,0.20625        6
-1.161659 -0.353788           64           64.0 {20.7043,-0.824556,0.20625} 19.0539,0.20625        6
-0.829067 -0.496475          128          128.0 {10.3248,-0.824904,0.20625} 11.792,0.20625        6
-0.594720 -0.360373          256          256.0 {20.5955,-0.90528,0.20625} 19.6862,0.20625        6
-1.057892 -1.521064          512          512.0 {5.55336,-0.646998,0.20625} 5.58909,0.20625        6
-0.902954 -0.748016         1024         1024.0 {23.1913,-0.815792,0.20625} 23.2675,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 1

Starting simulation for: --cats 256 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.815946 -0.728937         2048         2048.0 {21.1313,-0.892179,0.20625} 22.7136,0.20625        6
-0.830871 -0.845797         4096         4096.0 {22.6075,-0.782105,0.20625} 23.937,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.817613 -0.804354         8192         8192.0 {23.1873,-0.759808,0.20625} 24.0827,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.808176
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4171; id=1, #l=796; id=2, #l=1548; id=3, #l=512; id=4, #l=813; id=5, #l=3369; id=6, #l=2175; id=7, #l=0; id=8, #l=279; id=9, #l=395; id=10, #l=319; id=11, #l=658; id=12, #l=1445; id=13, #l=1276; id=14, #l=0; id=15, #l=51; 
    n.a.     n.a.            1            1.0  unknown 2.80809e-05,0.267474        6
-0.568401 -0.568401            2            2.0 {2.80809e-05,-0.484605,0.267474} 0.180809,0.267474        6
-0.437437 -0.306473            4            4.0 {0.136296,-0.466225,0.267474} 2.64583,0.267474        6
-0.218718 0.000000            8            8.0 {10.35,-0.85189,0.00625} 22.5925,0.00625        6
-0.271173 -0.323628           16           16.0 {14.2261,-0.953325,0.139583} 14.8173,0.139583        6
-0.265894 -0.260616           32           32.0 {4.80576,-0.65164,0.00625} 12.2195,0.139583        6
-0.440713 -0.615532           64           64.0 {13.369,-0.884199,0.139583} 10.9305,0.139583        6
-0.768591 -1.096470          128          128.0 {18.7182,-0.889062,0.00625} 22.1703,0.139583        6
-1.170312 -1.572033          256          256.0 {6.52175,-0.643948,0.139583} 5.17818,0.139583        6
-0.864256 -0.558199          512          512.0 {16.0565,-0.947665,0.139583} 16.1092,0.139583        6
-0.869846 -0.875436         1024         1024.0 {20.7454,-0.852404,0.139583} 20.858,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 2

Starting simulation for: --cats 256 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.877498 -0.885151         2048         2048.0 {22.2388,-0.891671,0.139583} 24.5768,0.139583        6
-0.812541 -0.747583         4096         4096.0 {22.6289,-0.872711,0.139583} 24.5935,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.848601 -0.884662         8192         8192.0 {16.3813,-0.970581,0.139583} 17.7043,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.860160
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3171; id=1, #l=2288; id=2, #l=2008; id=3, #l=186; id=4, #l=0; id=5, #l=1318; id=6, #l=993; id=7, #l=83; id=8, #l=0; id=9, #l=599; id=10, #l=938; id=11, #l=985; id=12, #l=949; id=13, #l=680; id=14, #l=324; id=15, #l=35; 
    n.a.     n.a.            1            1.0  unknown 0.000196775,0.0381702        6
-0.525130 -0.525130            2            2.0 {0.000196775,-0.527416,0.0381702} 1.26701,0.0381702        6
-0.474037 -0.422944            4            4.0 {0.955083,-0.516604,0.0381702} 18.5404,0.0381702        6
-0.578514 -0.682992            8            8.0 {22.6535,-0.88288,0.0381702} 24.6581,0.0381702        6
-1.011248 -1.443981           16           16.0 {20.3667,-0.879381,0.0381702} 22.5283,0.0381702        6
-0.796529 -0.581811           32           32.0 {0.786897,-0.512105,0.0381702} 13.0286,0.0381702        6
-0.845949 -0.895369           64           64.0 {19.4736,-0.894026,0.0337769} 9.39625,0.0337769        6
-0.831233 -0.816516          128          128.0 {3.74364,-0.271559,0.03125} 13.4274,0.03125        6
-0.781674 -0.732115          256          256.0 {20.3305,-0.834622,0.03125} 14.3292,0.03125        6
-0.766393 -0.751111          512          512.0 {4.25219,-0.631446,0.03125} 4.48797,0.03125        6
-0.751816 -0.737239         1024         1024.0 {24.6628,-0.718401,0.03125} 25.1656,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 3

Starting simulation for: --cats 256 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.744284 -0.736752         2048         2048.0 {6.26651,-0.653042,0.03125} 16.7096,0.03125        6
-0.740725 -0.737166         4096         4096.0 {11.2093,-0.860437,0.03125} 19.9844,0.03125        6
-0.738538 -0.736351         8192         8192.0 {20.6363,-0.873744,0.03125} 26.546,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.738816
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=461; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=302; id=8, #l=148; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=280; id=15, #l=162; 
    n.a.     n.a.            1            1.0  unknown 5.86506e-07,12.8063        6
0.000000 0.000000            2            2.0 {5.86506e-07,-0.473979,12.8063} 0.00377643,12.8063        6
0.000000 0.000000            4            4.0 {0.00284671,-0.530775,12.8063} 0.0552615,12.8063        6
0.000000 0.000000            8            8.0 {10.3501,-0.824688,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0607047,-0.176723,12.8063} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00234542,-0.516156,12.8063} 0.0388328,12.8063        6
0.000000 0.000000           64           64.0 {0.0513621,-0.449563,12.8063} 0.0247829,12.8063        6
0.000000 0.000000          128          128.0 {0.00913528,-0.498131,12.8063} 0.0327658,12.8063        6
0.000000 0.000000          256          256.0 {0.0496107,-0.483063,12.8063} 0.0349663,12.8063        6
0.000000 0.000000          512          512.0 {0.0103763,-0.161202,12.8063} 0.0109516,12.8063        6
0.000000 0.000000         1024         1024.0 {1.05969,-0.549146,12.8063} 1.06092,12.8063        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 256 and bandwidth: 25

Starting simulation for: --cats 512 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         2048         2048.0 {0.0152916,-0.214174,12.8063} 0.040775,12.8063        6
0.000000 0.000000         4096         4096.0 {0.214762,-0.455138,12.8063} 0.236175,12.8063        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {22.1021,-0.855214,12.8063} 22.1165,12.8063        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4023; id=1, #l=1792; id=2, #l=2233; id=3, #l=1794; id=4, #l=3; id=5, #l=2234; id=6, #l=1; id=7, #l=1794; id=8, #l=7; id=9, #l=4; id=10, #l=5; id=11, #l=6; id=12, #l=2235; id=13, #l=3; id=14, #l=1; id=15, #l=1772; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-19.017673 -19.017673            2            2.0 {0.00120175,-0.137432,0.00625} 0.149814,0.40625        6
-9.508837 0.000000            4            4.0 {0.120506,-0.443336,0.40625} 1.77278,0.40625        6
-4.754418 0.000000            8            8.0 {10.3501,-0.812108,0.00625} 22.5925,0.00625        6
-2.464948 -0.175477           16           16.0 {1.94437,-0.559529,0.40625} 9.58582,0.00625        6
-1.272579 -0.080210           32           32.0 {1.08932,-0.522406,0.40625} 2.23951,0.40625        6
-0.854500 -0.436422           64           64.0 {21.3422,-0.848862,0.40625} 20.5043,0.40625        6
-0.614263 -0.374026          128          128.0 {3.7649,-0.232688,0.40625} 4.5098,0.40625        6
-0.477024 -0.339784          256          256.0 {10.4562,-0.787986,0.40625} 9.99455,0.40625        6
-0.466578 -0.456132          512          512.0 {21.261,-0.845207,0.00625} 22.4398,0.00625        6
-0.658588 -0.850598         1024         1024.0 {14.051,-0.931559,0.40625} 14.0897,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 0

Starting simulation for: --cats 512 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.692877 -0.727166         2048         2048.0 {21.682,-0.818712,0.40625} 22.4854,0.40625        6
-0.767448 -0.842020         4096         4096.0 {24.5238,-0.880877,0.40625} 25.1988,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.753411 -0.739374         8192         8192.0 {11.8951,-0.873937,0.40625} 12.3497,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.783192
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4099; id=1, #l=1032; id=2, #l=2671; id=3, #l=201; id=4, #l=844; id=5, #l=2622; id=6, #l=1209; id=7, #l=154; id=8, #l=166; id=9, #l=241; id=10, #l=364; id=11, #l=263; id=12, #l=1938; id=13, #l=773; id=14, #l=77; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-33.716038 -33.716038            2            2.0 {0.00120175,-0.480717,0.00625} 0.264785,0.20625        6
-16.858019 0.000000            4            4.0 {0.207058,-0.473288,0.20625} 3.46154,0.20625        6
-8.429009 0.000000            8            8.0 {10.3501,-0.818424,0.00625} 22.5925,0.00625        6
-4.318377 -0.207745           16           16.0 {3.79951,-0.220235,0.20625} 9.58582,0.00625        6
-2.194535 -0.070693           32           32.0 {2.11533,-0.59573,0.20625} 4.38086,0.20625        6
-1.282219 -0.369904           64           64.0 {12.9164,-0.871138,0.20625} 11.2661,0.20625        6
-0.899952 -0.517685          128          128.0 {10.2945,-0.514166,0.20625} 11.7617,0.20625        6
-0.938273 -0.976594          256          256.0 {12.8076,-0.85147,0.20625} 11.8984,0.20625        6
-0.991363 -1.044452          512          512.0 {19.0988,-0.900504,0.20625} 19.1345,0.20625        6
-0.878679 -0.765995         1024         1024.0 {18.4338,-0.732396,0.20625} 18.5099,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 1

Starting simulation for: --cats 512 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.791837 -0.704995         2048         2048.0 {21.8283,-0.836435,0.20625} 23.4105,0.20625        6
-0.855066 -0.918294         4096         4096.0 {15.3044,-0.937555,0.20625} 16.634,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.866079 -0.877092         8192         8192.0 {19.8237,-0.855036,0.20625} 20.7191,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.869168
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3778; id=1, #l=817; id=2, #l=3022; id=3, #l=238; id=4, #l=746; id=5, #l=3106; id=6, #l=1393; id=7, #l=0; id=8, #l=118; id=9, #l=169; id=10, #l=610; id=11, #l=1193; id=12, #l=2289; id=13, #l=879; id=14, #l=0; id=15, #l=49; 
    n.a.     n.a.            1            1.0  unknown 2.7801e-05,0.270168        6
-0.156741 -0.156741            2            2.0 {2.7801e-05,-0.133655,0.270168} 0.179007,0.270168        6
-0.150885 -0.145030            4            4.0 {0.134937,-0.219177,0.270168} 2.61946,0.270168        6
-0.075443 0.000000            8            8.0 {10.3501,-0.761854,0.00625} 22.5925,0.00625        6
-0.063825 -0.052208           16           16.0 {2.87747,-0.307789,0.270168} 9.58582,0.00625        6
-0.163839 -0.263853           32           32.0 {4.80576,-0.616765,0.00625} 23.6523,0.139583        6
-0.805470 -1.447101           64           64.0 {23.8466,-0.777969,0.139583} 21.4081,0.139583        6
-0.652056 -0.498642          128          128.0 {18.7182,-0.904424,0.00625} 23.0957,0.139583        6
-0.701965 -0.751875          256          256.0 {21.7755,-0.850476,0.139583} 20.4319,0.139583        6
-0.787843 -0.873720          512          512.0 {13.5191,-0.525,0.139583} 13.5719,0.139583        6
-0.723272 -0.658702         1024         1024.0 {20.0588,-0.744395,0.139583} 20.1714,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 2

Starting simulation for: --cats 512 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.762989 -0.802706         2048         2048.0 {18.2686,-0.924737,0.139583} 20.6066,0.139583        6
-0.750488 -0.737986         4096         4096.0 {19.1961,-0.902596,0.139583} 21.1607,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.788048 -0.825609         8192         8192.0 {21.1872,-0.8877,0.139583} 22.5103,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.792308
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4017; id=1, #l=662; id=2, #l=2563; id=3, #l=231; id=4, #l=0; id=5, #l=1613; id=6, #l=1839; id=7, #l=78; id=8, #l=0; id=9, #l=156; id=10, #l=515; id=11, #l=1633; id=12, #l=1530; id=13, #l=1477; id=14, #l=180; id=15, #l=32; 
    n.a.     n.a.            1            1.0  unknown 0.00019657,0.0382101        6
-0.454907 -0.454907            2            2.0 {0.00019657,-0.456821,0.0382101} 1.26568,0.0382101        6
-0.427785 -0.400664            4            4.0 {0.954087,-0.489901,0.0382101} 18.5211,0.0382101        6
-0.557584 -0.687382            8            8.0 {22.6299,-0.784798,0.0382101} 24.6323,0.0382101        6
-1.008138 -1.458692           16           16.0 {20.3454,-0.822264,0.0382101} 22.5049,0.0382101        6
-0.804821 -0.601504           32           32.0 {0.786076,-0.489647,0.0382101} 13.015,0.0382101        6
-0.812565 -0.820309           64           64.0 {19.4565,-0.708615,0.0338065} 9.38802,0.0338065        6
-0.785173 -0.757782          128          128.0 {3.74364,-0.60102,0.03125} 13.4274,0.03125        6
-0.783401 -0.781629          256          256.0 {20.3305,-0.895294,0.03125} 14.3292,0.03125        6
-0.774060 -0.764719          512          512.0 {4.25219,-0.580504,0.03125} 4.48797,0.03125        6
-0.761447 -0.748834         1024         1024.0 {24.6628,-0.762673,0.03125} 25.1656,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 3

Starting simulation for: --cats 512 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.753104 -0.744761         2048         2048.0 {6.26651,-0.696847,0.03125} 16.7096,0.03125        6
-0.746820 -0.740536         4096         4096.0 {11.2093,-0.820809,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.739174 -0.731528         8192         8192.0 {20.6363,-0.843566,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.739581
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=462; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=302; id=8, #l=149; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=280; id=15, #l=162; 
    n.a.     n.a.            1            1.0  unknown 2.93324e-07,25.6063        6
0.000000 0.000000            2            2.0 {2.93324e-07,-0.502333,25.6063} 0.00188867,25.6063        6
0.000000 0.000000            4            4.0 {0.0014237,-0.161946,25.6063} 0.0276375,25.6063        6
0.000000 0.000000            8            8.0 {10.3501,-0.836747,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0303598,-0.157043,25.6063} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.00117299,-0.479925,25.6063} 0.0194211,25.6063        6
0.000000 0.000000           64           64.0 {0.0256873,-0.470867,25.6063} 0.0123945,25.6063        6
0.000000 0.000000          128          128.0 {0.00456875,-0.505934,25.6063} 0.0163869,25.6063        6
0.000000 0.000000          256          256.0 {0.0248114,-0.487658,25.6063} 0.0174874,25.6063        6
0.000000 0.000000          512          512.0 {0.0051894,-0.215899,25.6063} 0.00547714,25.6063        6
0.000000 0.000000         1024         1024.0 {0.0300986,-0.443191,25.6063} 0.0307122,25.6063        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 512 and bandwidth: 25

Starting simulation for: --cats 1024 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         2048         2048.0 {0.00764769,-0.443631,25.6063} 0.0203925,25.6063        6
0.000000 0.000000         4096         4096.0 {0.0136799,-0.185092,25.6063} 0.0243891,25.6063        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {0.181397,-0.519015,25.6063} 4.73021,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4009; id=1, #l=3229; id=2, #l=783; id=3, #l=2788; id=4, #l=445; id=5, #l=782; id=6, #l=1; id=7, #l=2787; id=8, #l=2; id=9, #l=445; id=10, #l=3; id=11, #l=782; id=12, #l=3; id=13, #l=1; id=14, #l=1; id=15, #l=2789; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-68.020164 -68.020164            2            2.0 {0.00120175,-0.484909,0.00625} 0.134429,0.40625        6
-34.010082 0.000000            4            4.0 {0.105122,-0.511268,0.40625} 1.7574,0.40625        6
-17.005041 0.000000            8            8.0 {10.3501,-0.774575,0.00625} 22.5925,0.00625        6
-8.588131 -0.171222           16           16.0 {1.92898,-0.576746,0.40625} 9.58582,0.00625        6
-7.595750 -6.603368           32           32.0 {4.80576,-0.6491,0.00625} 19.9472,0.40625        6
-4.045532 -0.495315           64           64.0 {21.3268,-0.875478,0.40625} 20.4889,0.40625        6
-2.262000 -0.478467          128          128.0 {11.1341,-0.495495,0.40625} 11.879,0.40625        6
-1.307891 -0.353781          256          256.0 {6.50234,-0.676543,0.40625} 6.04071,0.40625        6
-1.129676 -0.951461          512          512.0 {20.1579,-0.868828,0.40625} 20.176,0.40625        6
-0.934989 -0.740302         1024         1024.0 {13.7279,-0.933864,0.40625} 13.7666,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 0

Starting simulation for: --cats 1024 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.865617 -0.796245         2048         2048.0 {16.0051,-0.989984,0.40625} 16.8084,0.40625        6
-0.875088 -0.884558         4096         4096.0 {20.2007,-0.895214,0.40625} 20.8757,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.858057 -0.841027         8192         8192.0 {21.2643,-0.788038,0.40625} 21.7189,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.894754
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4076; id=1, #l=966; id=2, #l=3081; id=3, #l=287; id=4, #l=787; id=5, #l=2706; id=6, #l=429; id=7, #l=144; id=8, #l=125; id=9, #l=227; id=10, #l=905; id=11, #l=1299; id=12, #l=1831; id=13, #l=329; id=14, #l=67; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-37.550327 -37.550327            2            2.0 {0.00120175,-0.524384,0.00625} 0.249633,0.20625        6
-18.775164 0.000000            4            4.0 {0.191906,-0.18718,0.20625} 3.44639,0.20625        6
-9.387582 0.000000            8            8.0 {10.3501,-0.844219,0.00625} 22.5925,0.00625        6
-4.786799 -0.186016           16           16.0 {5.72376,-0.659207,0.20625} 9.58582,0.00625        6
-2.486623 -0.186447           32           32.0 {2.10017,-0.222994,0.20625} 4.36571,0.20625        6
-1.423961 -0.361299           64           64.0 {12.9012,-0.503301,0.20625} 11.2509,0.20625        6
-0.948891 -0.473821          128          128.0 {18.0369,-0.724645,0.20625} 19.5042,0.20625        6
-0.936302 -0.923714          256          256.0 {22.4895,-0.776581,0.20625} 21.5802,0.20625        6
-1.152230 -1.368158          512          512.0 {10.114,-0.774795,0.20625} 10.1497,0.20625        6
-0.918000 -0.683770         1024         1024.0 {17.5701,-0.994549,0.20625} 17.6463,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 1

Starting simulation for: --cats 1024 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.827703 -0.737405         2048         2048.0 {12.6616,-0.918843,0.20625} 14.2439,0.20625        6
-0.813691 -0.799680         4096         4096.0 {22.6832,-0.799283,0.20625} 24.0128,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.800174 -0.786658         8192         8192.0 {22.4146,-0.770422,0.20625} 23.31,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.819493
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4067; id=1, #l=1521; id=2, #l=2140; id=3, #l=300; id=4, #l=968; id=5, #l=1656; id=6, #l=1931; id=7, #l=0; id=8, #l=183; id=9, #l=560; id=10, #l=327; id=11, #l=961; id=12, #l=592; id=13, #l=1423; id=14, #l=0; id=15, #l=62; 
    n.a.     n.a.            1            1.0  unknown 2.7661e-05,0.271535        6
-0.155159 -0.155159            2            2.0 {2.7661e-05,-0.133635,0.271535} 0.178105,0.271535        6
-0.251709 -0.348258            4            4.0 {0.134258,-0.530446,0.271535} 2.60627,0.271535        6
-0.125854 0.000000            8            8.0 {10.3501,-0.801532,0.00625} 22.5925,0.00625        6
-0.254914 -0.383974           16           16.0 {14.1814,-0.886081,0.139583} 14.7725,0.139583        6
-0.331906 -0.408897           32           32.0 {4.80576,-0.675978,0.00625} 12.1747,0.139583        6
-0.394588 -0.457271           64           64.0 {2.42236,-0.219164,0.271535} 1.16882,0.271535        6
-0.915375 -1.436162          128          128.0 {18.7182,-0.971222,0.00625} 20.9315,0.139583        6
-0.675664 -0.435953          256          256.0 {13.1635,-0.89075,0.139583} 11.82,0.139583        6
-0.767487 -0.859311          512          512.0 {2.87736,-0.576901,0.139583} 2.93014,0.139583        6
-0.642848 -0.518208         1024         1024.0 {15.6857,-0.982071,0.139583} 15.7983,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 2

Starting simulation for: --cats 1024 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.764691 -0.886533         2048         2048.0 {10.2537,-0.786656,0.139583} 12.5917,0.139583        6
-0.790434 -0.816177         4096         4096.0 {26.2857,-0.932668,0.139583} 28.2502,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.854462 -0.918490         8192         8192.0 {16.844,-0.985283,0.139583} 18.167,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.848697
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3564; id=1, #l=2839; id=2, #l=1656; id=3, #l=304; id=4, #l=0; id=5, #l=981; id=6, #l=605; id=7, #l=101; id=8, #l=0; id=9, #l=1045; id=10, #l=1498; id=11, #l=1232; id=12, #l=878; id=13, #l=463; id=14, #l=349; id=15, #l=47; 
    n.a.     n.a.            1            1.0  unknown 0.000196467,0.03823        6
-0.467564 -0.467564            2            2.0 {0.000196467,-0.469498,0.03823} 1.26502,0.03823        6
-0.429280 -0.390996            4            4.0 {0.953589,-0.47833,0.03823} 18.5114,0.03823        6
-0.548250 -0.667220            8            8.0 {22.618,-0.867647,0.03823} 24.6195,0.03823        6
-1.077161 -1.606072           16           16.0 {20.3348,-0.833888,0.03823} 22.4931,0.03823        6
-0.812323 -0.547484           32           32.0 {0.785665,-0.241865,0.03823} 13.0082,0.03823        6
-0.869489 -0.926655           64           64.0 {19.448,-0.736826,0.0338214} 9.3839,0.0338214        6
-0.826216 -0.782942          128          128.0 {3.74364,-0.561103,0.03125} 13.4274,0.03125        6
-0.797648 -0.769080          256          256.0 {20.3305,-0.902766,0.03125} 14.3292,0.03125        6
-0.766940 -0.736233          512          512.0 {4.25219,-0.252845,0.03125} 4.48797,0.03125        6
-0.753660 -0.740380         1024         1024.0 {24.6628,-0.699798,0.03125} 25.1656,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 3

Starting simulation for: --cats 1024 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.750060 -0.746459         2048         2048.0 {6.26651,-0.682732,0.03125} 16.7096,0.03125        6
-0.743797 -0.737535         4096         4096.0 {11.2093,-0.512642,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.738278 -0.732758         8192         8192.0 {20.6363,-0.846632,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.737102
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=1; id=1, #l=3; id=2, #l=0; id=3, #l=463; id=4, #l=0; id=5, #l=0; id=6, #l=462; id=7, #l=302; id=8, #l=150; id=9, #l=0; id=10, #l=0; id=11, #l=0; id=12, #l=0; id=13, #l=159; id=14, #l=280; id=15, #l=162; 
    n.a.     n.a.            1            1.0  unknown 1.4668e-07,51.2062        6
0.000000 0.000000            2            2.0 {1.4668e-07,-0.477514,51.2062} 0.000944452,51.2062        6
0.000000 0.000000            4            4.0 {0.000711939,-0.51085,51.2062} 0.0138204,51.2062        6
0.000000 0.000000            8            8.0 {10.3501,-0.776515,0.00625} 22.5925,0.00625        6
0.000000 0.000000           16           16.0 {0.0151817,-0.471855,51.2062} 9.58582,0.00625        6
0.000000 0.000000           32           32.0 {0.000586569,-0.483367,51.2062} 0.00971176,51.2062        6
0.000000 0.000000           64           64.0 {0.0128452,-0.489863,51.2062} 0.006198,51.2062        6
0.000000 0.000000          128          128.0 {0.00228466,-0.510163,51.2062} 0.00819446,51.2062        6
0.000000 0.000000          256          256.0 {0.0124072,-0.507465,51.2062} 0.00874478,51.2062        6
0.000000 0.000000          512          512.0 {0.00259502,-0.501412,51.2062} 0.0027389,51.2062        6
0.000000 0.000000         1024         1024.0 {0.0150511,-0.451791,51.2062} 0.015358,51.2062        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 1024 and bandwidth: 25

Starting simulation for: --cats 2048 --bandwidth 0 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         2048         2048.0 {0.00382431,-0.444066,51.2062} 0.0101975,51.2062        6
0.000000 0.000000         4096         4096.0 {16.7548,-0.983294,51.2062} 16.7602,51.2062        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.000000 0.000000         8192         8192.0 {0.0125939,-0.154048,51.2062} 4.73022,0.00625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = 0.000000
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4000; id=1, #l=3199; id=2, #l=801; id=3, #l=3199; id=4, #l=0; id=5, #l=801; id=6, #l=1; id=7, #l=3200; id=8, #l=0; id=9, #l=0; id=10, #l=1; id=11, #l=802; id=12, #l=0; id=13, #l=0; id=14, #l=1; id=15, #l=2817; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-64.247406 -64.247406            2            2.0 {0.00120175,-0.454877,0.00625} 0.126737,0.40625        6
-32.123703 0.000000            4            4.0 {0.0974294,-0.502423,0.40625} 1.7497,0.40625        6
-16.061852 0.000000            8            8.0 {10.3501,-0.78167,0.00625} 22.5925,0.00625        6
-8.063302 -0.064753           16           16.0 {1.92129,-0.545442,0.40625} 9.58582,0.00625        6
-7.258940 -6.454577           32           32.0 {4.80576,-0.680083,0.00625} 19.9395,0.40625        6
-3.792568 -0.326196           64           64.0 {21.3191,-0.829715,0.40625} 20.4812,0.40625        6
-2.137012 -0.481455          128          128.0 {18.7182,-0.940895,0.00625} 20.7329,0.40625        6
-1.255874 -0.374736          256          256.0 {5.51004,-0.290698,0.40625} 5.0484,0.40625        6
-1.661449 -2.067024          512          512.0 {19.904,-0.856775,0.40625} 19.9222,0.40625        6
-1.401373 -1.141297         1024         1024.0 {17.6279,-0.977983,0.40625} 17.6666,0.40625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 0

Starting simulation for: --cats 2048 --bandwidth 1 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-1.174531 -0.947688         2048         2048.0 {22.7359,-0.85009,0.40625} 23.5392,0.40625        6
-0.986510 -0.798489         4096         4096.0 {20.6699,-0.76496,0.40625} 21.345,0.40625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.872673 -0.758837         8192         8192.0 {23.7489,-0.897107,0.40625} 24.2035,0.40625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.846926
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=4074; id=1, #l=211; id=2, #l=3068; id=3, #l=193; id=4, #l=155; id=5, #l=3789; id=6, #l=1054; id=7, #l=184; id=8, #l=166; id=9, #l=81; id=10, #l=205; id=11, #l=819; id=12, #l=2707; id=13, #l=1261; id=14, #l=43; id=15, #l=0; 
    n.a.     n.a.            1            1.0  unknown 0.00120175,0.00625        6
-34.663139 -34.663139            2            2.0 {0.00120175,-0.485758,0.00625} 0.242057,0.20625        6
-17.331570 0.000000            4            4.0 {0.184331,-0.490918,0.20625} 3.43881,0.20625        6
-8.665785 0.000000            8            8.0 {10.3501,-0.425873,0.00625} 22.5925,0.00625        6
-4.380532 -0.095278           16           16.0 {3.77679,-0.618584,0.20625} 9.58582,0.00625        6
-2.893362 -1.406193           32           32.0 {2.0926,-0.56194,0.20625} 4.35813,0.20625        6
-1.624848 -0.356334           64           64.0 {12.8937,-0.497169,0.20625} 11.2433,0.20625        6
-1.036692 -0.448536          128          128.0 {10.2718,-0.462643,0.20625} 11.739,0.20625        6
-0.989310 -0.941929          256          256.0 {12.7849,-0.913412,0.20625} 11.8756,0.20625        6
-0.961941 -0.934571          512          512.0 {19.5609,-0.880094,0.20625} 19.5967,0.20625        6
-0.723197 -0.484453         1024         1024.0 {23.3807,-0.768978,0.20625} 23.4569,0.20625        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 1

Starting simulation for: --cats 2048 --bandwidth 2 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.743221 -0.763245         2048         2048.0 {21.9267,-0.847202,0.20625} 23.509,0.20625        6
-0.806121 -0.869021         4096         4096.0 {15.7666,-0.980396,0.20625} 17.0961,0.20625        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.886773 -0.967424         8192         8192.0 {17.1949,-0.983667,0.20625} 18.0903,0.20625        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.922302
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3708; id=1, #l=982; id=2, #l=2976; id=3, #l=285; id=4, #l=841; id=5, #l=3305; id=6, #l=1402; id=7, #l=0; id=8, #l=136; id=9, #l=223; id=10, #l=759; id=11, #l=1339; id=12, #l=1794; id=13, #l=584; id=14, #l=0; id=15, #l=51; 
    n.a.     n.a.            1            1.0  unknown 2.7591e-05,0.272224        6
-0.514735 -0.514735            2            2.0 {2.7591e-05,-0.445548,0.272224} 0.177655,0.272224        6
-0.407677 -0.300618            4            4.0 {0.133918,-0.458407,0.272224} 2.59967,0.272224        6
-0.203838 0.000000            8            8.0 {10.35,-0.817653,0.00625} 22.5925,0.00625        6
-0.167109 -0.130380           16           16.0 {2.85573,-0.60443,0.272224} 9.58581,0.00625        6
-0.167521 -0.167934           32           32.0 {0.110336,-0.462817,0.272224} 1.82681,0.272224        6
-0.302480 -0.437439           64           64.0 {26.6899,-0.672884,0.139583} 24.2514,0.139583        6
-1.032436 -1.762392          128          128.0 {18.7182,-0.932874,0.00625} 21.1629,0.139583        6
-1.048713 -1.064990          256          256.0 {21.2755,-0.822342,0.139583} 19.9319,0.139583        6
-1.096117 -1.143521          512          512.0 {17.6759,-0.924999,0.139583} 17.7286,0.139583        6
-0.901170 -0.706223         1024         1024.0 {22.2454,-0.783348,0.139583} 22.358,0.139583        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 2

Starting simulation for: --cats 2048 --bandwidth 3 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.851237 -0.801303         2048         2048.0 {13.6194,-0.952126,0.139583} 15.9574,0.139583        6
-0.839719 -0.828201         4096         4096.0 {18.5319,-0.944146,0.139583} 20.4965,0.139583        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.837151 -0.834583         8192         8192.0 {25.4932,-0.988568,0.139583} 26.8163,0.139583        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.840051
total feature number = 60000
creating quadratic features for pairs: :: 
WARNING: any duplicate namespace interactions will be removed
You can use --leave_duplicate_interactions to disable this behaviour.
Enabling FTRL based optimization
Algorithm used: Coin Betting
ftrl_alpha = 4
ftrl_beta = 1
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = 
num sources = 1
Enabled reductions: ftrl, generate_interactions, scorer, binary, cats_tree, get_pmf, pmf_to_pdf, cb_explore_pdf, cats_pdf, sample_pdf, cats
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
Learn() count per node: id=0, #l=3412; id=1, #l=1278; id=2, #l=2191; id=3, #l=261; id=4, #l=0; id=5, #l=1424; id=6, #l=1432; id=7, #l=70; id=8, #l=0; id=9, #l=208; id=10, #l=931; id=11, #l=1336; id=12, #l=1266; id=13, #l=1149; id=14, #l=249; id=15, #l=44; 
    n.a.     n.a.            1            1.0  unknown 0.000196416,0.03824        6
-0.521969 -0.521969            2            2.0 {0.000196416,-0.524109,0.03824} 1.26469,0.03824        6
-0.468226 -0.414483            4            4.0 {0.953339,-0.507194,0.03824} 18.5066,0.03824        6
-0.575733 -0.683239            8            8.0 {22.6121,-0.91378,0.03824} 24.613,0.03824        6
-1.035445 -1.495157           16           16.0 {20.3295,-0.826478,0.03824} 22.4872,0.03824        6
-0.804020 -0.572595           32           32.0 {0.78546,-0.505594,0.03824} 13.0048,0.03824        6
-0.816294 -0.828568           64           64.0 {19.4437,-0.814961,0.0338288} 9.38184,0.0338288        6
-0.823198 -0.830102          128          128.0 {3.74364,-0.582563,0.03125} 13.4274,0.03125        6
-0.785072 -0.746945          256          256.0 {20.3305,-0.793605,0.03125} 14.3292,0.03125        6
-0.762668 -0.740264          512          512.0 {4.25219,-0.643019,0.03125} 4.48797,0.03125        6
-0.742732 -0.722796         1024         1024.0 {24.6628,-0.962693,0.03125} 25.1656,0.03125        6
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 3

Starting simulation for: --cats 2048 --bandwidth 25 --min_value 0 --max_value 32 --json --chain_hash --coin --epsilon 0.2 -q :: 
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.739782 -0.736833         2048         2048.0 {6.26651,-0.694128,0.03125} 16.7096,0.03125        6
-0.736563 -0.733343         4096         4096.0 {11.2093,-0.874905,0.03125} 19.9844,0.03125        6
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>-0.736096 -0.735630         8192         8192.0 {20.6363,-0.835252,0.03125} 26.546,0.03125        6

finished run
number of examples = 10000
weighted example sum = 10000.000000
weighted label sum = 10000.000000
average loss = -0.737215
total feature number = 60000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done with simulation for num_actions: 2048 and bandwidth: 25

Plotting...
</pre></div>
</div>
<img alt="../_images/python_cats_35_118.png" src="../_images/python_cats_35_118.png" />
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "VowpalWabbit/vowpal_wabbit",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              

              
              <div class='prev-next-bottom'>
                
    <a class='left-prev' id="prev-link" href="off_policy_evaluation.html" title="previous page">Offline policy evaluation using the VW command line</a>
    <a class='right-next' id="next-link" href="python_classification.html" title="next page">Classification with Vowpal Wabbit</a>

              </div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, John langford et al.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.5.4.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>